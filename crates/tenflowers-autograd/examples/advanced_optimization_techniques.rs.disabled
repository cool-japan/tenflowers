// # Advanced Optimization Techniques Example
//
// This example demonstrates advanced gradient-based optimization techniques including:
// - Gradient clipping (global norm and value-based)
// - Gradient accumulation for large effective batch sizes
// - Gradient compression for distributed training
// - Mixed precision training (AMP)
// - Second-order optimization (Newton's method, natural gradient)
// - Adaptive learning rate scheduling
// - Gradient noise injection for regularization
//
// These techniques are essential for training large-scale models efficiently.

use scirs2_autograd::ndarray::array;
use std::collections::HashMap;
use tenflowers_autograd::{
    clip_by_global_norm, clip_by_value, scale_gradients, AMPConfig, AMPPolicy, CompressionConfig,
    CompressionMethod, GradientAccumulator, GradientCompressor, GradientTape, TrackedTensor,
};
use tenflowers_core::{Result, Tensor};

fn main() -> Result<()> {
    println!("Advanced Optimization Techniques Example");
    println!("========================================\n");

    // Example 1: Gradient clipping to prevent exploding gradients
    example_1_gradient_clipping()?;

    // Example 2-7: Commented out due to API changes
    // These examples need to be updated to match the current GradientAccumulator,
    // AMPPolicy, and GradientCompressor APIs
    // TODO: Update these examples to match current API

    // example_2_gradient_accumulation()?;
    // example_3_gradient_compression()?;
    // example_4_mixed_precision_training()?;
    example_5_gradient_noise()?;
    example_6_adaptive_clipping()?;
    // example_7_complete_training_loop()?;

    println!("\n\nAdvanced optimization examples completed!");
    Ok(())
}

/// Example 1: Gradient clipping to prevent exploding gradients
fn example_1_gradient_clipping() -> Result<()> {
    println!("Example 1: Gradient Clipping");
    println!("----------------------------");

    // Simulate gradients from a model
    let grad1 = Tensor::from_array(array![10.0f32, 20.0, 30.0].into_dyn());
    let grad2 = Tensor::from_array(array![5.0f32, 15.0, 25.0].into_dyn());
    let gradients = vec![grad1, grad2];

    println!("Original gradients:");
    println!("  Grad 1: {:?}", gradients[0].as_slice().unwrap());
    println!("  Grad 2: {:?}", gradients[1].as_slice().unwrap());

    // Compute global norm
    let mut global_norm_sq = 0.0f32;
    for grad in &gradients {
        if let Some(data) = grad.as_slice() {
            for &val in data {
                global_norm_sq += val * val;
            }
        }
    }
    let global_norm = global_norm_sq.sqrt();
    println!("  Global norm: {:.2}", global_norm);

    // Clip by global norm (max norm = 10.0)
    let max_norm = 10.0f32;
    let (clipped_by_norm, clipped_norm) = clip_by_global_norm(&gradients, max_norm)?;

    println!("\nClipped by global norm (max = {}):", max_norm);
    println!("  Actual norm after clipping: {:.2}", clipped_norm);
    println!(
        "  Clipped grad 1: {:?}",
        clipped_by_norm[0].as_slice().unwrap()
    );
    println!(
        "  Clipped grad 2: {:?}",
        clipped_by_norm[1].as_slice().unwrap()
    );

    // Clip by value (max absolute value = 15.0)
    let clip_value = 15.0f32;
    let clipped_by_value = clip_by_value(&gradients, clip_value)?;

    println!("\nClipped by value (max abs = {}):", clip_value);
    println!(
        "  Clipped grad 1: {:?}",
        clipped_by_value[0].as_slice().unwrap()
    );
    println!(
        "  Clipped grad 2: {:?}",
        clipped_by_value[1].as_slice().unwrap()
    );

    println!();
    Ok(())
}

/// Example 2: Gradient accumulation for large effective batch sizes
fn example_2_gradient_accumulation() -> Result<()> {
    println!("Example 2: Gradient Accumulation");
    println!("--------------------------------");

    let accumulation_steps = 4;
    let mut accumulator = GradientAccumulator::new();

    println!("Accumulating gradients over {} steps", accumulation_steps);
    println!(
        "Effective batch size = {} × micro batch size\n",
        accumulation_steps
    );

    // Simulate multiple micro-batches
    for step in 0..accumulation_steps {
        // Simulate gradients from one micro-batch
        let grad1 = Tensor::from_array(
            array![1.0f32 * (step + 1) as f32, 2.0 * (step + 1) as f32].into_dyn(),
        );
        let grad2 = Tensor::from_array(
            array![0.5f32 * (step + 1) as f32, 1.5 * (step + 1) as f32].into_dyn(),
        );

        let gradients = vec![Some(grad1), Some(grad2)];

        println!(
            "Step {}: Gradients: {:?}, {:?}",
            step + 1,
            gradients[0].as_ref().unwrap().as_slice().unwrap(),
            gradients[1].as_ref().unwrap().as_slice().unwrap()
        );

        // Accumulate
        accumulator.accumulate(&gradients)?;
    }

    // Get averaged gradients
    let averaged = accumulator.get_averaged_gradients()?;

    println!("\nAveraged gradients:");
    println!(
        "  Param 1: {:?}",
        averaged[0].as_ref().unwrap().as_slice().unwrap()
    );
    println!(
        "  Param 2: {:?}",
        averaged[1].as_ref().unwrap().as_slice().unwrap()
    );

    // Clear for next iteration
    accumulator.clear();

    println!("\nBenefits:");
    println!("  - Larger effective batch size without OOM");
    println!("  - More stable training");
    println!("  - Better gradient estimates\n");

    Ok(())
}

/// Example 3: Gradient compression for communication efficiency
fn example_3_gradient_compression() -> Result<()> {
    println!("Example 3: Gradient Compression");
    println!("-------------------------------");

    // Create compressor with sparsification
    let config = CompressionConfig {
        method: CompressionMethod::Sparsification { threshold: 0.5 },
        error_feedback: true,
        min_tensor_size: 2, // Compress small tensors for demo
        target_ratio: 0.9,
    };

    let mut compressor = GradientCompressor::with_config(config);

    // Large gradient with many small values
    let gradient =
        Tensor::from_array(array![0.1f32, 2.0, 0.05, 3.0, 0.02, 1.5, 0.01, 4.0].into_dyn());

    println!("Original gradient:");
    println!("  {:?}", gradient.as_slice().unwrap());

    // Compress
    let compressed = compressor.compress(&gradient, "param1")?;

    println!("\nCompressed gradient (threshold = 0.5):");
    println!("  {:?}", compressed.as_slice().unwrap());

    // Get statistics
    let stats = compressor.get_stats();
    println!("\nCompression stats:");
    println!(
        "  Compression ratio: {:.1}%",
        stats.compression_ratio() * 100.0
    );
    println!("  Original bytes: {}", stats.total_bytes_original);
    println!("  Compressed bytes: {}", stats.total_bytes_compressed);

    println!("\nBenefits:");
    println!("  - Reduced communication in distributed training");
    println!("  - Lower bandwidth requirements");
    println!("  - Faster gradient synchronization\n");

    Ok(())
}

/// Example 4: Mixed precision training workflow
fn example_4_mixed_precision_training() -> Result<()> {
    println!("Example 4: Mixed Precision Training");
    println!("-----------------------------------");

    // Configure AMP
    let amp_config = AMPConfig {
        enabled: true,
        initial_scale: 65536.0,
        growth_factor: 2.0,
        backoff_factor: 0.5,
        growth_interval: 2000,
        target_dtype: tenflowers_core::DType::Float16,
    };

    let mut amp_policy = AMPPolicy::new(amp_config);

    println!("Mixed precision training enabled");
    println!("  Initial loss scale: {}", amp_policy.get_current_scale());
    println!("  Target dtype: FP16\n");

    // Simulate training iterations
    for iteration in 0..5 {
        // Simulate forward pass and compute loss
        let loss = Tensor::from_array(array![0.5f32 * (iteration + 1) as f32].into_dyn());

        // Scale loss for FP16
        let scaled_loss = amp_policy.scale_loss(&loss)?;

        println!(
            "Iteration {}: Loss = {:.3}, Scaled = {:.1}",
            iteration + 1,
            loss.as_slice().unwrap()[0],
            scaled_loss.as_slice().unwrap()[0]
        );

        // Simulate gradients
        let mut gradients = vec![
            Some(Tensor::from_array(array![1.0f32, 2.0].into_dyn())),
            Some(Tensor::from_array(array![0.5f32, 1.5].into_dyn())),
        ];

        // Unscale and check for overflow
        let should_step = amp_policy.unscale_and_check(&mut gradients)?;

        if should_step {
            println!("  ✓ Gradients valid, optimizer step");
        } else {
            println!("  ✗ Overflow detected, skipping step");
        }

        // Update scale based on whether we found overflow
        amp_policy.update_scale(!should_step);
    }

    println!("\nFinal loss scale: {}", amp_policy.get_current_scale());

    let metrics = amp_policy.get_stability_metrics();
    println!("Stability metrics:");
    println!("  Overflow count: {}", metrics.overflow_count);
    println!("  Scale updates: {}", metrics.scale_update_count);

    println!("\nBenefits:");
    println!("  - 2x faster training on modern GPUs");
    println!("  - 50% memory reduction");
    println!("  - Minimal accuracy impact\n");

    Ok(())
}

/// Example 5: Gradient noise injection for regularization
fn example_5_gradient_noise() -> Result<()> {
    println!("Example 5: Gradient Noise Injection");
    println!("-----------------------------------");

    let gradients = vec![
        Tensor::from_array(array![1.0f32, 2.0, 3.0].into_dyn()),
        Tensor::from_array(array![0.5f32, 1.5, 2.5].into_dyn()),
    ];

    println!("Original gradients:");
    for (i, grad) in gradients.iter().enumerate() {
        println!("  Param {}: {:?}", i + 1, grad.as_slice().unwrap());
    }

    // Add noise for regularization (helps escape sharp minima)
    let noise_scale = 0.01f32;
    let mut noisy_gradients = Vec::new();

    for grad in &gradients {
        // Simple noise simulation (in practice, use proper random numbers)
        let noise = Tensor::from_array(array![noise_scale, -noise_scale, noise_scale].into_dyn());
        let noisy = tenflowers_core::ops::add(grad, &noise)?;
        noisy_gradients.push(noisy);
    }

    println!("\nGradients with noise (scale = {}):", noise_scale);
    for (i, grad) in noisy_gradients.iter().enumerate() {
        println!("  Param {}: {:?}", i + 1, grad.as_slice().unwrap());
    }

    println!("\nBenefits:");
    println!("  - Helps escape sharp local minima");
    println!("  - Improves generalization");
    println!("  - Acts as implicit regularization\n");

    Ok(())
}

/// Example 6: Adaptive gradient clipping based on history
fn example_6_adaptive_clipping() -> Result<()> {
    println!("Example 6: Adaptive Gradient Clipping");
    println!("-------------------------------------");

    // Track gradient norms over time
    let mut norm_history = Vec::new();
    let window_size = 100;

    // Simulate training iterations
    for iteration in 1..=10 {
        // Simulate varying gradient norms
        let norm = if iteration % 3 == 0 {
            50.0f32 // Occasional spike
        } else {
            5.0 + iteration as f32 * 0.5
        };

        norm_history.push(norm);
        if norm_history.len() > window_size {
            norm_history.remove(0);
        }

        // Compute adaptive threshold (e.g., mean + 2*std)
        let mean = norm_history.iter().sum::<f32>() / norm_history.len() as f32;
        let variance = norm_history
            .iter()
            .map(|&x| (x - mean).powi(2))
            .sum::<f32>()
            / norm_history.len() as f32;
        let std_dev = variance.sqrt();
        let adaptive_threshold = mean + 2.0 * std_dev;

        let clipped = norm.min(adaptive_threshold);

        println!(
            "Iter {}: norm = {:.2}, threshold = {:.2}, clipped = {:.2}",
            iteration, norm, adaptive_threshold, clipped
        );
    }

    println!("\nBenefits:");
    println!("  - Adapts to gradient distribution");
    println!("  - Prevents over-aggressive clipping");
    println!("  - Handles varying gradient scales\n");

    Ok(())
}

/// Example 7: Complete training loop with all techniques
#[allow(dead_code)]
fn example_7_complete_training_loop() -> Result<()> {
    println!("Example 7: Complete Training Loop");
    println!("---------------------------------");

    // Configuration
    let learning_rate = 0.01f32;
    let accumulation_steps = 4;
    let max_grad_norm = 1.0f32;

    // Initialize components
    let mut accumulator = GradientAccumulator::new();
    let mut amp_policy = AMPPolicy::new(AMPConfig {
        enabled: true,
        initial_scale: 1024.0,
        ..Default::default()
    });

    println!("Training configuration:");
    println!("  Learning rate: {}", learning_rate);
    println!("  Gradient accumulation steps: {}", accumulation_steps);
    println!("  Max gradient norm: {}", max_grad_norm);
    println!("  Mixed precision: enabled\n");

    // Simulate training epochs
    for epoch in 1..=3 {
        println!("Epoch {}:", epoch);

        // Simulate multiple steps
        for step in 1..=accumulation_steps {
            let tape = GradientTape::new();

            // Simulate forward pass
            let x = tape.watch(Tensor::from_array(array![1.0f32, 2.0].into_dyn()));
            let y = x.mul(&x)?;
            let loss = y.sum(None, false)?;

            // Scale loss for mixed precision
            let scaled_loss = amp_policy.scale_loss(&loss.tensor)?;
            let scaled_loss_tracked = tape.watch(scaled_loss);

            // Backward pass
            let mut gradients = tape.gradient(
                std::slice::from_ref(&scaled_loss_tracked),
                std::slice::from_ref(&x),
            )?;

            // Unscale gradients
            let should_step = amp_policy.unscale_and_check(&mut gradients)?;

            if should_step {
                accumulator.accumulate(&gradients)?;
                println!(
                    "  Step {}/{}: gradients accumulated",
                    step, accumulation_steps
                );
            } else {
                println!("  Step {}/{}: overflow, skipping", step, accumulation_steps);
            }
        }

        // Get averaged gradients
        let mut avg_gradients = accumulator.get_averaged_gradients()?;

        // Convert Option<Tensor> to Tensor for clipping
        let mut grad_tensors: Vec<Tensor<f32>> = Vec::new();
        for opt_grad in avg_gradients.iter() {
            if let Some(grad) = opt_grad {
                grad_tensors.push(grad.clone());
            }
        }

        // Clip gradients
        let clipped_gradients = clip_by_global_norm(&grad_tensors, max_grad_norm)?;

        println!("  Averaged and clipped gradients");

        // Apply gradients (in real code, use optimizer)
        println!("  Applied gradients with learning rate {}", learning_rate);

        // Clear accumulator for next epoch
        accumulator.clear();

        // Update loss scale
        amp_policy.update_scale(false);
        println!(
            "  Updated loss scale to {}\n",
            amp_policy.get_current_scale()
        );
    }

    println!("Training complete!");
    println!("\nThis example demonstrated:");
    println!("  ✓ Mixed precision training");
    println!("  ✓ Gradient accumulation");
    println!("  ✓ Gradient clipping");
    println!("  ✓ Complete training workflow\n");

    Ok(())
}
