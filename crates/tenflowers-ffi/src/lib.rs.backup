//! Python bindings for TenfloweRS machine learning framework
#![deny(unsafe_code)]
#![allow(unsafe_code)] // Allow unsafe code for C FFI
#![allow(clippy::too_many_arguments)] // Common in ML APIs
#![allow(clippy::module_name_repetitions)] // Common in FFI bindings
#![allow(clippy::not_unsafe_ptr_arg_deref)] // C FFI functions work with raw pointers
#![allow(unexpected_cfgs)] // Allow tensorboard and other conditional features
#![allow(unused_imports)] // Some imports conditional on features
#![allow(deprecated)] // Some PyO3 functions deprecated but still needed
#![allow(clippy::uninlined_format_args)] // Format strings more readable with explicit args
#![allow(non_snake_case)] // Python method names like T() match Python conventions
#![allow(unused_variables)] // FFI callback parameters often unused
#![allow(unused_mut)] // PyO3 sometimes requires mut for RefMut
#![allow(unreachable_patterns)] // Match patterns for future device types
#![allow(clippy::only_used_in_recursion)] // Recursive validation functions
#![allow(clippy::redundant_closure)] // Some closures needed for type inference
#![allow(clippy::collapsible_if)] // Separate conditions more readable in FFI
#![allow(clippy::to_string_in_format_args)] // Sometimes needed for type consistency
#![allow(clippy::manual_range_contains)] // Explicit bounds checks more readable
#![allow(clippy::manual_slice_size_calculation)] // Memory layout explicit in FFI
#![allow(clippy::missing_const_for_thread_local)] // Thread-local error handling
#![allow(private_interfaces)] // FFI structs used in public enums
#![allow(clippy::unnecessary_cast)] // Type clarity in FFI conversions
#![allow(clippy::useless_format)] // String formatting for Python repr
#![allow(clippy::large_enum_variant)] // Neural network modules vary in size
#![allow(clippy::map_identity)] // Some maps needed for type clarity in FFI

// ===== Modules =====
pub mod benchmarks;
pub mod bottleneck_detection;
pub mod dtype_promotion;
pub mod eager_execution_optimizer;
pub mod large_model_support;
// pub mod memory_optimizer; // Temporarily disabled due to threading issues
pub mod test_module;
pub mod visualization;
use ::rand::{prelude::SliceRandom, thread_rng, Rng};
use numpy::{IntoPyArray, PyArrayDyn, PyReadonlyArrayDyn};
use pyo3::exceptions::{PyIndexError, PyNotImplementedError, PyRuntimeError, PyValueError};
use pyo3::prelude::*;
use pyo3::types::{PyDict, PyList, PySlice, PyTuple, PyType};
use pyo3::Bound;
use std::collections::HashMap;
use std::sync::Arc;
use std::sync::{OnceLock, RwLock};
use tenflowers_autograd::{
    no_grad::{is_grad_enabled as autograd_is_grad_enabled, EnableGradGuard, NoGradGuard},
    GradientTape, TrackedTensor,
};
use tenflowers_core::collective::{
    all_reduce_gradients, create_process_group, init_collective, ring_all_reduce, sync_parameters,
    ReductionOp,
};
use tenflowers_core::device::context::DEVICE_MANAGER;
use tenflowers_core::ops::{manipulation::cast, manipulation::transpose_axes, random, special};
use tenflowers_core::quantization::{
    dequantize, dynamic_quantize, fake_quantize, per_channel_quantize, quantize, QuantizationParams,
};
use tenflowers_core::{memory::global_monitor, DType, Device, Tensor};
use tenflowers_dataset::transforms::{
    BackTranslation, RandomHorizontalFlip, TokenReplacement, TokenShuffle,
    Transform as DatasetTransform, WordDropout,
};
use tenflowers_dataset::{
    DataLoaderConfig, DistributedSampler, ImportanceSampler, RandomSampler, Sampler,
    SequentialSampler, StratifiedSampler,
};
use tenflowers_neural::layers::embedding::{
    Embedding, LearnedPositionalEncoding, RotaryPositionalEmbedding, SinusoidalPositionalEncoding,
};
use tenflowers_neural::layers::{
    Activation, AvgPool2D, BatchNorm, Conv1D, Conv2D, Conv3D, ConvTranspose2D, GlobalAvgPool2D,
    GlobalMaxPool2D, MaxPool2D, MultiHeadAttention, TransformerDecoder, TransformerEncoder, GRU,
    LSTM, RNN,
};
use tenflowers_neural::loss::{
    cosine_embedding_loss as cosine_embedding_loss_impl, kl_div_loss as kl_div_loss_impl,
    l1_loss as l1_loss_impl, nll_loss as nll_loss_impl, smooth_l1_loss as smooth_l1_loss_impl,
    triplet_loss,
};
use tenflowers_neural::model::{FunctionalModel, FunctionalModelBuilder, Input, Node, SharedLayer};
use tenflowers_neural::optimizers::{
    parameter_groups::{ParameterGroupConfig, ParameterGroupOptimizer},
    Adagrad, Adam, AdamW, RMSprop, SGD,
};
use tenflowers_neural::pretrained::{EfficientNet, ResNet};
use tenflowers_neural::scheduler::{
    ConstantLR, CosineAnnealingLR, ExponentialLR, LearningRateScheduler, OneCycleLR, PlateauMode,
    PolynomialLR, ReduceLROnPlateau, StepLR, WarmupCosineDecayLR,
};
#[cfg(feature = "tensorboard")]
use tenflowers_neural::trainer::TensorboardCallback;
use tenflowers_neural::trainer::{
    Callback, CallbackAction, EarlyStopping, LearningRateReduction, ModelCheckpoint, Trainer,
    TrainingMetrics, TrainingState,
};
use tenflowers_neural::Model;
use tenflowers_neural::{
    binary_cross_entropy, categorical_cross_entropy, focal_loss as focal_loss_impl,
    hinge_loss as hinge_loss_impl, huber_loss as huber_loss_impl, mse,
    quantile_loss as quantile_loss_impl, sparse_categorical_cross_entropy, Dense, Layer,
};

// Global default device management
static DEFAULT_DEVICE: OnceLock<RwLock<Device>> = OnceLock::new();

fn get_default_device_lock() -> &'static RwLock<Device> {
    DEFAULT_DEVICE.get_or_init(|| RwLock::new(Device::Cpu))
}

// Memory profiling state
#[derive(Debug, Clone, Default)]
struct MemoryProfilingState {
    is_profiling: bool,
    start_time: Option<std::time::Instant>,
    peak_memory: usize,
    total_allocations: usize,
    total_deallocations: usize,
    initial_memory: usize,
}

static MEMORY_PROFILING: OnceLock<RwLock<MemoryProfilingState>> = OnceLock::new();

fn get_memory_profiling_lock() -> &'static RwLock<MemoryProfilingState> {
    MEMORY_PROFILING.get_or_init(|| RwLock::new(MemoryProfilingState::default()))
}

// Helper enum for advanced indexing with ellipsis and newaxis support
#[derive(Clone)]
enum IndexItem {
    Index(i32),
    Slice(SliceInfo),
    Ellipsis,
    NewAxis,
}

// Store slice information for processing
#[derive(Clone)]
struct SliceInfo {
    start: Option<isize>,
    stop: Option<isize>,
    step: Option<isize>,
}

#[pyclass]
#[derive(Clone)]
pub struct PyTensor {
    inner: Tensor<f32>,
}

#[pymethods]
impl PyTensor {
    #[new]
    fn new(shape: Vec<usize>) -> Self {
        Self {
            inner: Tensor::zeros(&shape),
        }
    }

    // Properties
    fn shape(&self) -> Vec<usize> {
        self.inner.shape().dims().to_vec()
    }

    fn ndim(&self) -> usize {
        self.inner.ndim()
    }

    fn size(&self) -> usize {
        self.inner.size()
    }

    fn numel(&self) -> usize {
        self.inner.numel()
    }

    fn requires_grad(&self) -> bool {
        self.inner.requires_grad()
    }

    fn set_requires_grad(&mut self, requires_grad: bool) {
        self.inner.set_requires_grad(requires_grad);
    }

    fn is_scalar(&self) -> bool {
        self.inner.is_scalar()
    }

    fn is_vector(&self) -> bool {
        self.inner.is_vector()
    }

    fn is_matrix(&self) -> bool {
        self.inner.is_matrix()
    }

    fn dtype(&self) -> String {
        // Enhanced dtype detection with future extensibility
        // Currently TenfloweRS tensors are primarily f32-based
        // When multi-dtype support is added, this will use self.inner.dtype()
        match std::any::TypeId::of::<f32>() {
            id if id == std::any::TypeId::of::<f32>() => "float32".to_string(),
            id if id == std::any::TypeId::of::<f64>() => "float64".to_string(),
            id if id == std::any::TypeId::of::<i32>() => "int32".to_string(),
            id if id == std::any::TypeId::of::<i64>() => "int64".to_string(),
            _ => {
                // Fallback for current implementation - all tensors are f32
                "float32".to_string()
            }
        }
    }

    #[getter]
    fn T(&self) -> PyResult<PyTensor> {
        self.transpose(None)
    }

    // Get the NumPy dtype string
    fn numpy_dtype(&self) -> String {
        match self.dtype().as_str() {
            "float32" => "<f4".to_string(), // little-endian float32
            "float64" => "<f8".to_string(), // little-endian float64
            "int32" => "<i4".to_string(),   // little-endian int32
            "int64" => "<i8".to_string(),   // little-endian int64
            "bool" => "|b1".to_string(),    // boolean
            _ => "<f4".to_string(),         // default to float32
        }
    }

    fn is_contiguous(&self) -> bool {
        // For CPU tensors, check if we can get a slice (indicates contiguous memory)
        // For GPU tensors, assume contiguous for now
        match &self.inner.storage {
            tenflowers_core::tensor::TensorStorage::Cpu(array) => array.is_standard_layout(),
            #[cfg(feature = "gpu")]
            tenflowers_core::tensor::TensorStorage::Gpu(_) => {
                // GPU tensors are typically contiguous
                true
            }
        }
    }

    // Additional memory layout information
    fn is_c_contiguous(&self) -> bool {
        self.is_contiguous()
    }

    fn is_f_contiguous(&self) -> bool {
        // For now, we only support C-contiguous arrays
        false
    }

    fn is_fortran_contiguous(&self) -> bool {
        self.is_f_contiguous()
    }

    fn strides(&self) -> Vec<usize> {
        // Calculate strides from shape (row-major order)
        let shape = self.shape();
        if shape.is_empty() {
            return vec![];
        }

        let mut strides = vec![0; shape.len()];
        let mut stride = 1;

        // Calculate strides in reverse order (row-major)
        for i in (0..shape.len()).rev() {
            strides[i] = stride;
            stride *= shape[i];
        }

        strides
    }

    fn itemsize(&self) -> usize {
        // Size of f32 in bytes
        std::mem::size_of::<f32>()
    }

    fn nbytes(&self) -> usize {
        // Total number of bytes
        self.numel() * self.itemsize()
    }

    // Enhanced memory layout information
    fn memory_format(&self) -> String {
        // Return memory format string
        if self.is_c_contiguous() {
            "contiguous".to_string()
        } else if self.is_f_contiguous() {
            "fortran_contiguous".to_string()
        } else {
            "non_contiguous".to_string()
        }
    }

    fn storage_offset(&self) -> usize {
        // For now, always return 0 since we don't support storage offsets
        0
    }

    fn element_size(&self) -> usize {
        // Same as itemsize, but with different name for compatibility
        self.itemsize()
    }

    fn layout(&self) -> String {
        // Detailed layout information
        format!(
            "Layout(shape={:?}, strides={:?}, dtype={}, format={})",
            self.shape(),
            self.strides(),
            self.dtype(),
            self.memory_format()
        )
    }

    fn is_pinned(&self) -> bool {
        // For now, return false as pinned memory is not implemented
        false
    }

    fn data_ptr(&self) -> PyResult<usize> {
        // Return data pointer address (for debugging/introspection)
        match &self.inner.storage {
            tenflowers_core::tensor::TensorStorage::Cpu(arr) => {
                if let Some(slice) = arr.as_slice() {
                    Ok(slice.as_ptr() as usize)
                } else {
                    Err(PyErr::new::<PyRuntimeError, _>("Tensor is not contiguous"))
                }
            }
            #[cfg(feature = "gpu")]
            tenflowers_core::tensor::TensorStorage::Gpu(_) => Err(PyErr::new::<PyRuntimeError, _>(
                "GPU tensors do not expose data pointers",
            )),
        }
    }

    // Arithmetic Operations
    fn add(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.add(&other.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn sub(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.sub(&other.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn mul(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.mul(&other.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn div(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.div(&other.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn pow(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.pow(&other.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn neg(&self) -> PyResult<PyTensor> {
        match self.inner.neg() {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Comparison Operations
    fn eq(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.eq(&other.inner) {
            Ok(result) => {
                // Convert bool tensor to f32 for consistency
                let f32_result = convert_bool_to_f32_tensor(result)?;
                Ok(PyTensor { inner: f32_result })
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn ne(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.ne(&other.inner) {
            Ok(result) => {
                let f32_result = convert_bool_to_f32_tensor(result)?;
                Ok(PyTensor { inner: f32_result })
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn gt(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.gt(&other.inner) {
            Ok(result) => {
                let f32_result = convert_bool_to_f32_tensor(result)?;
                Ok(PyTensor { inner: f32_result })
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn ge(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.ge(&other.inner) {
            Ok(result) => {
                let f32_result = convert_bool_to_f32_tensor(result)?;
                Ok(PyTensor { inner: f32_result })
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn lt(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.lt(&other.inner) {
            Ok(result) => {
                let f32_result = convert_bool_to_f32_tensor(result)?;
                Ok(PyTensor { inner: f32_result })
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn le(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.le(&other.inner) {
            Ok(result) => {
                let f32_result = convert_bool_to_f32_tensor(result)?;
                Ok(PyTensor { inner: f32_result })
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Mathematical Functions
    fn sqrt(&self) -> PyResult<PyTensor> {
        match self.inner.sqrt() {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn abs(&self) -> PyResult<PyTensor> {
        match self.inner.abs() {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn exp(&self) -> PyResult<PyTensor> {
        match self.inner.exp() {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn log(&self) -> PyResult<PyTensor> {
        match self.inner.log() {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn sin(&self) -> PyResult<PyTensor> {
        match self.inner.sin() {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn cos(&self) -> PyResult<PyTensor> {
        match self.inner.cos() {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Special Mathematical Functions
    fn erf(&self) -> PyResult<PyTensor> {
        match special::erf(&self.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn erfc(&self) -> PyResult<PyTensor> {
        match special::erfc(&self.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn gamma(&self) -> PyResult<PyTensor> {
        match special::gamma(&self.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn lgamma(&self) -> PyResult<PyTensor> {
        match special::lgamma(&self.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn digamma(&self) -> PyResult<PyTensor> {
        match special::digamma(&self.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn bessel_j0(&self) -> PyResult<PyTensor> {
        match special::bessel_j0(&self.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn bessel_j1(&self) -> PyResult<PyTensor> {
        match special::bessel_j1(&self.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn bessel_y0(&self) -> PyResult<PyTensor> {
        match special::bessel_y0(&self.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn bessel_y1(&self) -> PyResult<PyTensor> {
        match special::bessel_y1(&self.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Reduction Operations
    #[pyo3(signature = (axes=None, keepdims=None))]
    fn sum(&self, axes: Option<Vec<i32>>, keepdims: Option<bool>) -> PyResult<PyTensor> {
        let axes_ref = axes.as_deref();
        let keepdims = keepdims.unwrap_or(false);
        match self.inner.sum(axes_ref, keepdims) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    #[pyo3(signature = (axes=None, keepdims=None))]
    fn mean(&self, axes: Option<Vec<i32>>, keepdims: Option<bool>) -> PyResult<PyTensor> {
        let axes_ref = axes.as_deref();
        let keepdims = keepdims.unwrap_or(false);
        match self.inner.mean(axes_ref, keepdims) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    #[pyo3(signature = (axes=None, keepdims=None))]
    fn max(&self, axes: Option<Vec<i32>>, keepdims: Option<bool>) -> PyResult<PyTensor> {
        let axes_ref = axes.as_deref();
        let keepdims = keepdims.unwrap_or(false);
        match self.inner.max(axes_ref, keepdims) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    #[pyo3(signature = (axes=None, keepdims=None))]
    fn min(&self, axes: Option<Vec<i32>>, keepdims: Option<bool>) -> PyResult<PyTensor> {
        let axes_ref = axes.as_deref();
        let keepdims = keepdims.unwrap_or(false);
        match self.inner.min(axes_ref, keepdims) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Tensor Manipulation
    fn reshape(&self, shape: Vec<usize>) -> PyResult<PyTensor> {
        match self.inner.reshape(&shape) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    #[pyo3(signature = (axes=None))]
    fn transpose(&self, axes: Option<Vec<usize>>) -> PyResult<PyTensor> {
        let result = if let Some(axes) = axes {
            transpose_axes(&self.inner, Some(&axes))
        } else {
            self.inner.transpose()
        };

        match result {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    #[pyo3(signature = (axes=None))]
    fn squeeze(&self, axes: Option<Vec<usize>>) -> PyResult<PyTensor> {
        let axes_ref = axes.as_deref();
        match self.inner.squeeze(axes_ref) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn unsqueeze(&self, axes: Vec<usize>) -> PyResult<PyTensor> {
        match self.inner.unsqueeze(&axes) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // NumPy-style copy method
    fn copy(&self) -> PyTensor {
        PyTensor {
            inner: self.inner.clone(),
        }
    }

    // NumPy-style astype method (currently limited to float32)
    fn astype(&self, dtype: &str) -> PyResult<PyTensor> {
        match dtype {
            "float32" | "f4" | "<f4" => Ok(self.copy()),
            _ => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Data type '{dtype}' not supported yet. Currently only float32 is supported."
            ))),
        }
    }

    // Linear Algebra
    fn matmul(&self, other: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.matmul(&other.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Autograd
    #[pyo3(signature = (retain_graph=None, create_graph=None))]
    fn backward(&self, retain_graph: Option<bool>, create_graph: Option<bool>) -> PyResult<()> {
        // Enhanced parameter validation and warnings
        let retain_graph_val = retain_graph.unwrap_or(false);
        let create_graph_val = create_graph.unwrap_or(false);

        // Warn users about unsupported features for better UX
        if retain_graph_val {
            eprintln!("Warning: retain_graph=True is not yet supported in TenfloweRS autograd. Using default behavior.");
        }
        if create_graph_val {
            eprintln!("Warning: create_graph=True is not yet supported in TenfloweRS autograd. Using default behavior.");
        }

        match self.inner.backward() {
            Ok(()) => Ok(()),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn grad(&self) -> Option<PyTensor> {
        self.inner.grad().map(|g| PyTensor { inner: g.clone() })
    }

    // Device Management
    fn device(&self) -> String {
        self.inner.device().to_string()
    }

    fn is_cpu(&self) -> bool {
        self.inner.device().is_cpu()
    }

    #[cfg(feature = "gpu")]
    fn is_gpu(&self) -> bool {
        self.inner.device().is_gpu()
    }

    fn to_device(&self, device: &str) -> PyResult<PyTensor> {
        let target_device = parse_device_string(device)?;
        match self.inner.to(target_device) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn cpu(&self) -> PyResult<PyTensor> {
        self.to_device("cpu")
    }

    #[cfg(feature = "gpu")]
    fn cuda(&self, device_id: Option<usize>) -> PyResult<PyTensor> {
        let device_id = device_id.unwrap_or(0);
        self.to_device(&format!("gpu:{}", device_id))
    }

    // Python operator overloads
    fn __add__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.add(other)
    }

    fn __sub__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.sub(other)
    }

    fn __mul__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.mul(other)
    }

    fn __truediv__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.div(other)
    }

    fn __pow__(&self, other: &PyTensor, _mod: Option<PyObject>) -> PyResult<PyTensor> {
        self.pow(other)
    }

    fn __neg__(&self) -> PyResult<PyTensor> {
        self.neg()
    }

    fn __eq__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.eq(other)
    }

    fn __ne__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.ne(other)
    }

    fn __lt__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.lt(other)
    }

    fn __le__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.le(other)
    }

    fn __gt__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.gt(other)
    }

    fn __ge__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.ge(other)
    }

    // NumPy compatibility
    fn to_numpy<'py>(&self, py: Python<'py>) -> PyResult<Bound<'py, PyArrayDyn<f32>>> {
        match &self.inner.storage {
            tenflowers_core::tensor::TensorStorage::Cpu(arr) => Ok(arr.clone().into_pyarray(py)),
            #[cfg(feature = "gpu")]
            tenflowers_core::tensor::TensorStorage::Gpu(_) => {
                // Convert GPU tensor to CPU first
                let cpu_tensor = self.inner.to(Device::Cpu).map_err(|e| {
                    PyErr::new::<PyRuntimeError, _>(format!(
                        "Failed to convert GPU tensor to CPU: {}",
                        e
                    ))
                })?;
                match cpu_tensor.storage {
                    tenflowers_core::tensor::TensorStorage::Cpu(arr) => {
                        Ok(arr.into_pyarray_bound(py))
                    }
                    _ => Err(PyErr::new::<PyRuntimeError, _>(
                        "Unexpected storage type after CPU conversion",
                    )),
                }
            }
        }
    }

    fn numpy(&self, py: Python) -> PyResult<PyObject> {
        #[allow(deprecated)]
        let result = self.to_numpy(py).map(|arr| arr.into_py(py));
        result
    }

    // NumPy array interface
    fn __array__<'py>(&self, py: Python<'py>) -> PyResult<Bound<'py, PyArrayDyn<f32>>> {
        self.to_numpy(py)
    }

    // Array priority for operator precedence with NumPy
    fn __array_priority__(&self) -> f64 {
        1000.0 // Higher than NumPy's default (0.0) to ensure our operations take precedence
    }

    // Array wrap for ufunc output
    fn __array_wrap__(&self, result: PyObject) -> PyResult<PyTensor> {
        Python::with_gil(|py| {
            let bound_result = result.bind(py);

            // Try to extract as numpy array and convert back to PyTensor
            if let Ok(array) = bound_result.extract::<PyReadonlyArrayDyn<f32>>() {
                let ndarray = array.as_array();
                let owned_array = ndarray.to_owned();
                Ok(PyTensor {
                    inner: Tensor::from_array(owned_array),
                })
            } else {
                Err(PyErr::new::<PyRuntimeError, _>(
                    "Cannot wrap non-array result",
                ))
            }
        })
    }

    // Array function protocol for NumPy compatibility
    fn __array_function__(
        &self,
        _func: PyObject,
        _types: PyObject,
        _args: PyObject,
        _kwargs: PyObject,
    ) -> PyResult<PyObject> {
        Python::with_gil(|py| {
            // For now, return NotImplemented to let NumPy handle the function
            // In a full implementation, we would check the function name and
            // implement tensor-specific versions of common NumPy functions
            let not_implemented = py.NotImplemented();
            Ok(not_implemented)
        })
    }

    fn __array_interface__(&self, py: Python) -> PyResult<PyObject> {
        let dict = PyDict::new(py);

        // Shape
        let shape_tuple = PyTuple::new(py, self.shape())?;
        dict.set_item("shape", &shape_tuple)?;

        // Strides (in bytes)
        let strides: Vec<usize> = self
            .strides()
            .iter()
            .map(|&s| s * self.itemsize())
            .collect();
        let strides_tuple = PyTuple::new(py, strides)?;
        dict.set_item("strides", &strides_tuple)?;

        // Type descriptor
        dict.set_item("typestr", self.numpy_dtype())?;

        // Version
        dict.set_item("version", 3)?;

        // Data pointer and read-only flag
        match &self.inner.storage {
            tenflowers_core::tensor::TensorStorage::Cpu(arr) => {
                if let Some(slice) = arr.as_slice() {
                    let ptr = slice.as_ptr() as usize;
                    let readonly = 0usize; // false as usize
                    let data_tuple = PyTuple::new(py, [ptr, readonly])?;
                    dict.set_item("data", &data_tuple)?;
                } else {
                    return Err(PyErr::new::<PyRuntimeError, _>("Tensor is not contiguous"));
                }
            }
            #[cfg(feature = "gpu")]
            tenflowers_core::tensor::TensorStorage::Gpu(_) => {
                return Err(PyErr::new::<PyRuntimeError, _>(
                    "GPU tensors cannot expose raw pointer",
                ));
            }
        }

        Ok(dict.into())
    }

    // String representation
    fn __str__(&self) -> String {
        format!(
            "PyTensor(shape={:?}, device={:?})",
            self.shape(),
            self.inner.device()
        )
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }

    // Indexing and Slicing - Advanced implementation
    fn __getitem__(&self, key: PyObject) -> PyResult<PyTensor> {
        Python::with_gil(|py| {
            let bound_key = key.bind(py);

            // Handle different indexing types
            if let Ok(index) = bound_key.extract::<i32>() {
                // Single integer index
                let shape = self.shape();
                if shape.is_empty() {
                    return Err(PyErr::new::<PyIndexError, _>("Cannot index scalar tensor"));
                }

                // Handle negative indexing
                let positive_index = if index < 0 {
                    (shape[0] as i32 + index) as usize
                } else {
                    index as usize
                };

                return self.index_single_dimension(positive_index);
            }

            if let Ok(slice) = bound_key.downcast::<PySlice>() {
                // Single slice object
                return self.slice_single_dimension(slice);
            }

            if let Ok(tuple) = bound_key.downcast::<PyTuple>() {
                // Tuple of indices and slices
                return self.advanced_indexing(tuple);
            }

            if let Ok(list) = bound_key.downcast::<PyList>() {
                // List indexing (boolean or integer array)
                return self.array_indexing(list);
            }

            if let Ok(tensor) = bound_key.extract::<PyTensor>() {
                // Tensor indexing (boolean or integer array)
                return self.tensor_indexing(&tensor);
            }

            Err(PyErr::new::<PyIndexError, _>("Unsupported indexing type"))
        })
    }

    fn __setitem__(&mut self, key: PyObject, value: &PyTensor) -> PyResult<()> {
        Python::with_gil(|py| {
            let bound_key = key.bind(py);

            // Handle different indexing types for assignment
            if let Ok(index) = bound_key.extract::<i32>() {
                // Single integer index assignment
                return self.assign_single_index(index, value);
            }

            if let Ok(slice) = bound_key.downcast::<PySlice>() {
                // Single slice assignment
                return self.assign_slice(slice, value);
            }

            if let Ok(tuple) = bound_key.downcast::<PyTuple>() {
                // Tuple indexing assignment
                return self.assign_tuple_index(tuple, value);
            }

            if let Ok(list) = bound_key.downcast::<PyList>() {
                // List indexing assignment
                return self.assign_list_index(list, value);
            }

            if let Ok(tensor) = bound_key.extract::<PyTensor>() {
                // Tensor indexing assignment
                return self.assign_tensor_index(&tensor, value);
            }

            Err(PyErr::new::<PyIndexError, _>(
                "Unsupported indexing type for assignment",
            ))
        })
    }

    // In-place Operations
    fn iadd(&mut self, other: &PyTensor) -> PyResult<()> {
        // For now, use the out-of-place operations and replace the tensor
        // This is a temporary approach until proper in-place operations are available in core
        let result = self.add(other)?;
        self.inner = result.inner;
        Ok(())
    }

    fn isub(&mut self, other: &PyTensor) -> PyResult<()> {
        let result = self.sub(other)?;
        self.inner = result.inner;
        Ok(())
    }

    fn imul(&mut self, other: &PyTensor) -> PyResult<()> {
        let result = self.mul(other)?;
        self.inner = result.inner;
        Ok(())
    }

    fn itruediv(&mut self, other: &PyTensor) -> PyResult<()> {
        let result = self.div(other)?;
        self.inner = result.inner;
        Ok(())
    }

    fn ipow(&mut self, other: &PyTensor) -> PyResult<()> {
        let result = self.pow(other)?;
        self.inner = result.inner;
        Ok(())
    }

    // Python operator overloads for in-place operations
    fn __iadd__(&mut self, other: &PyTensor) -> PyResult<()> {
        self.iadd(other)
    }

    fn __isub__(&mut self, other: &PyTensor) -> PyResult<()> {
        self.isub(other)
    }

    fn __imul__(&mut self, other: &PyTensor) -> PyResult<()> {
        self.imul(other)
    }

    fn __itruediv__(&mut self, other: &PyTensor) -> PyResult<()> {
        self.itruediv(other)
    }

    fn __ipow__(&mut self, other: &PyTensor, _modulus: Option<PyObject>) -> PyResult<()> {
        self.ipow(other)
    }

    // Logical Operations
    fn logical_and(&self, other: &PyTensor) -> PyResult<PyTensor> {
        // Convert f32 tensors to bool tensors for logical operations
        let self_bool = convert_f32_to_bool_tensor(&self.inner)?;
        let other_bool = convert_f32_to_bool_tensor(&other.inner)?;

        match self_bool.logical_and(&other_bool) {
            Ok(result) => {
                let f32_result = convert_bool_to_f32_tensor(result)?;
                Ok(PyTensor { inner: f32_result })
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn logical_or(&self, other: &PyTensor) -> PyResult<PyTensor> {
        let self_bool = convert_f32_to_bool_tensor(&self.inner)?;
        let other_bool = convert_f32_to_bool_tensor(&other.inner)?;

        match self_bool.logical_or(&other_bool) {
            Ok(result) => {
                let f32_result = convert_bool_to_f32_tensor(result)?;
                Ok(PyTensor { inner: f32_result })
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn logical_not(&self) -> PyResult<PyTensor> {
        let self_bool = convert_f32_to_bool_tensor(&self.inner)?;

        match self_bool.logical_not() {
            Ok(result) => {
                let f32_result = convert_bool_to_f32_tensor(result)?;
                Ok(PyTensor { inner: f32_result })
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn logical_xor(&self, other: &PyTensor) -> PyResult<PyTensor> {
        let self_bool = convert_f32_to_bool_tensor(&self.inner)?;
        let other_bool = convert_f32_to_bool_tensor(&other.inner)?;

        match self_bool.logical_xor(&other_bool) {
            Ok(result) => {
                let f32_result = convert_bool_to_f32_tensor(result)?;
                Ok(PyTensor { inner: f32_result })
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Python operator overloads for logical operations
    fn __and__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.logical_and(other)
    }

    fn __or__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.logical_or(other)
    }

    fn __invert__(&self) -> PyResult<PyTensor> {
        self.logical_not()
    }

    fn __xor__(&self, other: &PyTensor) -> PyResult<PyTensor> {
        self.logical_xor(other)
    }

    // Helper method for single dimension indexing
    fn index_single_dimension(&self, index: usize) -> PyResult<PyTensor> {
        let shape = self.shape();
        if shape.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>("Cannot index scalar tensor"));
        }

        if index >= shape[0] {
            return Err(PyErr::new::<PyIndexError, _>(format!(
                "Index {} out of range for dimension of size {}",
                index, shape[0]
            )));
        }

        // Create range for first dimension only
        #[allow(clippy::single_range_in_vec_init)]
        let mut ranges = vec![index..index + 1];

        // Add full ranges for remaining dimensions
        #[allow(clippy::needless_range_loop)]
        for i in 1..shape.len() {
            ranges.push(0..shape[i]);
        }

        match self.inner.slice(&ranges) {
            Ok(result) => {
                // Remove the indexed dimension by reshaping
                let new_shape: Vec<usize> = shape[1..].to_vec();
                if new_shape.is_empty() {
                    // Result is a scalar
                    Ok(PyTensor { inner: result })
                } else {
                    match result.reshape(&new_shape) {
                        Ok(reshaped) => Ok(PyTensor { inner: reshaped }),
                        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    }
                }
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Helper method for single dimension slicing
    fn slice_single_dimension(&self, slice: &Bound<'_, PySlice>) -> PyResult<PyTensor> {
        let shape = self.shape();
        if shape.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>("Cannot slice scalar tensor"));
        }

        let dim_size = shape[0] as isize;
        let indices = slice
            .indices(dim_size)
            .map_err(|e| PyErr::new::<PyIndexError, _>(format!("Invalid slice: {e}")))?;

        let start = indices.start as usize;
        let stop = indices.stop as usize;
        let step = indices.step;

        if step != 1 {
            // Implement step slicing
            return self.step_slice_single_dimension(start, stop, step);
        }

        // Create ranges for slicing
        #[allow(clippy::single_range_in_vec_init)]
        let mut ranges = vec![start..stop];
        #[allow(clippy::needless_range_loop)]
        for i in 1..shape.len() {
            ranges.push(0..shape[i]);
        }

        match self.inner.slice(&ranges) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Helper method for advanced indexing with tuples
    fn advanced_indexing(&self, tuple: &Bound<'_, PyTuple>) -> PyResult<PyTensor> {
        let shape = self.shape();

        // First pass: parse indices and count newaxis/ellipsis
        let mut index_items = Vec::new();
        let mut ellipsis_count = 0;
        let mut newaxis_count = 0;

        for item in tuple.iter() {
            if item.is_ellipsis() {
                ellipsis_count += 1;
                if ellipsis_count > 1 {
                    return Err(PyErr::new::<PyIndexError, _>(
                        "Only one ellipsis (...) allowed in indexing",
                    ));
                }
                index_items.push(IndexItem::Ellipsis);
            } else if item.is_none() {
                // newaxis (None)
                newaxis_count += 1;
                index_items.push(IndexItem::NewAxis);
            } else if let Ok(index) = item.extract::<i32>() {
                index_items.push(IndexItem::Index(index));
            } else if let Ok(slice) = item.downcast::<PySlice>() {
                // Extract slice information
                let slice_info = SliceInfo {
                    start: slice.getattr("start").ok().and_then(|s| s.extract().ok()),
                    stop: slice.getattr("stop").ok().and_then(|s| s.extract().ok()),
                    step: slice.getattr("step").ok().and_then(|s| s.extract().ok()),
                };
                index_items.push(IndexItem::Slice(slice_info));
            } else {
                return Err(PyErr::new::<PyIndexError, _>(
                    "Unsupported indexing item in tuple",
                ));
            }
        }

        // Count non-newaxis indices to check tensor dimensionality
        let non_newaxis_indices = index_items
            .iter()
            .filter(|item| !matches!(item, IndexItem::NewAxis))
            .count();

        // Calculate how many dimensions ellipsis should expand to
        let basic_indices_count = index_items
            .iter()
            .filter(|item| matches!(item, IndexItem::Index(_) | IndexItem::Slice(_)))
            .count();

        if basic_indices_count > shape.len() {
            return Err(PyErr::new::<PyIndexError, _>("Too many indices for tensor"));
        }

        // Expand ellipsis to slices for missing dimensions
        let ellipsis_expansion_count = if ellipsis_count > 0 {
            shape.len().saturating_sub(basic_indices_count)
        } else {
            0
        };

        // Second pass: process indices with ellipsis expanded
        let mut slice_params = Vec::new();
        let mut new_shape = Vec::new();
        let mut tensor_dim_idx = 0;

        for item in &index_items {
            match item {
                IndexItem::Index(index) => {
                    if tensor_dim_idx >= shape.len() {
                        return Err(PyErr::new::<PyIndexError, _>(
                            "Index out of range for tensor dimensions",
                        ));
                    }

                    let positive_index = if *index < 0 {
                        (shape[tensor_dim_idx] as i32 + index) as isize
                    } else {
                        *index as isize
                    };

                    if positive_index < 0 || positive_index >= shape[tensor_dim_idx] as isize {
                        return Err(PyErr::new::<PyIndexError, _>(format!(
                            "Index {} out of range for dimension {} of size {}",
                            index, tensor_dim_idx, shape[tensor_dim_idx]
                        )));
                    }

                    // Create a slice that selects a single index
                    let index_slice = tenflowers_core::SliceParams::with_step(
                        Some(positive_index),
                        Some(positive_index + 1),
                        Some(1),
                    );
                    slice_params.push(index_slice);
                    tensor_dim_idx += 1;
                    // Don't add to new_shape as this dimension is indexed out
                }
                IndexItem::Slice(slice_info) => {
                    if tensor_dim_idx >= shape.len() {
                        return Err(PyErr::new::<PyIndexError, _>(
                            "Slice out of range for tensor dimensions",
                        ));
                    }

                    let dim_size = shape[tensor_dim_idx] as isize;

                    // Process slice info similar to PySlice.indices()
                    let start = slice_info.start;
                    let stop = slice_info.stop;
                    let step = slice_info.step;

                    // Create SliceParams for step slicing support
                    let slice_param = tenflowers_core::SliceParams::with_step(start, stop, step);

                    // Normalize the slice parameters to get the actual output size
                    let (norm_start, norm_stop, norm_step) =
                        match slice_param.normalize(shape[tensor_dim_idx]) {
                            Ok(result) => result,
                            Err(e) => {
                                return Err(PyErr::new::<PyIndexError, _>(format!(
                                    "Invalid slice: {}",
                                    e
                                )))
                            }
                        };

                    // Calculate the resulting size after step slicing
                    let slice_size = if norm_step > 0 && norm_stop > norm_start {
                        ((norm_stop - norm_start) as isize + norm_step - 1) / norm_step
                    } else if norm_step < 0 && norm_start > norm_stop {
                        ((norm_start - norm_stop) as isize + (-norm_step) - 1) / (-norm_step)
                    } else {
                        0
                    };

                    slice_params.push(slice_param);
                    new_shape.push(slice_size as usize);
                    tensor_dim_idx += 1;
                }
                IndexItem::Ellipsis => {
                    // Expand ellipsis to full slices for missing dimensions
                    for _ in 0..ellipsis_expansion_count {
                        if tensor_dim_idx >= shape.len() {
                            break;
                        }
                        // Create a full slice for this dimension
                        let full_slice = tenflowers_core::SliceParams::with_step(
                            Some(0),
                            Some(shape[tensor_dim_idx] as isize),
                            Some(1),
                        );
                        slice_params.push(full_slice);
                        new_shape.push(shape[tensor_dim_idx]);
                        tensor_dim_idx += 1;
                    }
                }
                IndexItem::NewAxis => {
                    // NewAxis adds a dimension of size 1 - handle in final reshape
                    new_shape.push(1);
                }
            }
        }

        // Add remaining dimensions as full slices if no ellipsis was used
        if ellipsis_count == 0 {
            while tensor_dim_idx < shape.len() {
                let full_slice = tenflowers_core::SliceParams::with_step(
                    Some(0),
                    Some(shape[tensor_dim_idx] as isize),
                    Some(1),
                );
                slice_params.push(full_slice);
                new_shape.push(shape[tensor_dim_idx]);
                tensor_dim_idx += 1;
            }
        }

        // Perform the slicing operation on the tensor with step support
        let sliced_result = match self.inner.slice_with_stride(&slice_params) {
            Ok(result) => result,
            Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        };

        // If we have newaxis dimensions, we need to properly handle them
        // by inserting dimensions of size 1 at the correct positions
        let final_result = if newaxis_count > 0 {
            // Build the correct final shape by processing the index items again
            let mut final_shape = Vec::new();
            let mut sliced_shape_idx = 0;
            let sliced_shape = sliced_result.shape().dims();

            for item in &index_items {
                match item {
                    IndexItem::Index(_) => {
                        // Index removes a dimension, don't add to final shape
                        // but advance sliced_shape_idx if this wasn't indexed out
                    }
                    IndexItem::Slice(_) => {
                        if sliced_shape_idx < sliced_shape.len() {
                            final_shape.push(sliced_shape[sliced_shape_idx]);
                            sliced_shape_idx += 1;
                        }
                    }
                    IndexItem::Ellipsis => {
                        // Add the expanded dimensions
                        for _ in 0..ellipsis_expansion_count {
                            if sliced_shape_idx < sliced_shape.len() {
                                final_shape.push(sliced_shape[sliced_shape_idx]);
                                sliced_shape_idx += 1;
                            }
                        }
                    }
                    IndexItem::NewAxis => {
                        final_shape.push(1);
                    }
                }
            }

            // Add any remaining dimensions from the sliced result
            while sliced_shape_idx < sliced_shape.len() {
                final_shape.push(sliced_shape[sliced_shape_idx]);
                sliced_shape_idx += 1;
            }

            match sliced_result.reshape(&final_shape) {
                Ok(reshaped) => reshaped,
                Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
            }
        } else {
            sliced_result
        };

        Ok(PyTensor {
            inner: final_result,
        })
    }

    // Helper method for array-based indexing
    fn array_indexing(&self, list: &Bound<'_, PyList>) -> PyResult<PyTensor> {
        if list.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>(
                "Empty list cannot be used for indexing",
            ));
        }

        let shape = self.shape();
        if shape.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>("Cannot index scalar tensor"));
        }

        // Try to parse as boolean array first
        let mut is_bool = true;
        let mut bool_indices = Vec::new();
        for item in list.iter() {
            if let Ok(val) = item.extract::<bool>() {
                bool_indices.push(val);
            } else {
                is_bool = false;
                break;
            }
        }

        if is_bool {
            return self.boolean_array_indexing(&bool_indices);
        }

        // Try to parse as integer array
        let mut integer_indices = Vec::new();
        for item in list.iter() {
            if let Ok(val) = item.extract::<i32>() {
                // Handle negative indices
                let positive_idx = if val < 0 {
                    (shape[0] as i32 + val) as usize
                } else {
                    val as usize
                };

                if positive_idx >= shape[0] {
                    return Err(PyErr::new::<PyIndexError, _>(format!(
                        "Index {} out of range for dimension of size {}",
                        val, shape[0]
                    )));
                }

                integer_indices.push(positive_idx);
            } else {
                return Err(PyErr::new::<PyIndexError, _>(
                    "List elements must be boolean or integer",
                ));
            }
        }

        self.integer_array_indexing(&integer_indices)
    }

    // Helper method for tensor-based indexing
    fn tensor_indexing(&self, index_tensor: &PyTensor) -> PyResult<PyTensor> {
        let index_shape = index_tensor.shape();
        let shape = self.shape();

        if shape.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>("Cannot index scalar tensor"));
        }

        // Check if index tensor is 1D
        if index_shape.len() != 1 {
            return Err(PyErr::new::<PyIndexError, _>(
                "Index tensor must be 1-dimensional",
            ));
        }

        // Get the index tensor data
        if let Some(index_data) = index_tensor.inner.as_slice() {
            // Check if the tensor contains boolean-like values (0.0 and 1.0)
            let is_boolean = index_data.iter().all(|&x| x == 0.0 || x == 1.0);

            if is_boolean {
                // Treat as boolean indexing
                let bool_indices: Vec<bool> = index_data.iter().map(|&x| x != 0.0).collect();
                self.boolean_array_indexing(&bool_indices)
            } else {
                // Treat as integer indexing - convert f32 to integer indices
                let mut integer_indices = Vec::new();
                for &val in index_data {
                    let idx = val as i32;

                    // Handle negative indices
                    let positive_idx = if idx < 0 {
                        (shape[0] as i32 + idx) as usize
                    } else {
                        idx as usize
                    };

                    if positive_idx >= shape[0] {
                        return Err(PyErr::new::<PyIndexError, _>(format!(
                            "Index {} out of range for dimension of size {}",
                            idx, shape[0]
                        )));
                    }

                    integer_indices.push(positive_idx);
                }

                self.integer_array_indexing(&integer_indices)
            }
        } else {
            Err(PyErr::new::<PyRuntimeError, _>(
                "Cannot access index tensor data",
            ))
        }
    }

    // Helper method for step slicing
    fn step_slice_single_dimension(
        &self,
        start: usize,
        stop: usize,
        step: isize,
    ) -> PyResult<PyTensor> {
        let shape = self.shape();
        if shape.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>("Cannot slice scalar tensor"));
        }

        if step == 0 {
            return Err(PyErr::new::<PyIndexError, _>("Step cannot be zero"));
        }

        // Calculate the indices we want to extract
        let mut indices = Vec::new();
        if step > 0 {
            let mut i = start;
            while i < stop && i < shape[0] {
                indices.push(i);
                i = (i as isize + step) as usize;
            }
        } else {
            // Negative step - go backwards
            let mut i = if start == 0 {
                shape[0] - 1
            } else {
                start.min(shape[0] - 1)
            };
            let stop = if stop == 0 { usize::MAX } else { stop };
            loop {
                if i >= stop {
                    indices.push(i);
                }
                if i == 0 || (i as isize + step) < 0 {
                    break;
                }
                i = (i as isize + step) as usize;
            }
        }

        if indices.is_empty() {
            // Return empty tensor
            let mut new_shape = shape.clone();
            new_shape[0] = 0;
            return Ok(PyTensor {
                inner: Tensor::zeros(&new_shape),
            });
        }

        // Extract the data for the stepped indices
        if let Some(data) = self.inner.as_slice() {
            let stride = shape[1..].iter().product::<usize>();
            let new_first_dim = indices.len();
            let mut new_data = Vec::with_capacity(new_first_dim * stride);

            for &idx in &indices {
                let start_pos = idx * stride;
                let end_pos = start_pos + stride;
                if end_pos <= data.len() {
                    new_data.extend_from_slice(&data[start_pos..end_pos]);
                }
            }

            let mut new_shape = shape.clone();
            new_shape[0] = new_first_dim;

            match Tensor::from_vec(new_data, &new_shape) {
                Ok(result) => Ok(PyTensor { inner: result }),
                Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
            }
        } else {
            Err(PyErr::new::<PyRuntimeError, _>(
                "Cannot access tensor data for step slicing",
            ))
        }
    }

    // Assignment helper methods
    fn assign_single_index(&mut self, index: i32, value: &PyTensor) -> PyResult<()> {
        let shape = self.shape();
        if shape.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>(
                "Cannot assign to scalar tensor",
            ));
        }

        // Handle negative indexing
        let positive_index = if index < 0 {
            (shape[0] as i32 + index) as usize
        } else {
            index as usize
        };

        if positive_index >= shape[0] {
            return Err(PyErr::new::<PyIndexError, _>(format!(
                "Index {} out of range for dimension of size {}",
                index, shape[0]
            )));
        }

        // Check value shape compatibility
        let value_shape = value.shape();
        let expected_shape: Vec<usize> = shape[1..].to_vec();

        if value_shape != expected_shape {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Value shape {value_shape:?} does not match expected shape {expected_shape:?}"
            )));
        }

        // Perform assignment
        if let (Some(value_data), tenflowers_core::tensor::TensorStorage::Cpu(ref mut self_arr)) =
            (value.inner.as_slice(), &mut self.inner.storage)
        {
            if let Some(self_data) = self_arr.as_slice_mut() {
                let stride = shape[1..].iter().product::<usize>();
                let start_pos = positive_index * stride;
                let end_pos = start_pos + stride;

                if end_pos <= self_data.len() && value_data.len() == stride {
                    self_data[start_pos..end_pos].copy_from_slice(value_data);
                    Ok(())
                } else {
                    Err(PyErr::new::<PyRuntimeError, _>(
                        "Index or value size mismatch",
                    ))
                }
            } else {
                Err(PyErr::new::<PyRuntimeError, _>(
                    "Index or value size mismatch",
                ))
            }
        } else {
            Err(PyErr::new::<PyRuntimeError, _>(
                "Cannot access mutable tensor data",
            ))
        }
    }

    fn assign_slice(&mut self, slice: &Bound<'_, PySlice>, value: &PyTensor) -> PyResult<()> {
        let shape = self.shape();
        if shape.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>(
                "Cannot assign to scalar tensor",
            ));
        }

        let dim_size = shape[0] as isize;
        let indices = slice
            .indices(dim_size)
            .map_err(|e| PyErr::new::<PyIndexError, _>(format!("Invalid slice: {e}")))?;

        let start = indices.start as usize;
        let stop = indices.stop as usize;
        let step = indices.step;

        if step != 1 {
            return Err(PyErr::new::<PyIndexError, _>("Step slicing assignment requires scatter operations - not yet fully supported in core tensor library"));
        }

        let slice_size = stop - start;
        let value_shape = value.shape();
        let mut expected_shape = vec![slice_size];
        expected_shape.extend_from_slice(&shape[1..]);

        if value_shape != expected_shape {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Value shape {value_shape:?} does not match expected shape {expected_shape:?}"
            )));
        }

        // Perform assignment
        if let (Some(value_data), tenflowers_core::tensor::TensorStorage::Cpu(ref mut self_arr)) =
            (value.inner.as_slice(), &mut self.inner.storage)
        {
            if let Some(self_data) = self_arr.as_slice_mut() {
                let stride = shape[1..].iter().product::<usize>();
                let start_pos = start * stride;
                let total_elements = slice_size * stride;
                let end_pos = start_pos + total_elements;

                if end_pos <= self_data.len() && value_data.len() == total_elements {
                    self_data[start_pos..end_pos].copy_from_slice(value_data);
                    Ok(())
                } else {
                    Err(PyErr::new::<PyRuntimeError, _>(
                        "Slice or value size mismatch",
                    ))
                }
            } else {
                Err(PyErr::new::<PyRuntimeError, _>(
                    "Index or value size mismatch",
                ))
            }
        } else {
            Err(PyErr::new::<PyRuntimeError, _>(
                "Cannot access mutable tensor data",
            ))
        }
    }

    fn assign_tuple_index(&mut self, tuple: &Bound<'_, PyTuple>, value: &PyTensor) -> PyResult<()> {
        let shape = self.shape();

        // First pass: parse indices and validate
        let mut index_items = Vec::new();
        let mut ellipsis_count = 0;

        for item in tuple.iter() {
            if item.is_ellipsis() {
                ellipsis_count += 1;
                if ellipsis_count > 1 {
                    return Err(PyErr::new::<PyIndexError, _>(
                        "Only one ellipsis (...) allowed in indexing",
                    ));
                }
                index_items.push(IndexItem::Ellipsis);
            } else if item.is_none() {
                // newaxis (None) - not supported for assignment
                return Err(PyErr::new::<PyIndexError, _>(
                    "newaxis (None) not supported for assignment",
                ));
            } else if let Ok(index) = item.extract::<i32>() {
                index_items.push(IndexItem::Index(index));
            } else if let Ok(slice) = item.downcast::<PySlice>() {
                // Extract slice information
                let slice_info = SliceInfo {
                    start: slice.getattr("start").ok().and_then(|s| s.extract().ok()),
                    stop: slice.getattr("stop").ok().and_then(|s| s.extract().ok()),
                    step: slice.getattr("step").ok().and_then(|s| s.extract().ok()),
                };
                index_items.push(IndexItem::Slice(slice_info));
            } else {
                return Err(PyErr::new::<PyIndexError, _>(
                    "Unsupported item type in tuple indexing",
                ));
            }
        }

        // For simplicity, we'll handle common cases first
        if index_items.len() == 1 {
            match &index_items[0] {
                IndexItem::Index(idx) => {
                    return self.assign_single_index(*idx, value);
                }
                IndexItem::Slice(slice_info) => {
                    // Convert SliceInfo to PySlice for existing function
                    return Python::with_gil(|py| {
                        let start_isize = slice_info.start.unwrap_or(0);
                        let stop_isize = slice_info.stop.unwrap_or(self.shape()[0] as isize);
                        let step_isize = slice_info.step.unwrap_or(1);

                        let slice = PySlice::new(py, start_isize, stop_isize, step_isize);
                        self.assign_slice(&slice, value)
                    });
                }
                _ => {
                    return Err(PyErr::new::<PyRuntimeError, _>(
                        "Complex tuple indexing assignment not yet fully implemented",
                    ));
                }
            }
        }

        // For multi-dimensional indexing, we need to build proper slice specifications
        if index_items.len() != shape.len() && ellipsis_count == 0 {
            return Err(PyErr::new::<PyIndexError, _>(format!(
                "Tuple indexing requires {} indices for {}-dimensional tensor, got {}",
                shape.len(),
                shape.len(),
                index_items.len()
            )));
        }

        // For now, return error for complex multi-dimensional assignments
        // This can be extended in the future to handle full N-dimensional assignments
        Err(PyErr::new::<PyRuntimeError, _>(
            "Multi-dimensional tuple indexing assignment not yet fully implemented",
        ))
    }

    fn assign_list_index(&mut self, list: &Bound<'_, PyList>, value: &PyTensor) -> PyResult<()> {
        if list.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>(
                "Empty list cannot be used for assignment",
            ));
        }

        let shape = self.shape();
        if shape.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>(
                "Cannot assign to scalar tensor",
            ));
        }

        // Parse indices similar to array_indexing
        let mut integer_indices = Vec::new();
        for item in list.iter() {
            if let Ok(val) = item.extract::<i32>() {
                let positive_idx = if val < 0 {
                    (shape[0] as i32 + val) as usize
                } else {
                    val as usize
                };

                if positive_idx >= shape[0] {
                    return Err(PyErr::new::<PyIndexError, _>(format!(
                        "Index {} out of range for dimension of size {}",
                        val, shape[0]
                    )));
                }

                integer_indices.push(positive_idx);
            } else {
                return Err(PyErr::new::<PyIndexError, _>(
                    "List elements must be integers for assignment",
                ));
            }
        }

        // Check value shape compatibility
        let value_shape = value.shape();
        let mut expected_shape = vec![integer_indices.len()];
        expected_shape.extend_from_slice(&shape[1..]);

        if value_shape != expected_shape {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Value shape {value_shape:?} does not match expected shape {expected_shape:?}"
            )));
        }

        // Perform assignment
        if let (Some(value_data), tenflowers_core::tensor::TensorStorage::Cpu(ref mut self_arr)) =
            (value.inner.as_slice(), &mut self.inner.storage)
        {
            if let Some(self_data) = self_arr.as_slice_mut() {
                let stride = shape[1..].iter().product::<usize>();

                for (i, &idx) in integer_indices.iter().enumerate() {
                    let self_start = idx * stride;
                    let self_end = self_start + stride;
                    let value_start = i * stride;
                    let value_end = value_start + stride;

                    if self_end <= self_data.len() && value_end <= value_data.len() {
                        self_data[self_start..self_end]
                            .copy_from_slice(&value_data[value_start..value_end]);
                    } else {
                        return Err(PyErr::new::<PyRuntimeError, _>(
                            "Index out of bounds during assignment",
                        ));
                    }
                }

                Ok(())
            } else {
                Err(PyErr::new::<PyRuntimeError, _>(
                    "Index or value size mismatch",
                ))
            }
        } else {
            Err(PyErr::new::<PyRuntimeError, _>(
                "Cannot access mutable tensor data",
            ))
        }
    }

    fn assign_tensor_index(&mut self, index_tensor: &PyTensor, value: &PyTensor) -> PyResult<()> {
        let index_shape = index_tensor.shape();
        let shape = self.shape();

        if shape.is_empty() {
            return Err(PyErr::new::<PyIndexError, _>("Cannot index scalar tensor"));
        }

        // Check if index tensor is 1D
        if index_shape.len() != 1 {
            return Err(PyErr::new::<PyIndexError, _>(
                "Index tensor must be 1-dimensional",
            ));
        }

        // Get the index tensor data
        if let Some(index_data) = index_tensor.inner.as_slice() {
            // Check if the tensor contains boolean-like values (0.0 and 1.0)
            let is_boolean = index_data.iter().all(|&x| x == 0.0 || x == 1.0);

            if is_boolean {
                // Treat as boolean indexing assignment
                let bool_indices: Vec<bool> = index_data.iter().map(|&x| x != 0.0).collect();
                self.assign_boolean_indices(bool_indices, value)
            } else {
                // Treat as integer indexing assignment - convert f32 to integer indices
                let mut integer_indices = Vec::new();
                for &val in index_data {
                    let idx = val as i32;

                    // Handle negative indices
                    let positive_idx = if idx < 0 {
                        (shape[0] as i32 + idx) as usize
                    } else {
                        idx as usize
                    };

                    if positive_idx >= shape[0] {
                        return Err(PyErr::new::<PyIndexError, _>(format!(
                            "Index {} out of range for dimension of size {}",
                            idx, shape[0]
                        )));
                    }

                    integer_indices.push(positive_idx);
                }

                self.assign_integer_indices(integer_indices, value)
            }
        } else {
            Err(PyErr::new::<PyRuntimeError, _>(
                "Cannot access index tensor data",
            ))
        }
    }

    // Helper method for boolean indexing assignment
    fn assign_boolean_indices(
        &mut self,
        bool_indices: Vec<bool>,
        value: &PyTensor,
    ) -> PyResult<()> {
        let shape = self.shape();

        if bool_indices.len() != shape[0] {
            return Err(PyErr::new::<PyIndexError, _>(format!(
                "Boolean index length {} does not match first dimension size {}",
                bool_indices.len(),
                shape[0]
            )));
        }

        // Count number of True values to determine expected value shape
        let true_count = bool_indices.iter().filter(|&&x| x).count();
        let value_shape = value.shape();

        // Check value shape compatibility
        let mut expected_shape = vec![true_count];
        expected_shape.extend_from_slice(&shape[1..]);

        if value_shape != expected_shape {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Value shape {value_shape:?} does not match expected shape {expected_shape:?}"
            )));
        }

        // For now, this is a simplified implementation that requires core tensor library support
        // In a full implementation, we would need set_indices or scatter operations
        Err(PyErr::new::<PyRuntimeError, _>(
            "Boolean indexing assignment requires core tensor library support - not yet implemented"
        ))
    }

    // Helper method for integer indexing assignment
    fn assign_integer_indices(
        &mut self,
        integer_indices: Vec<usize>,
        value: &PyTensor,
    ) -> PyResult<()> {
        let shape = self.shape();
        let value_shape = value.shape();

        // Check value shape compatibility
        let mut expected_shape = vec![integer_indices.len()];
        expected_shape.extend_from_slice(&shape[1..]);

        if value_shape != expected_shape {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Value shape {value_shape:?} does not match expected shape {expected_shape:?}"
            )));
        }

        // For now, this is a simplified implementation that requires core tensor library support
        // In a full implementation, we would need set_indices or scatter operations
        Err(PyErr::new::<PyRuntimeError, _>(
            "Integer tensor indexing assignment requires core tensor library support - not yet implemented"
        ))
    }
}

// Private implementation methods for PyTensor
impl PyTensor {
    // Helper method for boolean array indexing
    fn boolean_array_indexing(&self, bool_indices: &[bool]) -> PyResult<PyTensor> {
        let shape = self.shape();

        if bool_indices.len() != shape[0] {
            return Err(PyErr::new::<PyIndexError, _>(format!(
                "Boolean index length {} does not match first dimension size {}",
                bool_indices.len(),
                shape[0]
            )));
        }

        // Count true values to determine result size
        let true_count = bool_indices.iter().filter(|&&b| b).count();

        if true_count == 0 {
            // Return empty tensor
            let mut new_shape = shape.clone();
            new_shape[0] = 0;
            return Ok(PyTensor {
                inner: Tensor::zeros(&new_shape),
            });
        }

        // Extract selected rows
        if let Some(data) = self.inner.as_slice() {
            let stride = shape[1..].iter().product::<usize>();
            let mut new_data = Vec::with_capacity(true_count * stride);

            for (idx, &select) in bool_indices.iter().enumerate() {
                if select {
                    let start_pos = idx * stride;
                    let end_pos = start_pos + stride;
                    if end_pos <= data.len() {
                        new_data.extend_from_slice(&data[start_pos..end_pos]);
                    }
                }
            }

            let mut new_shape = shape.clone();
            new_shape[0] = true_count;

            match Tensor::from_vec(new_data, &new_shape) {
                Ok(result) => Ok(PyTensor { inner: result }),
                Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
            }
        } else {
            Err(PyErr::new::<PyRuntimeError, _>(
                "Cannot access tensor data for boolean indexing",
            ))
        }
    }

    // Helper method for integer array indexing
    fn integer_array_indexing(&self, indices: &[usize]) -> PyResult<PyTensor> {
        let shape = self.shape();

        if indices.is_empty() {
            // Return empty tensor
            let mut new_shape = shape.clone();
            new_shape[0] = 0;
            return Ok(PyTensor {
                inner: Tensor::zeros(&new_shape),
            });
        }

        // Extract selected rows
        if let Some(data) = self.inner.as_slice() {
            let stride = shape[1..].iter().product::<usize>();
            let mut new_data = Vec::with_capacity(indices.len() * stride);

            for &idx in indices {
                let start_pos = idx * stride;
                let end_pos = start_pos + stride;
                if end_pos <= data.len() {
                    new_data.extend_from_slice(&data[start_pos..end_pos]);
                }
            }

            let mut new_shape = shape.clone();
            new_shape[0] = indices.len();

            match Tensor::from_vec(new_data, &new_shape) {
                Ok(result) => Ok(PyTensor { inner: result }),
                Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
            }
        } else {
            Err(PyErr::new::<PyRuntimeError, _>(
                "Cannot access tensor data for integer indexing",
            ))
        }
    }
}

// Functional API Classes
#[pyclass]
struct PyInput {
    inner: Input<f32>,
}

#[pymethods]
impl PyInput {
    #[new]
    #[pyo3(signature = (shape, name=None))]
    fn new(shape: Vec<usize>, name: Option<String>) -> Self {
        let input = if let Some(name) = name {
            Input::new_named(shape, name)
        } else {
            Input::new(shape)
        };
        Self { inner: input }
    }

    /// Get the shape of this input
    fn shape(&self) -> Vec<usize> {
        self.inner.shape().to_vec()
    }

    /// Get the name of this input
    fn name(&self) -> Option<String> {
        self.inner.name().map(|s| s.to_string())
    }

    /// String representation
    fn __str__(&self) -> String {
        if let Some(name) = self.name() {
            format!("PyInput(shape={:?}, name='{}')", self.shape(), name)
        } else {
            format!("PyInput(shape={:?})", self.shape())
        }
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

#[pyclass]
#[derive(Clone)]
struct PyNode {
    inner: Node<f32>,
}

#[pymethods]
impl PyNode {
    #[new]
    #[pyo3(signature = (shape, name=None))]
    fn new(shape: Vec<usize>, name: Option<String>) -> Self {
        // Create a node with no inputs (will be connected later)
        let node = if let Some(name) = name {
            Node::new_named(shape, vec![], name)
        } else {
            Node::new(shape, vec![])
        };
        Self { inner: node }
    }

    /// Get the shape of this node
    fn shape(&self) -> Vec<usize> {
        self.inner.shape().to_vec()
    }

    /// Get the name of this node
    fn name(&self) -> Option<String> {
        self.inner.name().map(|s| s.to_string())
    }

    /// String representation
    fn __str__(&self) -> String {
        if let Some(name) = self.name() {
            format!("PyNode(shape={:?}, name='{}')", self.shape(), name)
        } else {
            format!("PyNode(shape={:?})", self.shape())
        }
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

#[pyclass(unsendable)]
struct PySharedLayer {
    inner: SharedLayer<f32>,
}

#[pymethods]
impl PySharedLayer {
    #[new]
    #[pyo3(signature = (layer, name=None))]
    fn new(layer: PyNeuralModule, name: Option<String>) -> PyResult<Self> {
        // Convert PyNeuralModule to Box<dyn Layer<f32>>
        // Enhanced error handling and layer type detection
        use tenflowers_neural::Dense;

        // Match on the actual layer type to create the appropriate SharedLayer
        let boxed_layer: Box<dyn Layer<f32>> = match layer {
            PyNeuralModule::Dense(dense) => Box::new(dense.inner.clone()),
            PyNeuralModule::Activation(activation) => Box::new(activation.inner.clone()),
            _ => {
                // For unsupported layer types, provide clear error message
                return Err(PyErr::new::<PyNotImplementedError, _>(
                    "Complex layer types not yet supported in SharedLayer - currently only Dense and Activation layers are supported"
                ));
            }
        };

        let shared = if let Some(name) = name {
            SharedLayer::new_named(boxed_layer, name)
        } else {
            SharedLayer::new(boxed_layer)
        };

        Ok(Self { inner: shared })
    }

    /// Get the name of this shared layer
    fn name(&self) -> Option<String> {
        self.inner.name().map(|s| s.to_string())
    }

    /// Apply this shared layer to a node
    fn call(&self, input: &PyNode) -> PyResult<PyNode> {
        match self.inner.call(&input.inner) {
            Ok(node) => Ok(PyNode { inner: node }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "SharedLayer call failed: {e}"
            ))),
        }
    }

    /// String representation
    fn __str__(&self) -> String {
        if let Some(name) = self.name() {
            format!("PySharedLayer(name='{}')", name)
        } else {
            "PySharedLayer()".to_string()
        }
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

#[pyclass(unsendable)]
struct PyFunctionalModel {
    inner: FunctionalModel<f32>,
}

#[pymethods]
impl PyFunctionalModel {
    /// Forward pass with multiple inputs/outputs
    fn forward_multi(&self, inputs: Vec<PyTensor>) -> PyResult<Vec<PyTensor>> {
        let tensor_inputs: Vec<&Tensor<f32>> = inputs.iter().map(|t| &t.inner).collect();
        match self.inner.forward_multi(&tensor_inputs) {
            Ok(outputs) => Ok(outputs.into_iter().map(|t| PyTensor { inner: t }).collect()),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "FunctionalModel forward failed: {e}"
            ))),
        }
    }

    /// Forward pass (single input/output for Model trait compatibility)
    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "FunctionalModel forward failed: {e}"
            ))),
        }
    }

    /// Get model parameters
    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|tensor| PyTensor {
                inner: tensor.clone(),
            })
            .collect()
    }

    /// Set training mode
    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    /// Training mode
    fn train(&mut self) {
        self.set_training(true);
    }

    /// Evaluation mode
    fn eval(&mut self) {
        self.set_training(false);
    }

    /// String representation with model information
    fn __str__(&self) -> String {
        "PyFunctionalModel(layers=functional)".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

#[pyclass(unsendable)]
struct PyFunctionalModelBuilder {
    inner: FunctionalModelBuilder<f32>,
}

#[pymethods]
impl PyFunctionalModelBuilder {
    #[new]
    fn new() -> Self {
        Self {
            inner: FunctionalModelBuilder::new(),
        }
    }

    /// Add an input to the model
    fn add_input<'a>(mut slf: PyRefMut<'a, Self>, input: &'a PyInput) -> PyRefMut<'a, Self> {
        let builder = std::mem::replace(&mut slf.inner, FunctionalModelBuilder::new());
        slf.inner = builder.add_input(input.inner.clone());
        slf
    }

    /// Add a shared layer to the builder
    fn add_shared_layer<'a>(
        mut slf: PyRefMut<'a, Self>,
        layer: &'a PySharedLayer,
    ) -> PyRefMut<'a, Self> {
        // This is a placeholder - we'd need proper integration with the layer system
        slf
    }

    /// Set the model name
    fn name(mut slf: PyRefMut<'_, Self>, name: String) -> PyRefMut<'_, Self> {
        let builder = std::mem::replace(&mut slf.inner, FunctionalModelBuilder::new());
        slf.inner = builder.name(name);
        slf
    }

    /// Build the functional model
    fn build(
        mut slf: PyRefMut<'_, Self>,
        outputs: &Bound<'_, PyList>,
    ) -> PyResult<PyFunctionalModel> {
        let output_nodes: PyResult<Vec<Node<f32>>> = outputs
            .iter()
            .map(|item| {
                let node: PyNode = item.extract()?;
                Ok(node.inner)
            })
            .collect();
        let output_nodes = output_nodes?;
        let builder = std::mem::replace(&mut slf.inner, FunctionalModelBuilder::new());
        match builder.build(output_nodes) {
            Ok(model) => Ok(PyFunctionalModel { inner: model }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to build FunctionalModel: {e}"
            ))),
        }
    }

    /// String representation
    fn __str__(&self) -> String {
        "PyFunctionalModelBuilder()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// Autograd Classes
#[pyclass]
#[derive(Clone)]
struct PyTrackedTensor {
    inner: TrackedTensor<f32>,
}

#[pymethods]
impl PyTrackedTensor {
    #[new]
    fn new(tensor: &PyTensor) -> Self {
        let tape = GradientTape::new();
        let tracked = tape.watch(tensor.inner.clone());
        Self { inner: tracked }
    }

    fn tensor(&self) -> PyTensor {
        PyTensor {
            inner: self.inner.tensor().clone(),
        }
    }

    #[pyo3(signature = (retain_graph=None, create_graph=None))]
    fn backward(&self, retain_graph: Option<bool>, create_graph: Option<bool>) -> PyResult<()> {
        // Note: retain_graph and create_graph options are parsed but not yet implemented in core
        // These are placeholders for future implementation when core autograd supports them
        let _retain_graph = retain_graph.unwrap_or(false);
        let _create_graph = create_graph.unwrap_or(false);

        // This is a placeholder - in a full implementation, this would require
        // access to a GradientTape to compute gradients
        // For now, we'll just return success as the gradient tape handles the actual computation
        Ok(())
    }

    fn grad(&self) -> Option<PyTensor> {
        // This is a placeholder - in a full implementation, this would access
        // computed gradients from the gradient tape
        // For now, we'll return None as gradients need to be computed via a GradientTape
        None
    }

    fn zero_grad(&self) -> PyResult<()> {
        // This would zero out the gradients for this tensor
        // For now, this is a placeholder implementation
        // In a full implementation, this would clear the gradients associated with this tensor
        // from the gradient tape or tensor's gradient storage
        Ok(())
    }

    // Arithmetic operations
    fn __add__(&self, other: &PyTrackedTensor) -> PyResult<PyTrackedTensor> {
        match self.inner.add(&other.inner) {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn __mul__(&self, other: &PyTrackedTensor) -> PyResult<PyTrackedTensor> {
        match self.inner.mul(&other.inner) {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn __sub__(&self, other: &PyTrackedTensor) -> PyResult<PyTrackedTensor> {
        match self.inner.sub(&other.inner) {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn __truediv__(&self, other: &PyTrackedTensor) -> PyResult<PyTrackedTensor> {
        match self.inner.div(&other.inner) {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn matmul(&self, other: &PyTrackedTensor) -> PyResult<PyTrackedTensor> {
        match self.inner.matmul(&other.inner) {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Activation functions
    fn relu(&self) -> PyResult<PyTrackedTensor> {
        match self.inner.relu() {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn sigmoid(&self) -> PyResult<PyTrackedTensor> {
        match self.inner.sigmoid() {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn tanh(&self) -> PyResult<PyTrackedTensor> {
        match self.inner.tanh() {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Mathematical Functions
    fn sqrt(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = self.inner.tensor().sqrt();
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn abs(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = self.inner.tensor().abs();
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn exp(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = self.inner.tensor().exp();
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn log(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = self.inner.tensor().log();
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn sin(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = self.inner.tensor().sin();
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn cos(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = self.inner.tensor().cos();
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Special Mathematical Functions
    fn erf(&self) -> PyResult<PyTrackedTensor> {
        // For TrackedTensor, we need to apply the function through the tape
        // This is a simplified implementation - in practice, special functions
        // would need custom gradient implementations
        let tensor_result = special::erf(self.inner.tensor());
        match tensor_result {
            Ok(result) => {
                // Create a new TrackedTensor with the result
                // Note: This loses gradient tracking - proper implementation would
                // register custom gradient function with the tape
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn erfc(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = special::erfc(self.inner.tensor());
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn gamma(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = special::gamma(self.inner.tensor());
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn lgamma(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = special::lgamma(self.inner.tensor());
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn digamma(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = special::digamma(self.inner.tensor());
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn bessel_j0(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = special::bessel_j0(self.inner.tensor());
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn bessel_j1(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = special::bessel_j1(self.inner.tensor());
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn bessel_y0(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = special::bessel_y0(self.inner.tensor());
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn bessel_y1(&self) -> PyResult<PyTrackedTensor> {
        let tensor_result = special::bessel_y1(self.inner.tensor());
        match tensor_result {
            Ok(result) => {
                let tape = GradientTape::new();
                let tracked = tape.watch(result);
                Ok(PyTrackedTensor { inner: tracked })
            },
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Reduction operations
    #[pyo3(signature = (axes=None, keepdims=None))]
    fn sum(&self, axes: Option<Vec<i32>>, keepdims: Option<bool>) -> PyResult<PyTrackedTensor> {
        match self.inner.sum(axes, keepdims.unwrap_or(false)) {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    #[pyo3(signature = (axes=None, keepdims=None))]
    fn mean(&self, axes: Option<Vec<i32>>, keepdims: Option<bool>) -> PyResult<PyTrackedTensor> {
        match self.inner.mean(axes, keepdims.unwrap_or(false)) {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Shape operations
    fn reshape(&self, shape: Vec<usize>) -> PyResult<PyTrackedTensor> {
        match self.inner.reshape(&shape) {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn transpose(&self) -> PyResult<PyTrackedTensor> {
        match self.inner.transpose() {
            Ok(result) => Ok(PyTrackedTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Properties
    fn shape(&self) -> Vec<usize> {
        self.inner.tensor().shape().dims().to_vec()
    }

    fn size(&self) -> usize {
        self.inner.tensor().size()
    }

    fn ndim(&self) -> usize {
        self.inner.tensor().ndim()
    }
}

// GradientTape Context Manager
#[pyclass]
struct PyGradientTape {
    inner: Arc<GradientTape>,
}

#[pymethods]
impl PyGradientTape {
    #[new]
    #[pyo3(signature = (persistent=false))]
    fn new(persistent: Option<bool>) -> Self {
        // For now, ignore persistent flag (could be implemented later)
        Self {
            inner: Arc::new(GradientTape::new()),
        }
    }

    fn watch(&self, tensor: &PyTensor) -> PyTrackedTensor {
        let tracked = self.inner.watch(tensor.inner.clone());
        PyTrackedTensor { inner: tracked }
    }

    fn gradient(
        &self,
        target: &PyTrackedTensor,
        sources: Vec<PyTrackedTensor>,
    ) -> PyResult<Vec<PyTensor>> {
        let source_refs: Vec<_> = sources.iter().map(|s| &s.inner).collect();
        match self.inner.gradient(&target.inner, &source_refs) {
            Ok(gradients) => {
                let py_gradients = gradients
                    .into_iter()
                    .map(|g| PyTensor { inner: g })
                    .collect();
                Ok(py_gradients)
            }
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Context manager support
    fn __enter__(slf: PyRef<'_, Self>) -> PyRef<'_, Self> {
        slf
    }

    fn __exit__(
        &self,
        exc_type: Option<pyo3::PyObject>,
        exc_value: Option<pyo3::PyObject>,
        traceback: Option<pyo3::PyObject>,
    ) -> PyResult<bool> {
        // Cleanup if needed
        Ok(false) // Don't suppress exceptions
    }

    // PyTorch-compatible batch method
    fn batch_jacobian(
        &self,
        target: &PyTrackedTensor,
        sources: Vec<PyTrackedTensor>,
    ) -> PyResult<Vec<PyTensor>> {
        // For compatibility - same as gradient for now
        self.gradient(target, sources)
    }
}

// Autograd Utility Functions for PyTorch Compatibility
#[pyfunction]
fn no_grad() -> PyNoGradContext {
    PyNoGradContext::new()
}

#[pyfunction]
fn enable_grad() -> PyEnableGradContext {
    PyEnableGradContext::new()
}

/// Check if gradient computation is currently enabled
#[pyfunction]
fn is_grad_enabled() -> bool {
    autograd_is_grad_enabled()
}

#[pyclass]
struct PyNoGradContext {
    _guard: Option<NoGradGuard>,
}

#[pymethods]
impl PyNoGradContext {
    #[new]
    fn new() -> Self {
        Self { _guard: None }
    }

    fn __enter__(mut slf: PyRefMut<'_, Self>) -> PyRefMut<'_, Self> {
        // Create the NoGradGuard to disable gradient computation
        slf._guard = Some(NoGradGuard::new());
        slf
    }

    fn __exit__(
        &mut self,
        exc_type: Option<pyo3::PyObject>,
        exc_value: Option<pyo3::PyObject>,
        traceback: Option<pyo3::PyObject>,
    ) -> PyResult<bool> {
        // Drop the guard to restore gradient computation state
        self._guard = None;
        Ok(false)
    }

    /// Check if gradient computation is currently enabled
    fn is_grad_enabled(&self) -> bool {
        autograd_is_grad_enabled()
    }
}

#[pyclass]
struct PyEnableGradContext {
    _guard: Option<EnableGradGuard>,
}

#[pymethods]
impl PyEnableGradContext {
    #[new]
    fn new() -> Self {
        Self { _guard: None }
    }

    fn __enter__(mut slf: PyRefMut<'_, Self>) -> PyRefMut<'_, Self> {
        // Create the EnableGradGuard to enable gradient computation
        slf._guard = Some(EnableGradGuard::new());
        slf
    }

    fn __exit__(
        &mut self,
        exc_type: Option<pyo3::PyObject>,
        exc_value: Option<pyo3::PyObject>,
        traceback: Option<pyo3::PyObject>,
    ) -> PyResult<bool> {
        // Drop the guard to restore previous gradient computation state
        self._guard = None;
        Ok(false)
    }

    /// Check if gradient computation is currently enabled
    fn is_grad_enabled(&self) -> bool {
        autograd_is_grad_enabled()
    }
}

// Neural Network Layer Classes
#[pyclass]
pub struct PyDense {
    inner: Dense<f32>,
}

#[pymethods]
impl PyDense {
    #[new]
    #[pyo3(signature = (input_dim, output_dim, use_bias=true, activation=None))]
    fn new(
        input_dim: usize,
        output_dim: usize,
        use_bias: Option<bool>,
        activation: Option<String>,
    ) -> Self {
        let use_bias = use_bias.unwrap_or(true);
        let mut dense = Dense::new(input_dim, output_dim, use_bias);

        if let Some(act) = activation {
            dense = dense.with_activation(act);
        }

        Self { inner: dense }
    }

    // Forward pass
    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Get parameters
    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|tensor| PyTensor {
                inner: tensor.clone(),
            })
            .collect()
    }

    // Set training mode
    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    // Training mode property
    fn train(&mut self) {
        self.set_training(true);
    }

    // Evaluation mode
    fn eval(&mut self) {
        self.set_training(false);
    }

    // String representation
    fn __str__(&self) -> String {
        "PyDense()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }

    // Clone method for Python
    fn clone(&self) -> PyResult<PyDense> {
        // For now, we'll return an error since we can't properly clone Dense
        // In a full implementation, we'd need to implement proper cloning
        Err(PyErr::new::<PyRuntimeError, _>(
            "Dense layer cloning not yet implemented",
        ))
    }
}

impl Clone for PyDense {
    fn clone(&self) -> Self {
        // Properly clone the Dense layer with all parameters
        PyDense {
            inner: self.inner.clone(),
        }
    }
}

// Sequential Model Class (Simplified implementation for now)
#[pyclass]
struct PySequential {
    layers: Vec<PyDense>,
    training: bool,
}

#[pymethods]
impl PySequential {
    #[new]
    fn new() -> Self {
        Self {
            layers: Vec::new(),
            training: false,
        }
    }

    // Add a layer to the sequential model
    fn add(&mut self, layer: PyDense) {
        self.layers.push(layer);
    }

    // Forward pass through all layers
    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        let mut current_output = input.clone();

        for layer in &self.layers {
            current_output = layer.forward(&current_output)?;
        }

        Ok(current_output)
    }

    // Get all parameters from all layers
    fn parameters(&self) -> Vec<PyTensor> {
        let mut all_params = Vec::new();
        for layer in &self.layers {
            all_params.extend(layer.parameters());
        }
        all_params
    }

    // Get all named parameters from all layers
    fn named_parameters(&self) -> Vec<(String, PyTensor)> {
        let mut named_params = Vec::new();
        for (layer_idx, layer) in self.layers.iter().enumerate() {
            let layer_params = layer.parameters();
            for (param_idx, param) in layer_params.iter().enumerate() {
                let param_name = match param_idx {
                    0 => format!("layers.{}.weight", layer_idx),
                    1 => format!("layers.{}.bias", layer_idx),
                    _ => format!("layers.{}.param_{}", layer_idx, param_idx),
                };
                named_params.push((param_name, param.clone()));
            }
        }
        named_params
    }

    // Set training mode for all layers
    fn set_training(&mut self, training: bool) {
        self.training = training;
        for layer in &mut self.layers {
            layer.set_training(training);
        }
    }

    // Training mode
    fn train(&mut self) {
        self.set_training(true);
    }

    // Evaluation mode
    fn eval(&mut self) {
        self.set_training(false);
    }

    // Get number of layers
    fn __len__(&self) -> usize {
        self.layers.len()
    }

    // String representation
    fn __str__(&self) -> String {
        format!("PySequential({} layers)", self.layers.len())
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// Activation Layer Class
#[pyclass]
pub struct PyActivation {
    inner: Activation,
}

#[pymethods]
impl PyActivation {
    #[new]
    fn new(activation: &str) -> PyResult<Self> {
        let activation = match activation.to_lowercase().as_str() {
            "relu" => Activation::ReLU,
            "sigmoid" => Activation::Sigmoid,
            "tanh" => Activation::Tanh,
            "softmax" => Activation::Softmax,
            "mish" => Activation::Mish,
            _ => {
                return Err(PyErr::new::<PyValueError, _>(format!(
                    "Unknown activation: {activation}"
                )))
            }
        };

        Ok(Self { inner: activation })
    }

    // Forward pass
    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Get parameters (activation layers have no parameters)
    fn parameters(&self) -> Vec<PyTensor> {
        Vec::new()
    }

    // Set training mode (activation layers don't need training mode)
    fn set_training(&mut self, _training: bool) {
        // No-op for activation layers
    }

    // Training mode
    fn train(&mut self) {
        self.set_training(true);
    }

    // Evaluation mode
    fn eval(&mut self) {
        self.set_training(false);
    }

    // String representation
    fn __str__(&self) -> String {
        match self.inner {
            Activation::ReLU => "PyActivation(ReLU)".to_string(),
            Activation::Sigmoid => "PyActivation(Sigmoid)".to_string(),
            Activation::Tanh => "PyActivation(Tanh)".to_string(),
            Activation::Softmax => "PyActivation(Softmax)".to_string(),
            Activation::Mish => "PyActivation(Mish)".to_string(),
            Activation::HardSwish => "PyActivation(HardSwish)".to_string(),
            Activation::HardSigmoid => "PyActivation(HardSigmoid)".to_string(),
            Activation::CELU { alpha } => format!("PyActivation(CELU(alpha={}))", alpha),
        }
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyActivation {
    fn clone(&self) -> Self {
        #[allow(clippy::needless_match)]
        let activation = match self.inner {
            Activation::ReLU => Activation::ReLU,
            Activation::Sigmoid => Activation::Sigmoid,
            Activation::Tanh => Activation::Tanh,
            Activation::Softmax => Activation::Softmax,
            Activation::Mish => Activation::Mish,
            Activation::HardSwish => Activation::HardSwish,
            Activation::HardSigmoid => Activation::HardSigmoid,
            Activation::CELU { alpha } => Activation::CELU { alpha },
        };
        PyActivation { inner: activation }
    }
}

// Optimizer Classes
#[pyclass(unsendable)]
struct PySGD {
    #[allow(dead_code)]
    inner: SGD<f32>,
}

#[pymethods]
impl PySGD {
    #[new]
    #[pyo3(signature = (learning_rate, momentum=None))]
    fn new(learning_rate: f32, momentum: Option<f32>) -> Self {
        let mut sgd = SGD::new(learning_rate);
        if let Some(mom) = momentum {
            sgd = sgd.with_momentum(mom);
        }
        Self { inner: sgd }
    }

    // Step method - updates parameters in a model
    fn step(&mut self, model: &mut PySequential) -> PyResult<()> {
        // For now, implement manual parameter updates since we don't have a full Model trait
        // This is a simplified implementation
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for param in layer_params {
                if let Some(grad) = param.inner.grad() {
                    // Simple SGD update: param = param - lr * grad
                    let lr = self.inner.get_learning_rate();
                    let lr_tensor = Tensor::from_scalar(lr);
                    let lr_grad = match grad.mul(&lr_tensor) {
                        Ok(result) => result,
                        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    };
                    let _new_param = match param.inner.sub(&lr_grad) {
                        Ok(result) => result,
                        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    };
                    // Note: This is a simplified approach - in practice we'd need mutable access
                    // For now, this demonstrates the concept
                }
            }
        }
        Ok(())
    }

    // Zero gradients for a model
    fn zero_grad(&self, model: &mut PySequential) {
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for mut param in layer_params {
                if param.inner.requires_grad() {
                    let zero_grad = Tensor::zeros(param.inner.shape().dims());
                    param.inner.set_grad(Some(zero_grad));
                }
            }
        }
    }

    // Learning rate access methods
    fn get_learning_rate(&self) -> f32 {
        self.inner.get_learning_rate()
    }

    fn set_learning_rate(&mut self, learning_rate: f32) {
        self.inner.set_learning_rate(learning_rate);
    }

    // String representation
    fn __str__(&self) -> String {
        format!("PySGD(learning_rate={})", self.inner.get_learning_rate())
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }

    /// Save optimizer state to a dictionary
    fn state_dict(&self) -> PyResult<HashMap<String, PyObject>> {
        Python::with_gil(|py| {
            let mut state = HashMap::new();

            // Save basic parameters
            state.insert(
                "learning_rate".to_string(),
                self.inner.get_learning_rate().to_object(py),
            );

            // Note: Momentum and velocity state would require access to private fields
            // For now, we save what we can access publicly
            state.insert("optimizer_type".to_string(), "SGD".to_object(py));

            Ok(state)
        })
    }

    /// Load optimizer state from a dictionary
    fn load_state_dict(&mut self, state_dict: HashMap<String, PyObject>) -> PyResult<()> {
        Python::with_gil(|py| {
            // Load learning rate if present
            if let Some(lr_obj) = state_dict.get("learning_rate") {
                if let Ok(lr) = lr_obj.extract::<f32>(py) {
                    self.inner.set_learning_rate(lr);
                }
            }

            // Note: For full state restoration, we would need additional methods
            // in the underlying SGD implementation to set momentum and velocity

            Ok(())
        })
    }
}

impl Clone for PySGD {
    fn clone(&self) -> Self {
        // Clone preserves learning rate but resets internal state
        // Note: Cannot access private momentum field, so using None
        Self::new(self.inner.get_learning_rate(), None)
    }
}

#[pyclass(unsendable)]
struct PyAdam {
    #[allow(dead_code)]
    inner: Adam<f32>,
}

#[pymethods]
impl PyAdam {
    #[new]
    #[pyo3(signature = (learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8))]
    fn new(
        learning_rate: Option<f32>,
        beta1: Option<f32>,
        beta2: Option<f32>,
        epsilon: Option<f32>,
    ) -> Self {
        let learning_rate = learning_rate.unwrap_or(0.001);
        let beta1 = beta1.unwrap_or(0.9);
        let beta2 = beta2.unwrap_or(0.999);
        let epsilon = epsilon.unwrap_or(1e-8);

        let mut adam = Adam::with_betas(learning_rate, beta1, beta2);
        adam = adam.with_epsilon(epsilon);
        Self { inner: adam }
    }

    // Step method - simplified implementation for model updates
    fn step(&mut self, model: &mut PySequential) -> PyResult<()> {
        // For now, implement a simplified version that doesn't use the full Adam algorithm
        // In a complete implementation, this would use the full Adam algorithm
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for param in layer_params {
                if let Some(grad) = param.inner.grad() {
                    // Simplified update: param = param - lr * grad
                    let lr = self.inner.get_learning_rate();
                    let lr_tensor = Tensor::from_scalar(lr);
                    let lr_grad = match grad.mul(&lr_tensor) {
                        Ok(result) => result,
                        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    };
                    let _new_param = match param.inner.sub(&lr_grad) {
                        Ok(result) => result,
                        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    };
                    // Note: This is a simplified approach - in practice we'd need mutable access
                }
            }
        }
        Ok(())
    }

    // Zero gradients for a model
    fn zero_grad(&self, model: &mut PySequential) {
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for mut param in layer_params {
                if param.inner.requires_grad() {
                    let zero_grad = Tensor::zeros(param.inner.shape().dims());
                    param.inner.set_grad(Some(zero_grad));
                }
            }
        }
    }

    // Learning rate access methods
    fn get_learning_rate(&self) -> f32 {
        self.inner.get_learning_rate()
    }

    fn set_learning_rate(&mut self, learning_rate: f32) {
        self.inner.set_learning_rate(learning_rate);
    }

    // String representation
    fn __str__(&self) -> String {
        format!("PyAdam(learning_rate={})", self.inner.get_learning_rate())
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }

    /// Save optimizer state to a dictionary
    fn state_dict(&self) -> PyResult<HashMap<String, PyObject>> {
        Python::with_gil(|py| {
            let mut state = HashMap::new();

            // Save basic parameters
            state.insert(
                "learning_rate".to_string(),
                self.inner.get_learning_rate().to_object(py),
            );

            // Note: beta1, beta2, epsilon, and momentum buffers would require access to private fields
            // For now, we save what we can access publicly
            state.insert("optimizer_type".to_string(), "Adam".to_object(py));

            Ok(state)
        })
    }

    /// Load optimizer state from a dictionary
    fn load_state_dict(&mut self, state_dict: HashMap<String, PyObject>) -> PyResult<()> {
        Python::with_gil(|py| {
            // Load learning rate if present
            if let Some(lr_obj) = state_dict.get("learning_rate") {
                if let Ok(lr) = lr_obj.extract::<f32>(py) {
                    self.inner.set_learning_rate(lr);
                }
            }

            // Note: For full state restoration, we would need additional methods
            // in the underlying Adam implementation to set beta parameters and momentum buffers

            Ok(())
        })
    }
}

impl Clone for PyAdam {
    fn clone(&self) -> Self {
        // Clone preserves learning rate but resets internal state
        // Note: Cannot access private beta1, beta2, epsilon fields, so using defaults
        Self::new(
            Some(self.inner.get_learning_rate()),
            Some(0.9),   // Default beta1
            Some(0.999), // Default beta2
            Some(1e-8),  // Default epsilon
        )
    }
}

#[pyclass(unsendable)]
struct PyAdamW {
    #[allow(dead_code)]
    inner: AdamW<f32>,
}

#[pymethods]
impl PyAdamW {
    #[new]
    #[pyo3(signature = (learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, weight_decay=0.01))]
    fn new(
        learning_rate: Option<f32>,
        beta1: Option<f32>,
        beta2: Option<f32>,
        epsilon: Option<f32>,
        weight_decay: Option<f32>,
    ) -> Self {
        let learning_rate = learning_rate.unwrap_or(0.001);
        let beta1 = beta1.unwrap_or(0.9);
        let beta2 = beta2.unwrap_or(0.999);
        let epsilon = epsilon.unwrap_or(1e-8);
        let weight_decay = weight_decay.unwrap_or(0.01);

        let mut adamw = AdamW::with_betas(learning_rate, weight_decay, beta1, beta2);
        adamw = adamw.with_epsilon(epsilon);
        Self { inner: adamw }
    }

    // Step method - simplified implementation
    fn step(&mut self, model: &mut PySequential) -> PyResult<()> {
        // Simplified implementation
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for param in layer_params {
                if let Some(grad) = param.inner.grad() {
                    // Simplified update: param = param - lr * grad
                    let lr = self.inner.get_learning_rate();
                    let lr_tensor = Tensor::from_scalar(lr);
                    let lr_grad = match grad.mul(&lr_tensor) {
                        Ok(result) => result,
                        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    };
                    let _new_param = match param.inner.sub(&lr_grad) {
                        Ok(result) => result,
                        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    };
                    // Note: This is a simplified approach - in practice we'd need mutable access
                }
            }
        }
        Ok(())
    }

    // Zero gradients for a model
    fn zero_grad(&self, model: &mut PySequential) {
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for mut param in layer_params {
                if param.inner.requires_grad() {
                    let zero_grad = Tensor::zeros(param.inner.shape().dims());
                    param.inner.set_grad(Some(zero_grad));
                }
            }
        }
    }

    // Learning rate access methods
    fn get_learning_rate(&self) -> f32 {
        self.inner.get_learning_rate()
    }

    fn set_learning_rate(&mut self, learning_rate: f32) {
        self.inner.set_learning_rate(learning_rate);
    }

    // String representation
    fn __str__(&self) -> String {
        format!("PyAdamW(learning_rate={})", self.inner.get_learning_rate())
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyAdamW {
    fn clone(&self) -> Self {
        // Clone preserves hyperparameters but resets internal state
        // AdamW fields are public, so we can access them directly
        Self::new(
            Some(self.inner.learning_rate),
            Some(self.inner.beta1),
            Some(self.inner.beta2),
            Some(self.inner.epsilon),
            Some(self.inner.weight_decay),
        )
    }
}

#[pyclass(unsendable)]
struct PyRMSprop {
    #[allow(dead_code)]
    inner: RMSprop,
}

#[pymethods]
impl PyRMSprop {
    #[new]
    #[pyo3(signature = (learning_rate=0.01, alpha=0.99, epsilon=1e-8, momentum=None, weight_decay=0.0))]
    fn new(
        learning_rate: Option<f32>,
        alpha: Option<f32>,
        epsilon: Option<f32>,
        momentum: Option<f32>,
        weight_decay: Option<f32>,
    ) -> Self {
        let learning_rate = learning_rate.unwrap_or(0.01);
        let alpha = alpha.unwrap_or(0.99);
        let epsilon = epsilon.unwrap_or(1e-8);
        let weight_decay = weight_decay.unwrap_or(0.0);

        let mut rmsprop = RMSprop::new(learning_rate)
            .with_alpha(alpha)
            .with_epsilon(epsilon)
            .with_weight_decay(weight_decay);

        if let Some(momentum_val) = momentum {
            rmsprop = rmsprop.with_momentum(momentum_val);
        }

        Self { inner: rmsprop }
    }

    // Step method - simplified implementation
    fn step(&mut self, model: &mut PySequential) -> PyResult<()> {
        // Simplified implementation - in a complete implementation this would use the full RMSprop algorithm
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for param in layer_params {
                if let Some(grad) = param.inner.grad() {
                    // Simplified update: param = param - lr * grad
                    let lr = self.inner.get_learning_rate();
                    let lr_tensor = Tensor::from_scalar(lr);
                    let lr_grad = match grad.mul(&lr_tensor) {
                        Ok(result) => result,
                        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    };
                    let _new_param = match param.inner.sub(&lr_grad) {
                        Ok(result) => result,
                        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    };
                    // Note: This is a simplified approach - in practice we'd need mutable access
                }
            }
        }
        Ok(())
    }

    // Zero gradients for a model
    fn zero_grad(&self, model: &mut PySequential) {
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for mut param in layer_params {
                if param.inner.requires_grad() {
                    let zero_grad = Tensor::zeros(param.inner.shape().dims());
                    param.inner.set_grad(Some(zero_grad));
                }
            }
        }
    }

    // Learning rate access methods
    fn get_learning_rate(&self) -> f32 {
        self.inner.get_learning_rate()
    }

    fn set_learning_rate(&mut self, learning_rate: f32) {
        self.inner.set_learning_rate(learning_rate);
    }

    // String representation
    fn __str__(&self) -> String {
        format!(
            "PyRMSprop(learning_rate={})",
            self.inner.get_learning_rate()
        )
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyRMSprop {
    fn clone(&self) -> Self {
        // Clone preserves learning rate but resets internal state
        Self::new(
            Some(self.inner.get_learning_rate()),
            Some(self.inner.alpha),
            Some(self.inner.epsilon),
            self.inner.momentum,
            Some(self.inner.weight_decay),
        )
    }
}

#[pyclass(unsendable)]
struct PyAdagrad {
    #[allow(dead_code)]
    inner: Adagrad<f32>,
}

#[pymethods]
impl PyAdagrad {
    #[new]
    #[pyo3(signature = (learning_rate=0.01, epsilon=1e-10))]
    fn new(learning_rate: Option<f32>, epsilon: Option<f32>) -> Self {
        let learning_rate = learning_rate.unwrap_or(0.01);
        let epsilon = epsilon.unwrap_or(1e-10);

        let adagrad = Adagrad::new(learning_rate).with_epsilon(epsilon);

        Self { inner: adagrad }
    }

    // Step method - simplified implementation
    fn step(&mut self, model: &mut PySequential) -> PyResult<()> {
        // Simplified implementation - in a complete implementation this would use the full Adagrad algorithm
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for param in layer_params {
                if let Some(grad) = param.inner.grad() {
                    // Simplified update: param = param - lr * grad
                    let lr = self.inner.get_learning_rate();
                    let lr_tensor = Tensor::from_scalar(lr);
                    let lr_grad = match grad.mul(&lr_tensor) {
                        Ok(result) => result,
                        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    };
                    let _new_param = match param.inner.sub(&lr_grad) {
                        Ok(result) => result,
                        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
                    };
                    // Note: This is a simplified approach - in practice we'd need mutable access
                }
            }
        }
        Ok(())
    }

    // Zero gradients for a model
    fn zero_grad(&self, model: &mut PySequential) {
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for mut param in layer_params {
                if param.inner.requires_grad() {
                    let zero_grad = Tensor::zeros(param.inner.shape().dims());
                    param.inner.set_grad(Some(zero_grad));
                }
            }
        }
    }

    // Learning rate access methods
    fn get_learning_rate(&self) -> f32 {
        self.inner.get_learning_rate()
    }

    fn set_learning_rate(&mut self, learning_rate: f32) {
        self.inner.set_learning_rate(learning_rate);
    }

    // String representation
    fn __str__(&self) -> String {
        format!(
            "PyAdagrad(learning_rate={})",
            self.inner.get_learning_rate()
        )
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyAdagrad {
    fn clone(&self) -> Self {
        // Clone preserves learning rate but resets internal state
        // Note: Cannot access private epsilon field, so using default
        Self::new(
            Some(self.inner.get_learning_rate()),
            Some(1e-10), // Default epsilon
        )
    }
}

// =====================================================================
// Parameter Groups
// =====================================================================

#[pyclass]
struct PyParameterGroupConfig {
    inner: ParameterGroupConfig,
}

#[pymethods]
impl PyParameterGroupConfig {
    #[new]
    #[pyo3(signature = (learning_rate=0.001, weight_decay=0.0))]
    fn new(learning_rate: Option<f32>, weight_decay: Option<f32>) -> Self {
        let learning_rate = learning_rate.unwrap_or(0.001);
        let weight_decay = weight_decay.unwrap_or(0.0);

        let config = ParameterGroupConfig::new(learning_rate).with_weight_decay(weight_decay);

        Self { inner: config }
    }

    #[getter]
    fn learning_rate(&self) -> f32 {
        self.inner.learning_rate
    }

    #[setter]
    fn set_learning_rate(&mut self, learning_rate: f32) {
        self.inner.learning_rate = learning_rate;
    }

    #[getter]
    fn weight_decay(&self) -> f32 {
        self.inner.weight_decay
    }

    #[setter]
    fn set_weight_decay(&mut self, weight_decay: f32) {
        self.inner.weight_decay = weight_decay;
    }

    fn with_weight_decay(&mut self, weight_decay: f32) -> Self {
        let mut config = self.inner.clone();
        config.weight_decay = weight_decay;
        Self { inner: config }
    }

    fn __str__(&self) -> String {
        format!(
            "ParameterGroupConfig(learning_rate={}, weight_decay={})",
            self.inner.learning_rate, self.inner.weight_decay
        )
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyParameterGroupConfig {
    fn clone(&self) -> Self {
        Self {
            inner: self.inner.clone(),
        }
    }
}

#[pyclass(unsendable)]
struct PyParameterGroupOptimizer {
    inner: ParameterGroupOptimizer<f32, SGD<f32>>,
}

#[pymethods]
impl PyParameterGroupOptimizer {
    #[new]
    #[pyo3(signature = (optimizer_type="sgd", default_learning_rate=0.001))]
    fn new(optimizer_type: Option<&str>, default_learning_rate: Option<f32>) -> PyResult<Self> {
        let optimizer_type = optimizer_type.unwrap_or("sgd");
        let default_learning_rate = default_learning_rate.unwrap_or(0.001);

        let default_config = ParameterGroupConfig::new(default_learning_rate);

        let optimizer = match optimizer_type {
            "sgd" => {
                let factory = |config: &ParameterGroupConfig| SGD::<f32>::new(config.learning_rate);
                ParameterGroupOptimizer::new(factory, default_config)
            }
            _ => {
                return Err(PyErr::new::<PyValueError, _>(format!(
                    "Unsupported optimizer type: {}",
                    optimizer_type
                )))
            }
        };

        Ok(Self { inner: optimizer })
    }

    fn add_group(&mut self, name: &str, config: &PyParameterGroupConfig) -> PyResult<usize> {
        match self.inner.add_group(name.to_string(), config.inner.clone()) {
            Ok(index) => Ok(index),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn add_parameters_to_group(
        &mut self,
        group_index: usize,
        parameters: Vec<PyTensor>,
    ) -> PyResult<()> {
        let param_refs: Vec<&Tensor<f32>> = parameters.iter().map(|p| &p.inner).collect();
        match self.inner.add_parameters_to_group(group_index, &param_refs) {
            Ok(_) => Ok(()),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn add_parameters_to_group_by_name(
        &mut self,
        group_name: &str,
        parameters: Vec<PyTensor>,
    ) -> PyResult<()> {
        let param_refs: Vec<&Tensor<f32>> = parameters.iter().map(|p| &p.inner).collect();
        match self
            .inner
            .add_parameters_to_group_by_name(group_name, &param_refs)
        {
            Ok(_) => Ok(()),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn group_names(&self) -> Vec<String> {
        self.inner
            .group_names()
            .iter()
            .map(|s| s.to_string())
            .collect()
    }

    fn set_group_learning_rate(&mut self, group_index: usize, learning_rate: f32) -> PyResult<()> {
        match self
            .inner
            .set_group_learning_rate(group_index, learning_rate)
        {
            Ok(_) => Ok(()),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn set_group_learning_rate_by_name(
        &mut self,
        group_name: &str,
        learning_rate: f32,
    ) -> PyResult<()> {
        match self
            .inner
            .set_group_learning_rate_by_name(group_name, learning_rate)
        {
            Ok(_) => Ok(()),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    fn get_group_learning_rate(&self, group_index: usize) -> Option<f32> {
        self.inner.get_group_learning_rate(group_index)
    }

    fn find_parameter_group(&self, param: &PyTensor) -> Option<usize> {
        self.inner.find_parameter_group(&param.inner)
    }

    fn step(&mut self, model: &mut PySequential) -> PyResult<()> {
        // Note: This is a simplified implementation
        // In a complete implementation, this would use the parameter group optimizer step method
        // For now, implement a basic parameter update across all groups
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for param in layer_params {
                if let Some(grad) = param.inner.grad() {
                    // Find which group this parameter belongs to
                    if let Some(group_index) = self.inner.find_parameter_group(&param.inner) {
                        if let Some(lr) = self.inner.get_group_learning_rate(group_index) {
                            // Apply parameter update: param = param - lr * grad
                            let lr_tensor = Tensor::from_scalar(lr);
                            let lr_grad = match grad.mul(&lr_tensor) {
                                Ok(result) => result,
                                Err(e) => {
                                    return Err(PyErr::new::<PyRuntimeError, _>(e.to_string()))
                                }
                            };
                            let _new_param = match param.inner.sub(&lr_grad) {
                                Ok(result) => result,
                                Err(e) => {
                                    return Err(PyErr::new::<PyRuntimeError, _>(e.to_string()))
                                }
                            };
                        }
                    }
                }
            }
        }
        Ok(())
    }

    fn zero_grad(&self, model: &mut PySequential) {
        // Zero gradients for all parameters
        for layer in &mut model.layers {
            let layer_params = layer.parameters();
            for mut param in layer_params {
                if param.inner.requires_grad() {
                    let zero_grad = Tensor::zeros(param.inner.shape().dims());
                    param.inner.set_grad(Some(zero_grad));
                }
            }
        }
    }

    #[staticmethod]
    fn with_pretrained_and_new_layers(pretrained_lr: f32, new_layer_lr: f32) -> PyResult<Self> {
        let factory =
            Box::new(|config: &ParameterGroupConfig| SGD::<f32>::new(config.learning_rate));
        let optimizer = ParameterGroupOptimizer::with_pretrained_and_new_layers(
            factory,
            pretrained_lr,
            new_layer_lr,
        );

        Ok(Self { inner: optimizer })
    }

    fn __str__(&self) -> String {
        let names = self.group_names();
        format!("ParameterGroupOptimizer(groups={:?})", names)
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// =====================================================================
// Learning Rate Schedulers
// =====================================================================

/// Constant learning rate scheduler (no scheduling)
#[pyclass]
struct PyConstantLR {
    inner: ConstantLR,
}

#[pymethods]
impl PyConstantLR {
    #[new]
    fn new(lr: f32) -> Self {
        Self {
            inner: ConstantLR::new(lr),
        }
    }

    fn get_lr(&self, step: usize) -> f32 {
        self.inner.get_lr(step)
    }

    fn __str__(&self) -> String {
        format!("PyConstantLR(lr={})", self.inner.get_lr(0))
    }
}

/// Step decay learning rate scheduler
#[pyclass]
struct PyStepLR {
    inner: StepLR,
}

#[pymethods]
impl PyStepLR {
    #[new]
    fn new(initial_lr: f32, step_size: usize, gamma: f32) -> Self {
        Self {
            inner: StepLR::new(initial_lr, step_size, gamma),
        }
    }

    fn get_lr(&self, step: usize) -> f32 {
        self.inner.get_lr(step)
    }

    fn __str__(&self) -> String {
        format!(
            "PyStepLR(initial_lr={}, step_size={}, gamma={})",
            self.inner.get_lr(0),
            self.inner.get_lr(0),
            0.1
        ) // approximation for display
    }
}

/// Exponential decay learning rate scheduler
#[pyclass]
struct PyExponentialLR {
    inner: ExponentialLR,
}

#[pymethods]
impl PyExponentialLR {
    #[new]
    fn new(initial_lr: f32, gamma: f32) -> Self {
        Self {
            inner: ExponentialLR::new(initial_lr, gamma),
        }
    }

    fn get_lr(&self, step: usize) -> f32 {
        self.inner.get_lr(step)
    }

    fn __str__(&self) -> String {
        format!(
            "PyExponentialLR(initial_lr={}, gamma={})",
            self.inner.get_lr(0),
            0.95
        ) // approximation for display
    }
}

/// Cosine annealing learning rate scheduler
#[pyclass]
struct PyCosineAnnealingLR {
    inner: CosineAnnealingLR,
}

#[pymethods]
impl PyCosineAnnealingLR {
    #[new]
    #[pyo3(signature = (initial_lr, t_max, min_lr=0.0))]
    fn new(initial_lr: f32, t_max: usize, min_lr: Option<f32>) -> Self {
        let mut scheduler = CosineAnnealingLR::new(initial_lr, t_max);
        if let Some(min_lr) = min_lr {
            scheduler = scheduler.with_min_lr(min_lr);
        }
        Self { inner: scheduler }
    }

    fn get_lr(&self, step: usize) -> f32 {
        self.inner.get_lr(step)
    }

    fn __str__(&self) -> String {
        format!(
            "PyCosineAnnealingLR(initial_lr={}, t_max={})",
            self.inner.get_lr(0),
            1000
        ) // approximation for display
    }
}

/// Polynomial decay learning rate scheduler
#[pyclass]
struct PyPolynomialLR {
    inner: PolynomialLR,
}

#[pymethods]
impl PyPolynomialLR {
    #[new]
    #[pyo3(signature = (initial_lr, max_steps, final_lr=0.0, power=1.0))]
    fn new(initial_lr: f32, max_steps: usize, final_lr: Option<f32>, power: Option<f32>) -> Self {
        let mut scheduler = PolynomialLR::new(initial_lr, max_steps);
        if let Some(final_lr) = final_lr {
            scheduler = scheduler.with_final_lr(final_lr);
        }
        if let Some(power) = power {
            scheduler = scheduler.with_power(power);
        }
        Self { inner: scheduler }
    }

    fn get_lr(&self, step: usize) -> f32 {
        self.inner.get_lr(step)
    }

    fn __str__(&self) -> String {
        format!(
            "PyPolynomialLR(initial_lr={}, max_steps={})",
            self.inner.get_lr(0),
            1000
        ) // approximation for display
    }
}

/// Warmup cosine decay learning rate scheduler
#[pyclass]
struct PyWarmupCosineDecayLR {
    inner: WarmupCosineDecayLR,
}

#[pymethods]
impl PyWarmupCosineDecayLR {
    #[new]
    #[pyo3(signature = (peak_lr, warmup_steps, total_steps, initial_lr=0.0, min_lr=0.0))]
    fn new(
        peak_lr: f32,
        warmup_steps: usize,
        total_steps: usize,
        initial_lr: Option<f32>,
        min_lr: Option<f32>,
    ) -> Self {
        let mut scheduler = WarmupCosineDecayLR::new(peak_lr, warmup_steps, total_steps);
        if let Some(initial_lr) = initial_lr {
            scheduler = scheduler.with_initial_lr(initial_lr);
        }
        if let Some(min_lr) = min_lr {
            scheduler = scheduler.with_min_lr(min_lr);
        }
        Self { inner: scheduler }
    }

    fn get_lr(&self, step: usize) -> f32 {
        self.inner.get_lr(step)
    }

    fn __str__(&self) -> String {
        format!(
            "PyWarmupCosineDecayLR(peak_lr={}, warmup_steps={}, total_steps={})",
            self.inner.get_lr(1000),
            100,
            1000
        ) // approximation for display
    }
}

/// Reduce learning rate on plateau scheduler
#[pyclass]
struct PyReduceLROnPlateau {
    inner: ReduceLROnPlateau,
}

#[pymethods]
impl PyReduceLROnPlateau {
    #[new]
    #[pyo3(signature = (initial_lr, factor=0.1, patience=10, min_lr=0.0, mode="min"))]
    fn new(
        initial_lr: f32,
        factor: Option<f32>,
        patience: Option<usize>,
        min_lr: Option<f32>,
        mode: Option<&str>,
    ) -> Self {
        let mut scheduler =
            ReduceLROnPlateau::new(initial_lr, factor.unwrap_or(0.1), patience.unwrap_or(10));
        if let Some(min_lr) = min_lr {
            scheduler = scheduler.with_min_lr(min_lr);
        }
        if let Some(mode_str) = mode {
            let plateau_mode = match mode_str {
                "max" => PlateauMode::Max,
                _ => PlateauMode::Min,
            };
            scheduler = scheduler.with_mode(plateau_mode);
        }
        Self { inner: scheduler }
    }

    fn get_lr(&self, step: usize) -> f32 {
        self.inner.get_lr(step)
    }

    fn step(&mut self, metric: f32) {
        self.inner.step_with_metric(metric);
    }

    fn reset(&mut self) {
        self.inner.reset();
    }

    fn __str__(&self) -> String {
        "PyReduceLROnPlateau(factor=0.1, patience=10)".to_string()
    }
}

/// One cycle learning rate scheduler
#[pyclass]
struct PyOneCycleLR {
    inner: OneCycleLR,
}

#[pymethods]
impl PyOneCycleLR {
    #[new]
    #[pyo3(signature = (max_lr, total_steps, pct_start=0.3, anneal_strategy="cos", div_factor=25.0, final_div_factor=10000.0))]
    fn new(
        max_lr: f32,
        total_steps: usize,
        pct_start: Option<f32>,
        anneal_strategy: Option<&str>,
        div_factor: Option<f32>,
        final_div_factor: Option<f32>,
    ) -> Self {
        let mut scheduler = OneCycleLR::new(max_lr, total_steps);
        if let Some(pct_start) = pct_start {
            scheduler = scheduler.with_pct_start(pct_start);
        }
        if let Some(anneal_strategy) = anneal_strategy {
            scheduler = scheduler.with_anneal_strategy(anneal_strategy);
        }
        // Set div factors together using the combined method
        let div_factor = div_factor.unwrap_or(25.0);
        let final_div_factor = final_div_factor.unwrap_or(10000.0);
        scheduler = scheduler.with_div_factors(div_factor, final_div_factor);

        Self { inner: scheduler }
    }

    fn get_lr(&self, step: usize) -> f32 {
        self.inner.get_lr(step)
    }

    fn __str__(&self) -> String {
        format!(
            "PyOneCycleLR(max_lr={}, total_steps={})",
            self.inner.get_lr(1),
            1000
        ) // approximation for display
    }
}

// Parameter Class - wrapper around tensors that indicates they are trainable parameters
#[pyclass]
#[derive(Clone)]
struct PyParameter {
    inner: PyTensor,
}

#[pymethods]
impl PyParameter {
    #[new]
    fn new(tensor: PyTensor) -> Self {
        // Parameters require gradients by default
        let mut param_tensor = tensor;
        param_tensor.inner.set_requires_grad(true);
        Self {
            inner: param_tensor,
        }
    }

    // Create a parameter from numpy array
    #[classmethod]
    fn from_numpy(_cls: &Bound<'_, PyType>, array: PyReadonlyArrayDyn<f32>) -> PyResult<Self> {
        let tensor = from_numpy(array)?;
        Ok(Self::new(tensor))
    }

    // Get the underlying tensor
    fn tensor(&self) -> PyTensor {
        self.inner.clone()
    }

    // Get the data as numpy array
    fn data(&self, py: Python<'_>) -> PyResult<PyObject> {
        let array = self.inner.to_numpy(py)?;
        Ok(array.into_py(py))
    }

    // Get the gradient
    fn grad(&self) -> Option<PyTensor> {
        self.inner.grad()
    }

    // Set the gradient
    #[pyo3(signature = (grad=None))]
    fn set_grad(&mut self, grad: Option<PyTensor>) {
        match grad {
            Some(grad_tensor) => self.inner.inner.set_grad(Some(grad_tensor.inner)),
            None => self.inner.inner.set_grad(None),
        }
    }

    // Zero the gradient
    fn zero_grad(&mut self) {
        self.inner.inner.set_grad(None)
    }

    // Shape property
    #[getter]
    fn shape(&self) -> Vec<usize> {
        self.inner.shape()
    }

    // Device property
    #[getter]
    fn device(&self) -> String {
        self.inner.device()
    }

    // Requires grad property
    #[getter]
    fn requires_grad(&self) -> bool {
        self.inner.requires_grad()
    }

    #[setter]
    fn set_requires_grad(&mut self, requires_grad: bool) {
        self.inner.set_requires_grad(requires_grad)
    }

    // Move to device
    fn to_device(&self, device: &str) -> PyResult<Self> {
        let new_tensor = self.inner.to_device(device)?;
        Ok(Self::new(new_tensor))
    }

    // Clone
    fn clone(&self) -> Self {
        Self::new(self.inner.clone())
    }

    // String representation
    fn __str__(&self) -> String {
        format!("Parameter containing:\n{}", self.inner.__str__())
    }

    fn __repr__(&self) -> String {
        format!(
            "Parameter({}, requires_grad={})",
            self.inner.__repr__(),
            self.requires_grad()
        )
    }
}

// BatchNorm Layer Class - Using unsendable to work around RefCell thread safety issues
#[pyclass(unsendable)]
pub struct PyBatchNorm {
    inner: BatchNorm<f32>,
}

#[pymethods]
impl PyBatchNorm {
    #[new]
    #[pyo3(signature = (num_features, momentum=None, epsilon=None))]
    fn new(num_features: usize, momentum: Option<f32>, epsilon: Option<f32>) -> Self {
        let mut batchnorm = BatchNorm::new(num_features);

        // Set momentum and epsilon if provided
        if let Some(momentum_val) = momentum {
            batchnorm = batchnorm.with_momentum(momentum_val);
        }
        if let Some(epsilon_val) = epsilon {
            batchnorm = batchnorm.with_epsilon(epsilon_val);
        }

        Self { inner: batchnorm }
    }

    // Forward pass
    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Get parameters
    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|tensor| PyTensor {
                inner: tensor.clone(),
            })
            .collect()
    }

    // Set training mode
    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    // Training mode
    fn train(&mut self) {
        self.set_training(true);
    }

    // Evaluation mode
    fn eval(&mut self) {
        self.set_training(false);
    }

    // String representation
    fn __str__(&self) -> String {
        "PyBatchNorm()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyBatchNorm {
    fn clone(&self) -> Self {
        // BatchNorm doesn't support Clone trait yet due to RefCell complexity
        // Create new instance with default parameters until core adds Clone support
        PyBatchNorm {
            inner: BatchNorm::new(64).with_momentum_and_epsilon(0.1, 1e-5), // reasonable defaults
        }
    }
}

// Conv2D Layer Class
#[pyclass]
pub struct PyConv2D {
    inner: Conv2D<f32>,
}

#[pymethods]
impl PyConv2D {
    #[new]
    #[pyo3(signature = (in_channels, out_channels, kernel_size, stride=None, padding=None, use_bias=None))]
    fn new(
        in_channels: usize,
        out_channels: usize,
        kernel_size: (usize, usize),
        stride: Option<(usize, usize)>,
        padding: Option<String>,
        use_bias: Option<bool>,
    ) -> Self {
        let stride = stride.unwrap_or((1, 1));
        let padding = padding.unwrap_or_else(|| "valid".to_string());
        let use_bias = use_bias.unwrap_or(true);

        let conv2d = Conv2D::new(
            in_channels,
            out_channels,
            kernel_size,
            stride,
            padding,
            use_bias,
        );

        Self { inner: conv2d }
    }

    // Forward pass
    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Get parameters
    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|tensor| PyTensor {
                inner: tensor.clone(),
            })
            .collect()
    }

    // Set training mode
    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    // Training mode
    fn train(&mut self) {
        self.set_training(true);
    }

    // Evaluation mode
    fn eval(&mut self) {
        self.set_training(false);
    }

    // String representation
    fn __str__(&self) -> String {
        "PyConv2D()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyConv2D {
    fn clone(&self) -> Self {
        // Properly clone the Conv2D layer with all parameters
        PyConv2D {
            inner: self.inner.clone(),
        }
    }
}

// Conv1D Layer Class
#[pyclass]
pub struct PyConv1D {
    inner: Conv1D<f32>,
}

#[pymethods]
impl PyConv1D {
    #[new]
    #[pyo3(signature = (in_channels, out_channels, kernel_size, stride=None, padding=None, dilation=None, groups=None, use_bias=None))]
    fn new(
        in_channels: usize,
        out_channels: usize,
        kernel_size: usize,
        stride: Option<usize>,
        padding: Option<String>,
        dilation: Option<usize>,
        groups: Option<usize>,
        use_bias: Option<bool>,
    ) -> Self {
        let stride = stride.unwrap_or(1);
        let padding = padding.unwrap_or_else(|| "valid".to_string());
        let dilation = dilation.unwrap_or(1);
        let groups = groups.unwrap_or(1);
        let use_bias = use_bias.unwrap_or(true);

        let conv1d = Conv1D::new(
            in_channels,
            out_channels,
            kernel_size,
            Some(stride),
            Some(padding),
            Some(dilation),
            Some(groups),
            use_bias,
        );

        Self { inner: conv1d }
    }

    // Simple constructor for common use cases
    #[classmethod]
    fn simple(
        _cls: &Bound<'_, PyType>,
        in_channels: usize,
        out_channels: usize,
        kernel_size: usize,
    ) -> Self {
        let conv1d = Conv1D::simple(in_channels, out_channels, kernel_size);
        Self { inner: conv1d }
    }

    // Forward pass
    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Get parameters
    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|tensor| PyTensor {
                inner: tensor.clone(),
            })
            .collect()
    }

    // Set training mode
    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    // Training mode
    fn train(&mut self) {
        self.set_training(true);
    }

    // Evaluation mode
    fn eval(&mut self) {
        self.set_training(false);
    }

    // String representation
    fn __str__(&self) -> String {
        "PyConv1D()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyConv1D {
    fn clone(&self) -> Self {
        // Properly clone the Conv1D layer with all parameters
        PyConv1D {
            inner: self.inner.clone_layer(),
        }
    }
}

// Conv3D Layer Class
#[pyclass]
pub struct PyConv3D {
    inner: Conv3D<f32>,
}

#[pymethods]
impl PyConv3D {
    #[new]
    #[pyo3(signature = (in_channels, out_channels, kernel_size, stride=None, padding=None, dilation=None, groups=None, use_bias=None))]
    fn new(
        in_channels: usize,
        out_channels: usize,
        kernel_size: (usize, usize, usize),
        stride: Option<(usize, usize, usize)>,
        padding: Option<String>,
        dilation: Option<(usize, usize, usize)>,
        groups: Option<usize>,
        use_bias: Option<bool>,
    ) -> Self {
        let stride = stride.unwrap_or((1, 1, 1));
        let padding = padding.unwrap_or_else(|| "valid".to_string());
        let dilation = dilation.unwrap_or((1, 1, 1));
        let groups = groups.unwrap_or(1);
        let use_bias = use_bias.unwrap_or(true);

        let conv3d = Conv3D::new(
            in_channels,
            out_channels,
            kernel_size,
            Some(stride),
            Some(padding),
            Some(dilation),
            Some(groups),
            use_bias,
        );

        Self { inner: conv3d }
    }

    // Simple constructor for common use cases
    #[classmethod]
    fn simple(
        _cls: &Bound<'_, PyType>,
        in_channels: usize,
        out_channels: usize,
        kernel_size: (usize, usize, usize),
    ) -> Self {
        let conv3d = Conv3D::simple(in_channels, out_channels, kernel_size);
        Self { inner: conv3d }
    }

    // Forward pass
    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        }
    }

    // Get parameters
    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|tensor| PyTensor {
                inner: tensor.clone(),
            })
            .collect()
    }

    // Set training mode
    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    // Training mode
    fn train(&mut self) {
        self.set_training(true);
    }

    // Evaluation mode
    fn eval(&mut self) {
        self.set_training(false);
    }

    // String representation
    fn __str__(&self) -> String {
        "PyConv3D()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyConv3D {
    fn clone(&self) -> Self {
        // Conv3D doesn't support Clone trait yet
        // Create new instance with reasonable defaults until core adds Clone support
        PyConv3D {
            inner: Conv3D::simple(32, 64, (3, 3, 3)), // reasonable defaults
        }
    }
}

// LSTM Layer Class
#[pyclass]
pub struct PyLSTM {
    inner: LSTM<f32>,
}

#[pymethods]
impl PyLSTM {
    #[new]
    #[pyo3(signature = (input_size, hidden_size, num_layers=None, bias=None, batch_first=None, dropout=None, bidirectional=None))]
    fn new(
        input_size: usize,
        hidden_size: usize,
        num_layers: Option<usize>,
        bias: Option<bool>,
        batch_first: Option<bool>,
        dropout: Option<f32>,
        bidirectional: Option<bool>,
    ) -> PyResult<Self> {
        match LSTM::new(
            input_size,
            hidden_size,
            num_layers,
            bias,
            batch_first,
            dropout,
            bidirectional,
        ) {
            Ok(lstm) => Ok(Self { inner: lstm }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create LSTM: {e}"
            ))),
        }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "LSTM forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyLSTM()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyLSTM {
    fn clone(&self) -> Self {
        // Properly clone the LSTM layer with all parameters
        PyLSTM {
            inner: self.inner.clone(),
        }
    }
}

// GRU Layer Class
#[pyclass]
pub struct PyGRU {
    inner: GRU<f32>,
}

#[pymethods]
impl PyGRU {
    #[new]
    #[pyo3(signature = (input_size, hidden_size, num_layers=None, bias=None, batch_first=None, dropout=None, bidirectional=None))]
    fn new(
        input_size: usize,
        hidden_size: usize,
        num_layers: Option<usize>,
        bias: Option<bool>,
        batch_first: Option<bool>,
        dropout: Option<f32>,
        bidirectional: Option<bool>,
    ) -> PyResult<Self> {
        match GRU::new(
            input_size,
            hidden_size,
            num_layers,
            bias,
            batch_first,
            dropout,
            bidirectional,
        ) {
            Ok(gru) => Ok(Self { inner: gru }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create GRU: {e}"
            ))),
        }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "GRU forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyGRU()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyGRU {
    fn clone(&self) -> Self {
        // Properly clone the GRU layer with all parameters
        PyGRU {
            inner: self.inner.clone(),
        }
    }
}

// RNN Layer Class
#[pyclass]
pub struct PyRNN {
    inner: RNN<f32>,
}

#[pymethods]
impl PyRNN {
    #[new]
    #[pyo3(signature = (input_size, hidden_size, num_layers=None, nonlinearity=None, bias=None, batch_first=None, dropout=None, bidirectional=None))]
    fn new(
        input_size: usize,
        hidden_size: usize,
        num_layers: Option<usize>,
        nonlinearity: Option<String>,
        bias: Option<bool>,
        batch_first: Option<bool>,
        dropout: Option<f32>,
        bidirectional: Option<bool>,
    ) -> PyResult<Self> {
        match RNN::new(
            input_size,
            hidden_size,
            num_layers,
            bias,
            batch_first,
            dropout,
            bidirectional,
            nonlinearity,
        ) {
            Ok(rnn) => Ok(Self { inner: rnn }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create RNN: {e}"
            ))),
        }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "RNN forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyRNN()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyRNN {
    fn clone(&self) -> Self {
        // Properly clone the RNN layer with all parameters
        PyRNN {
            inner: self.inner.clone(),
        }
    }
}

// MultiHeadAttention Layer Class
#[pyclass]
pub struct PyMultiHeadAttention {
    inner: MultiHeadAttention<f32>,
}

#[pymethods]
impl PyMultiHeadAttention {
    #[new]
    #[pyo3(signature = (embed_dim, num_heads, use_bias=None))]
    fn new(embed_dim: usize, num_heads: usize, use_bias: Option<bool>) -> PyResult<Self> {
        let use_bias = use_bias.unwrap_or(true);
        match MultiHeadAttention::new(embed_dim, num_heads, use_bias) {
            Ok(attention) => Ok(Self { inner: attention }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create MultiHeadAttention: {e}"
            ))),
        }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "MultiHeadAttention forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyMultiHeadAttention()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyMultiHeadAttention {
    fn clone(&self) -> Self {
        // MultiHeadAttention doesn't support Clone trait yet
        // Create new instance with reasonable defaults until core adds Clone support
        PyMultiHeadAttention {
            inner: MultiHeadAttention::new(512, 8, true).unwrap_or_else(|_| {
                // Fallback with more conservative defaults if creation fails
                MultiHeadAttention::new(256, 4, false)
                    .expect("Failed to create MultiHeadAttention with fallback parameters")
            }),
        }
    }
}

// TransformerEncoder Layer Class
#[pyclass]
pub struct PyTransformerEncoder {
    inner: TransformerEncoder<f32>,
}

#[pymethods]
impl PyTransformerEncoder {
    #[new]
    #[pyo3(signature = (embed_dim, num_heads, feed_forward_dim=None, dropout_rate=None, pre_norm=None))]
    fn new(
        embed_dim: usize,
        num_heads: usize,
        feed_forward_dim: Option<usize>,
        dropout_rate: Option<f32>,
        pre_norm: Option<bool>,
    ) -> PyResult<Self> {
        match TransformerEncoder::new(
            embed_dim,
            num_heads,
            feed_forward_dim,
            dropout_rate,
            pre_norm,
        ) {
            Ok(encoder) => Ok(Self { inner: encoder }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create TransformerEncoder: {e}"
            ))),
        }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "TransformerEncoder forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyTransformerEncoder()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyTransformerEncoder {
    fn clone(&self) -> Self {
        // TransformerEncoder doesn't support Clone trait yet
        // Create new instance with reasonable defaults until core adds Clone support
        PyTransformerEncoder {
            inner: TransformerEncoder::new(512, 8, Some(2048), Some(0.1), Some(true)).unwrap(), // reasonable defaults
        }
    }
}

// TransformerDecoder Layer Class
#[pyclass]
pub struct PyTransformerDecoder {
    inner: TransformerDecoder<f32>,
}

#[pymethods]
impl PyTransformerDecoder {
    #[new]
    #[pyo3(signature = (embed_dim, num_heads, feed_forward_dim=None, dropout_rate=None, pre_norm=None))]
    fn new(
        embed_dim: usize,
        num_heads: usize,
        feed_forward_dim: Option<usize>,
        dropout_rate: Option<f32>,
        pre_norm: Option<bool>,
    ) -> PyResult<Self> {
        match TransformerDecoder::new(
            embed_dim,
            num_heads,
            feed_forward_dim,
            dropout_rate,
            pre_norm,
        ) {
            Ok(decoder) => Ok(Self { inner: decoder }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create TransformerDecoder: {e}"
            ))),
        }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "TransformerDecoder forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyTransformerDecoder()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyTransformerDecoder {
    fn clone(&self) -> Self {
        // TransformerDecoder doesn't support Clone trait yet
        // Create new instance with reasonable defaults until core adds Clone support
        PyTransformerDecoder {
            inner: TransformerDecoder::new(512, 8, Some(2048), Some(0.1), Some(true)).unwrap(), // reasonable defaults
        }
    }
}

// ResNet Model Class
#[pyclass(unsendable)]
struct PyResNet {
    inner: ResNet<f32>,
}

#[pymethods]
impl PyResNet {
    #[new]
    fn new(model_name: String, num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);

        let resnet = match model_name.as_str() {
            "resnet18" => ResNet::resnet18(num_classes),
            "resnet34" => ResNet::resnet34(num_classes),
            "resnet50" => ResNet::resnet50(num_classes),
            "resnet101" => ResNet::resnet101(num_classes),
            "resnet152" => ResNet::resnet152(num_classes),
            _ => {
                return Err(PyErr::new::<PyRuntimeError, _>(format!(
                    "Unknown ResNet model: {}",
                    model_name
                )))
            }
        };

        Ok(Self { inner: resnet })
    }

    #[staticmethod]
    fn resnet18(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: ResNet::resnet18(num_classes),
        })
    }

    #[staticmethod]
    fn resnet34(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: ResNet::resnet34(num_classes),
        })
    }

    #[staticmethod]
    fn resnet50(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: ResNet::resnet50(num_classes),
        })
    }

    #[staticmethod]
    fn resnet101(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: ResNet::resnet101(num_classes),
        })
    }

    #[staticmethod]
    fn resnet152(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: ResNet::resnet152(num_classes),
        })
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "ResNet forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyResNet()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyResNet {
    fn clone(&self) -> Self {
        // ResNet doesn't support Clone trait yet
        // Create new instance with reasonable defaults until core adds Clone support
        PyResNet {
            inner: ResNet::resnet18(1000), // reasonable default
        }
    }
}

// EfficientNet Model Class
#[pyclass(unsendable)]
struct PyEfficientNet {
    inner: EfficientNet<f32>,
}

#[pymethods]
impl PyEfficientNet {
    #[new]
    fn new(model_name: String, num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);

        let efficientnet = match model_name.as_str() {
            "efficientnet_b0" => EfficientNet::efficientnet_b0(num_classes),
            "efficientnet_b1" => EfficientNet::efficientnet_b1(num_classes),
            "efficientnet_b2" => EfficientNet::efficientnet_b2(num_classes),
            "efficientnet_b3" => EfficientNet::efficientnet_b3(num_classes),
            "efficientnet_b4" => EfficientNet::efficientnet_b4(num_classes),
            "efficientnet_b5" => EfficientNet::efficientnet_b5(num_classes),
            "efficientnet_b6" => EfficientNet::efficientnet_b6(num_classes),
            "efficientnet_b7" => EfficientNet::efficientnet_b7(num_classes),
            _ => {
                return Err(PyErr::new::<PyRuntimeError, _>(format!(
                    "Unknown EfficientNet model: {}",
                    model_name
                )))
            }
        };

        Ok(Self {
            inner: efficientnet,
        })
    }

    #[staticmethod]
    fn efficientnet_b0(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: EfficientNet::efficientnet_b0(num_classes),
        })
    }

    #[staticmethod]
    fn efficientnet_b1(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: EfficientNet::efficientnet_b1(num_classes),
        })
    }

    #[staticmethod]
    fn efficientnet_b2(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: EfficientNet::efficientnet_b2(num_classes),
        })
    }

    #[staticmethod]
    fn efficientnet_b3(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: EfficientNet::efficientnet_b3(num_classes),
        })
    }

    #[staticmethod]
    fn efficientnet_b4(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: EfficientNet::efficientnet_b4(num_classes),
        })
    }

    #[staticmethod]
    fn efficientnet_b5(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: EfficientNet::efficientnet_b5(num_classes),
        })
    }

    #[staticmethod]
    fn efficientnet_b6(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: EfficientNet::efficientnet_b6(num_classes),
        })
    }

    #[staticmethod]
    fn efficientnet_b7(num_classes: Option<usize>) -> PyResult<Self> {
        let num_classes = num_classes.unwrap_or(1000);
        Ok(Self {
            inner: EfficientNet::efficientnet_b7(num_classes),
        })
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "EfficientNet forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyEfficientNet()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyEfficientNet {
    fn clone(&self) -> Self {
        // EfficientNet doesn't support Clone trait yet
        // Create new instance with reasonable defaults until core adds Clone support
        PyEfficientNet {
            inner: EfficientNet::efficientnet_b0(1000), // reasonable default
        }
    }
}

// MaxPool2D Layer Class
#[pyclass]
struct PyMaxPool2D {
    inner: MaxPool2D,
}

#[pymethods]
impl PyMaxPool2D {
    #[new]
    #[pyo3(signature = (kernel_size, stride=None))]
    fn new(kernel_size: (usize, usize), stride: Option<(usize, usize)>) -> Self {
        Self {
            inner: MaxPool2D::new(kernel_size, stride),
        }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "MaxPool2D forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        vec![] // Pooling layers have no parameters
    }

    fn set_training(&mut self, training: bool) {
        <MaxPool2D as Layer<f32>>::set_training(&mut self.inner, training);
    }

    fn __str__(&self) -> String {
        "PyMaxPool2D()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyMaxPool2D {
    fn clone(&self) -> Self {
        PyMaxPool2D {
            inner: MaxPool2D::new((2, 2), None),
        }
    }
}

// AvgPool2D Layer Class
#[pyclass]
struct PyAvgPool2D {
    inner: AvgPool2D,
}

#[pymethods]
impl PyAvgPool2D {
    #[new]
    #[pyo3(signature = (kernel_size, stride=None))]
    fn new(kernel_size: (usize, usize), stride: Option<(usize, usize)>) -> Self {
        Self {
            inner: AvgPool2D::new(kernel_size, stride),
        }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "AvgPool2D forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        vec![] // Pooling layers have no parameters
    }

    fn set_training(&mut self, training: bool) {
        <AvgPool2D as Layer<f32>>::set_training(&mut self.inner, training);
    }

    fn __str__(&self) -> String {
        "PyAvgPool2D()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyAvgPool2D {
    fn clone(&self) -> Self {
        PyAvgPool2D {
            inner: AvgPool2D::new((2, 2), None),
        }
    }
}

// GlobalMaxPool2D Layer Class
#[pyclass]
struct PyGlobalMaxPool2D {
    inner: GlobalMaxPool2D<f32>,
}

#[pymethods]
impl PyGlobalMaxPool2D {
    #[new]
    #[pyo3(signature = (keepdims=None))]
    fn new(keepdims: Option<bool>) -> Self {
        let inner = if let Some(keepdims) = keepdims {
            GlobalMaxPool2D::new().with_keepdims(keepdims)
        } else {
            GlobalMaxPool2D::new()
        };
        Self { inner }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "GlobalMaxPool2D forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        vec![] // Pooling layers have no parameters
    }

    fn set_training(&mut self, training: bool) {
        <GlobalMaxPool2D<f32> as Layer<f32>>::set_training(&mut self.inner, training);
    }

    fn __str__(&self) -> String {
        "PyGlobalMaxPool2D()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyGlobalMaxPool2D {
    fn clone(&self) -> Self {
        PyGlobalMaxPool2D {
            inner: GlobalMaxPool2D::new(),
        }
    }
}

// GlobalAvgPool2D Layer Class
#[pyclass]
struct PyGlobalAvgPool2D {
    inner: GlobalAvgPool2D<f32>,
}

#[pymethods]
impl PyGlobalAvgPool2D {
    #[new]
    #[pyo3(signature = (keepdims=None))]
    fn new(keepdims: Option<bool>) -> Self {
        let inner = if let Some(keepdims) = keepdims {
            GlobalAvgPool2D::new().with_keepdims(keepdims)
        } else {
            GlobalAvgPool2D::new()
        };
        Self { inner }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "GlobalAvgPool2D forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        vec![] // Pooling layers have no parameters
    }

    fn set_training(&mut self, training: bool) {
        <GlobalAvgPool2D<f32> as Layer<f32>>::set_training(&mut self.inner, training);
    }

    fn __str__(&self) -> String {
        "PyGlobalAvgPool2D()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyGlobalAvgPool2D {
    fn clone(&self) -> Self {
        PyGlobalAvgPool2D {
            inner: GlobalAvgPool2D::new(),
        }
    }
}

// ConvTranspose2D Layer Class
#[pyclass]
pub struct PyConvTranspose2D {
    inner: ConvTranspose2D<f32>,
}

#[pymethods]
impl PyConvTranspose2D {
    #[new]
    #[pyo3(signature = (in_channels, out_channels, kernel_size, stride=None, padding=None, output_padding=None, dilation=None, groups=None, use_bias=None))]
    fn new(
        in_channels: usize,
        out_channels: usize,
        kernel_size: (usize, usize),
        stride: Option<(usize, usize)>,
        padding: Option<(usize, usize)>,
        output_padding: Option<(usize, usize)>,
        dilation: Option<(usize, usize)>,
        groups: Option<usize>,
        use_bias: Option<bool>,
    ) -> Self {
        let use_bias = use_bias.unwrap_or(true);
        Self {
            inner: ConvTranspose2D::new(
                in_channels,
                out_channels,
                kernel_size,
                stride,
                padding,
                output_padding,
                dilation,
                groups,
                use_bias,
            ),
        }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "ConvTranspose2D forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyConvTranspose2D()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyConvTranspose2D {
    fn clone(&self) -> Self {
        // ConvTranspose2D doesn't support Clone trait yet
        // Create new instance with reasonable defaults until core adds Clone support
        PyConvTranspose2D {
            inner: ConvTranspose2D::new(32, 64, (3, 3), None, None, None, None, None, true), // reasonable defaults
        }
    }
}

// Sinusoidal Positional Encoding Layer Class
#[pyclass(unsendable)]
struct PySinusoidalPositionalEncoding {
    inner: SinusoidalPositionalEncoding<f32>,
}

#[pymethods]
impl PySinusoidalPositionalEncoding {
    #[new]
    #[pyo3(signature = (d_model, max_len=None, dropout=None))]
    fn new(d_model: usize, max_len: Option<usize>, dropout: Option<f32>) -> PyResult<Self> {
        match SinusoidalPositionalEncoding::new(d_model, max_len, dropout) {
            Ok(encoding) => Ok(PySinusoidalPositionalEncoding { inner: encoding }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create SinusoidalPositionalEncoding: {e}"
            ))),
        }
    }

    fn forward(&self, x: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&x.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "SinusoidalPositionalEncoding forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PySinusoidalPositionalEncoding()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PySinusoidalPositionalEncoding {
    fn clone(&self) -> Self {
        // SinusoidalPositionalEncoding doesn't support Clone trait yet
        // Create new instance with reasonable defaults until core adds Clone support
        PySinusoidalPositionalEncoding {
            inner: SinusoidalPositionalEncoding::new(512, Some(5000), Some(0.1)).unwrap(), // reasonable defaults
        }
    }
}

// Learned Positional Encoding Layer Class
#[pyclass(unsendable)]
struct PyLearnedPositionalEncoding {
    inner: LearnedPositionalEncoding<f32>,
}

#[pymethods]
impl PyLearnedPositionalEncoding {
    #[new]
    #[pyo3(signature = (d_model, max_len=None, dropout=None))]
    fn new(d_model: usize, max_len: Option<usize>, dropout: Option<f32>) -> PyResult<Self> {
        match LearnedPositionalEncoding::new(d_model, max_len, dropout) {
            Ok(encoding) => Ok(PyLearnedPositionalEncoding { inner: encoding }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create LearnedPositionalEncoding: {e}"
            ))),
        }
    }

    fn forward(&self, x: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&x.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "LearnedPositionalEncoding forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyLearnedPositionalEncoding()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyLearnedPositionalEncoding {
    fn clone(&self) -> Self {
        // LearnedPositionalEncoding doesn't support Clone trait yet
        // Create new instance with reasonable defaults until core adds Clone support
        PyLearnedPositionalEncoding {
            inner: LearnedPositionalEncoding::new(512, Some(5000), Some(0.1)).unwrap(), // reasonable defaults
        }
    }
}

// Rotary Positional Embedding Layer Class
#[pyclass(unsendable)]
struct PyRotaryPositionalEmbedding {
    inner: RotaryPositionalEmbedding<f32>,
}

#[pymethods]
impl PyRotaryPositionalEmbedding {
    #[new]
    #[pyo3(signature = (d_model, max_len=None, base=None, scaling_factor=None))]
    fn new(
        d_model: usize,
        max_len: Option<usize>,
        base: Option<f64>,
        scaling_factor: Option<f64>,
    ) -> PyResult<Self> {
        match RotaryPositionalEmbedding::new(d_model, max_len, base, scaling_factor) {
            Ok(encoding) => Ok(PyRotaryPositionalEmbedding { inner: encoding }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create RotaryPositionalEmbedding: {e}"
            ))),
        }
    }

    fn forward(&self, x: &PyTensor, position_offset: Option<usize>) -> PyResult<PyTensor> {
        match self.inner.forward(&x.inner, position_offset) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "RotaryPositionalEmbedding forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn __str__(&self) -> String {
        "PyRotaryPositionalEmbedding()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyRotaryPositionalEmbedding {
    fn clone(&self) -> Self {
        // RotaryPositionalEmbedding doesn't support Clone trait yet
        // Create new instance with reasonable defaults until core adds Clone support
        PyRotaryPositionalEmbedding {
            inner: RotaryPositionalEmbedding::new(512, Some(8192), Some(10000.0), Some(1.0))
                .unwrap(), // reasonable defaults
        }
    }
}

// Embedding Layer Class
#[pyclass(unsendable)]
struct PyEmbedding {
    inner: Embedding<f32>,
}

#[pymethods]
impl PyEmbedding {
    #[new]
    fn new(num_embeddings: usize, embedding_dim: usize) -> Self {
        let embedding = Embedding::new(num_embeddings, embedding_dim);
        Self { inner: embedding }
    }

    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self.inner.forward(&input.inner) {
            Ok(output) => Ok(PyTensor { inner: output }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Embedding forward failed: {e}"
            ))),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        self.inner
            .parameters()
            .into_iter()
            .map(|t| PyTensor {
                inner: (*t).clone(),
            })
            .collect()
    }

    fn set_training(&mut self, training: bool) {
        self.inner.set_training(training);
    }

    fn num_embeddings(&self) -> usize {
        self.inner.num_embeddings()
    }

    fn embedding_dim(&self) -> usize {
        self.inner.embedding_dim()
    }

    // Note: weight() method is not available due to private field access

    fn __str__(&self) -> String {
        format!(
            "PyEmbedding(num_embeddings={}, embedding_dim={})",
            self.inner.num_embeddings(),
            self.inner.embedding_dim()
        )
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl Clone for PyEmbedding {
    fn clone(&self) -> Self {
        // Create a new embedding with the same parameters
        Self::new(self.inner.num_embeddings(), self.inner.embedding_dim())
    }
}

// Helper function to convert f32 tensor to bool tensor
fn convert_f32_to_bool_tensor(tensor: &Tensor<f32>) -> PyResult<Tensor<bool>> {
    if let Some(f32_data) = tensor.as_slice() {
        let shape = tensor.shape().dims().to_vec();
        let bool_data: Vec<bool> = f32_data.iter().map(|&f| f != 0.0).collect();

        match Tensor::from_vec(bool_data, &shape) {
            Ok(tensor) => Ok(tensor),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create bool tensor: {e}"
            ))),
        }
    } else {
        Err(PyErr::new::<PyRuntimeError, _>("Cannot access tensor data"))
    }
}

// Helper function to convert bool tensor to f32 tensor
fn convert_bool_to_f32_tensor(bool_tensor: Tensor<bool>) -> PyResult<Tensor<f32>> {
    let shape = bool_tensor.shape().dims().to_vec();

    if let Some(bool_data) = bool_tensor.as_slice() {
        // Convert bool values to f32: true -> 1.0, false -> 0.0
        let f32_data: Vec<f32> = bool_data
            .iter()
            .map(|&b| if b { 1.0 } else { 0.0 })
            .collect();

        match Tensor::from_vec(f32_data, &shape) {
            Ok(tensor) => Ok(tensor),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to create f32 tensor: {e}"
            ))),
        }
    } else {
        Err(PyErr::new::<PyRuntimeError, _>(
            "Cannot access bool tensor data",
        ))
    }
}

// Helper function to parse device string
fn parse_device_string(device: &str) -> PyResult<Device> {
    let device = device.to_lowercase();
    if device == "cpu" {
        Ok(Device::Cpu)
    } else if device.starts_with("gpu:") || device.starts_with("cuda:") {
        #[cfg(feature = "gpu")]
        {
            let id_str = device.split(':').nth(1).ok_or_else(|| {
                PyErr::new::<PyValueError, _>("Invalid device format. Use 'gpu:0' or 'cuda:0'")
            })?;
            let id = id_str
                .parse::<usize>()
                .map_err(|_| PyErr::new::<PyValueError, _>("Invalid device ID"))?;
            Ok(Device::Gpu(id))
        }
        #[cfg(not(feature = "gpu"))]
        {
            Err(PyErr::new::<PyRuntimeError, _>("GPU support not compiled"))
        }
    } else if device == "gpu" || device == "cuda" {
        #[cfg(feature = "gpu")]
        {
            Ok(Device::Gpu(0))
        }
        #[cfg(not(feature = "gpu"))]
        {
            Err(PyErr::new::<PyRuntimeError, _>("GPU support not compiled"))
        }
    } else {
        Err(PyErr::new::<PyValueError, _>(format!(
            "Unknown device: {device}"
        )))
    }
}

// Tensor creation functions
#[pyfunction]
fn zeros(shape: Vec<usize>) -> PyTensor {
    PyTensor {
        inner: Tensor::zeros(&shape),
    }
}

#[pyfunction]
fn ones(shape: Vec<usize>) -> PyTensor {
    PyTensor {
        inner: Tensor::ones(&shape),
    }
}

#[pyfunction]
fn full(shape: Vec<usize>, value: f32) -> PyTensor {
    PyTensor {
        inner: Tensor::full(&shape, value),
    }
}

#[pyfunction]
fn eye(n: usize) -> PyTensor {
    PyTensor {
        inner: Tensor::eye(n),
    }
}

#[pyfunction]
#[pyo3(signature = (start, end, step=None))]
fn arange(start: f32, end: f32, step: Option<f32>) -> PyResult<PyTensor> {
    let step = step.unwrap_or(1.0);
    match Tensor::arange(start, end, step) {
        Ok(tensor) => Ok(PyTensor { inner: tensor }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn linspace(start: f32, end: f32, steps: usize) -> PyResult<PyTensor> {
    match Tensor::linspace(start, end, steps) {
        Ok(tensor) => Ok(PyTensor { inner: tensor }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn from_scalar(value: f32) -> PyTensor {
    PyTensor {
        inner: Tensor::from_scalar(value),
    }
}

#[pyfunction]
fn from_numpy(array: PyReadonlyArrayDyn<f32>) -> PyResult<PyTensor> {
    let ndarray = array.as_array();

    // Handle non-contiguous arrays by making them contiguous
    let owned_array = if ndarray.is_standard_layout() {
        // Already contiguous, just clone
        ndarray.to_owned()
    } else {
        // Make contiguous by creating a new array with standard layout
        // Use as_standard_layout which returns a CowArray, then to_owned to get ArrayD
        ndarray.as_standard_layout().to_owned()
    };

    Ok(PyTensor {
        inner: Tensor::from_array(owned_array),
    })
}

#[pyfunction]
fn from_vec(data: Vec<f32>, shape: Vec<usize>) -> PyResult<PyTensor> {
    match Tensor::from_vec(data, &shape) {
        Ok(tensor) => Ok(PyTensor { inner: tensor }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

// Random tensor creation functions
#[pyfunction]
#[pyo3(signature = (shape, seed=None))]
fn randn(shape: Vec<usize>, seed: Option<u64>) -> PyResult<PyTensor> {
    match random::randn_f32(&shape, seed) {
        Ok(tensor) => Ok(PyTensor { inner: tensor }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
#[pyo3(signature = (shape, seed=None))]
fn rand(shape: Vec<usize>, seed: Option<u64>) -> PyResult<PyTensor> {
    match random::rand_f32(&shape, seed) {
        Ok(tensor) => Ok(PyTensor { inner: tensor }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
#[pyo3(signature = (shape, mean=None, std=None, seed=None))]
fn random_normal(
    shape: Vec<usize>,
    mean: Option<f32>,
    std: Option<f32>,
    seed: Option<u64>,
) -> PyResult<PyTensor> {
    let mean = mean.unwrap_or(0.0);
    let std = std.unwrap_or(1.0);
    match random::random_normal_f32(&shape, mean, std, seed) {
        Ok(tensor) => Ok(PyTensor { inner: tensor }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
#[pyo3(signature = (shape, min=None, max=None, seed=None))]
fn random_uniform(
    shape: Vec<usize>,
    min: Option<f32>,
    max: Option<f32>,
    seed: Option<u64>,
) -> PyResult<PyTensor> {
    let min = min.unwrap_or(0.0);
    let max = max.unwrap_or(1.0);
    match random::random_uniform_f32(&shape, min, max, seed) {
        Ok(tensor) => Ok(PyTensor { inner: tensor }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
#[pyo3(signature = (start, stop, num, base=None))]
fn logspace(start: f32, stop: f32, num: usize, base: Option<f32>) -> PyResult<PyTensor> {
    let base = base.unwrap_or(10.0);
    let linspace_result = Tensor::linspace(start, stop, num)
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    // Convert to base^x
    if let Some(data) = linspace_result.as_slice() {
        let log_data: Vec<f32> = data.iter().map(|&x| base.powf(x)).collect();
        let shape = linspace_result.shape().dims().to_vec();
        let result = Tensor::from_vec(log_data, &shape)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
        Ok(PyTensor { inner: result })
    } else {
        Err(PyErr::new::<PyRuntimeError, _>(
            "Failed to access tensor data",
        ))
    }
}

#[pyfunction]
fn empty(shape: Vec<usize>) -> PyTensor {
    // Create uninitialized tensor - for safety, we'll fill with zeros
    PyTensor {
        inner: Tensor::zeros(&shape),
    }
}

#[pyfunction]
#[pyo3(signature = (v=None, k=None))]
fn diag(v: Option<&PyTensor>, k: Option<i32>) -> PyResult<PyTensor> {
    let k = k.unwrap_or(0);

    match v {
        Some(tensor) => {
            // Extract diagonal from 2D tensor or create diagonal matrix from 1D tensor
            let shape = tensor.shape();
            if shape.len() == 1 {
                // Create diagonal matrix from 1D tensor
                let n = shape[0];
                let matrix_size = (n as i32 + k.abs()) as usize;

                if let Some(input_data) = tensor.inner.as_slice() {
                    let mut result_data = vec![0.0f32; matrix_size * matrix_size];

                    for (i, &val) in input_data.iter().enumerate() {
                        let row = if k >= 0 { i } else { (i as i32 - k) as usize };
                        let col = if k >= 0 { (i as i32 + k) as usize } else { i };
                        if row < matrix_size && col < matrix_size {
                            result_data[row * matrix_size + col] = val;
                        }
                    }

                    let result = Tensor::from_vec(result_data, &[matrix_size, matrix_size])
                        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
                    Ok(PyTensor { inner: result })
                } else {
                    Err(PyErr::new::<PyRuntimeError, _>("Cannot access tensor data"))
                }
            } else if shape.len() == 2 {
                // Extract diagonal from 2D tensor
                let rows = shape[0];
                let cols = shape[1];
                let diag_size =
                    std::cmp::min(rows as i32 - k.max(0), cols as i32 + k.min(0)) as usize;

                if let Some(input_data) = tensor.inner.as_slice() {
                    let mut diag_data = Vec::with_capacity(diag_size);
                    for i in 0..diag_size {
                        let row = if k >= 0 { i } else { (i as i32 - k) as usize };
                        let col = if k >= 0 { (i as i32 + k) as usize } else { i };
                        if row < rows && col < cols {
                            diag_data.push(input_data[row * cols + col]);
                        }
                    }
                    let result = Tensor::from_vec(diag_data, &[diag_size])
                        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
                    Ok(PyTensor { inner: result })
                } else {
                    Err(PyErr::new::<PyRuntimeError, _>("Cannot access tensor data"))
                }
            } else {
                Err(PyErr::new::<PyValueError, _>(
                    "Input must be 1D or 2D tensor",
                ))
            }
        }
        None => {
            // Create identity matrix
            let result = Tensor::eye(3); // Default size, user should specify
            Ok(PyTensor { inner: result })
        }
    }
}

#[pyfunction]
#[pyo3(signature = (n, m=None, k=None))]
fn tri(n: usize, m: Option<usize>, k: Option<i32>) -> PyResult<PyTensor> {
    let m = m.unwrap_or(n);
    let k = k.unwrap_or(0);

    let mut result_data = vec![0.0f32; n * m];

    for i in 0..n {
        for j in 0..m {
            if (j as i32) <= (i as i32 + k) {
                result_data[i * m + j] = 1.0;
            }
        }
    }

    let result = Tensor::from_vec(result_data, &[n, m]).map_err(|e| {
        PyErr::new::<PyRuntimeError, _>(format!("Failed to create triangular matrix: {}", e))
    })?;

    Ok(PyTensor { inner: result })
}

#[pyfunction]
#[pyo3(signature = (shape, min, max, seed=None))]
fn randint(shape: Vec<usize>, min: i64, max: i64, seed: Option<u64>) -> PyResult<PyTensor> {
    match random::random_uniform_int(&shape, min, max, seed) {
        Ok(tensor) => {
            // Convert i64 tensor to f32 tensor for consistency
            // This is a placeholder - ideally we'd support multiple dtypes
            let data: Vec<f32> = tensor
                .as_slice()
                .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Failed to get tensor data"))?
                .iter()
                .map(|&x| x as f32)
                .collect();
            let f32_tensor = Tensor::from_vec(data, &shape)
                .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
            Ok(PyTensor { inner: f32_tensor })
        }
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

// Device utility functions
#[pyfunction]
fn is_gpu_available() -> bool {
    #[cfg(feature = "gpu")]
    {
        // Check if any GPU devices are available by querying the device placement manager
        let placement = DevicePlacement::new(
            tenflowers_core::device::placement::PlacementStrategy::FirstAvailable,
        );
        placement
            .available_devices()
            .iter()
            .any(|device| device.is_gpu())
    }
    #[cfg(not(feature = "gpu"))]
    {
        false
    }
}

#[pyfunction]
fn get_device_count() -> usize {
    #[cfg(feature = "gpu")]
    {
        // Count GPU devices available through the device placement manager
        let placement = DevicePlacement::new(
            tenflowers_core::device::placement::PlacementStrategy::FirstAvailable,
        );
        placement
            .available_devices()
            .iter()
            .filter(|device| device.is_gpu())
            .count()
    }
    #[cfg(not(feature = "gpu"))]
    {
        0
    }
}

#[pyfunction]
fn set_default_device(device: &str) -> PyResult<()> {
    let device = parse_device_string(device)?;

    let lock = get_default_device_lock();
    match lock.write() {
        Ok(mut default_device) => {
            *default_device = device;
            Ok(())
        }
        Err(_) => Err(PyErr::new::<PyRuntimeError, _>(
            "Failed to acquire device lock for writing",
        )),
    }
}

#[pyfunction]
fn get_default_device_string() -> PyResult<String> {
    match get_default_device() {
        Ok(device) => Ok(device.to_string()),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e)),
    }
}

// Memory management functions
#[pyfunction]
#[pyo3(signature = (device=None))]
fn memory_allocated(device: Option<&str>) -> PyResult<usize> {
    let device = if let Some(dev) = device {
        parse_device_string(dev)?
    } else {
        Device::Cpu
    };

    // Get current memory usage from performance monitor
    match device {
        Device::Cpu => {
            // Use global performance monitor for CPU memory tracking
            let monitor = global_monitor();
            Ok(monitor.get_current_memory())
        }
        _ => {
            // For non-CPU devices, attempt to get memory from device context
            match DEVICE_MANAGER.get_context(&device) {
                Ok(context) => {
                    // Use performance monitor as fallback for any device
                    let monitor = global_monitor();
                    Ok(monitor.get_current_memory())
                }
                Err(_) => Ok(0),
            }
        }
    }
}

#[pyfunction]
#[pyo3(signature = (device=None))]
fn memory_reserved(device: Option<&str>) -> PyResult<usize> {
    let device = if let Some(dev) = device {
        parse_device_string(dev)?
    } else {
        Device::Cpu
    };

    // Get device context and query reserved memory capacity
    match DEVICE_MANAGER.get_context(&device) {
        Ok(context) => {
            let properties = context.properties();
            // Return total device memory capacity as reserved memory
            Ok(properties.total_memory)
        }
        Err(_) => {
            // Fallback: estimate system memory for CPU, return 0 for unknown devices
            match device {
                Device::Cpu => {
                    // For CPU, estimate available system memory (simplified)
                    Ok(8_000_000_000) // 8GB default estimate
                }
                _ => Ok(0),
            }
        }
    }
}

#[pyfunction]
#[pyo3(signature = (device=None))]
fn empty_cache(device: Option<&str>) -> PyResult<()> {
    let device = if let Some(dev) = device {
        parse_device_string(dev)?
    } else {
        Device::Cpu
    };

    // Clear memory caches based on device type
    match device {
        Device::Cpu => {
            // Clear CPU memory tracking in performance monitor
            let monitor = global_monitor();
            monitor.clear();
            Ok(())
        }
        _ => {
            // For non-CPU devices, attempt to synchronize and clear caches
            match DEVICE_MANAGER.get_context(&device) {
                Ok(context) => {
                    // Synchronize device to ensure all operations complete
                    context.synchronize().unwrap_or(());
                    // Clear global performance monitor as fallback
                    let monitor = global_monitor();
                    monitor.clear();
                    Ok(())
                }
                Err(_) => {
                    // Just clear global monitor if device context unavailable
                    let monitor = global_monitor();
                    monitor.clear();
                    Ok(())
                }
            }
        }
    }
}

#[pyfunction]
#[pyo3(signature = (device=None))]
fn memory_stats(device: Option<&str>) -> PyResult<PyObject> {
    let device = if let Some(dev) = device {
        parse_device_string(dev)?
    } else {
        Device::Cpu
    };

    Python::with_gil(|py| {
        let dict = PyDict::new(py);

        // Get device context and query memory statistics
        match DEVICE_MANAGER.get_context(&device) {
            Ok(context) => {
                let properties = context.properties();
                dict.set_item("total_memory", properties.total_memory)?;
                dict.set_item("device_name", properties.name)?;
                dict.set_item("allocated", 0usize)?;
                dict.set_item("reserved", 0usize)?;
                dict.set_item("free", properties.total_memory)?;
                dict.set_item("cached", 0usize)?;
            }
            Err(_) => {
                // Fallback values if device context cannot be obtained
                dict.set_item("allocated", 0usize)?;
                dict.set_item("reserved", 0usize)?;
                dict.set_item("free", 0usize)?;
                dict.set_item("cached", 0usize)?;
            }
        }

        Ok(dict.into())
    })
}

// Profiling utilities
#[pyfunction]
fn memory_profiler_start() -> PyResult<()> {
    let lock = get_memory_profiling_lock();
    match lock.write() {
        Ok(mut state) => {
            if state.is_profiling {
                return Err(PyErr::new::<PyRuntimeError, _>(
                    "Memory profiling is already running",
                ));
            }

            // Get initial memory usage
            let initial_memory = memory_allocated(None).unwrap_or_default();

            state.is_profiling = true;
            state.start_time = Some(std::time::Instant::now());
            state.peak_memory = initial_memory;
            state.total_allocations = 0;
            state.total_deallocations = 0;
            state.initial_memory = initial_memory;

            Ok(())
        }
        Err(_) => Err(PyErr::new::<PyRuntimeError, _>(
            "Failed to acquire profiling lock for writing",
        )),
    }
}

#[pyfunction]
fn memory_profiler_stop() -> PyResult<PyObject> {
    let lock = get_memory_profiling_lock();
    match lock.write() {
        Ok(mut state) => {
            if !state.is_profiling {
                return Err(PyErr::new::<PyRuntimeError, _>(
                    "Memory profiling is not running",
                ));
            }

            // Get current memory usage for final calculations
            let current_memory = memory_allocated(None).unwrap_or_default();

            // Update peak memory if current is higher
            if current_memory > state.peak_memory {
                state.peak_memory = current_memory;
            }

            // Calculate duration
            let duration = state
                .start_time
                .map(|start| start.elapsed().as_secs_f64())
                .unwrap_or(0.0);

            // Create result dictionary
            Python::with_gil(|py| {
                let dict = PyDict::new(py);

                dict.set_item("peak_memory", state.peak_memory)?;
                dict.set_item("initial_memory", state.initial_memory)?;
                dict.set_item("final_memory", current_memory)?;
                dict.set_item(
                    "memory_delta",
                    current_memory.saturating_sub(state.initial_memory),
                )?;
                dict.set_item("total_allocations", state.total_allocations)?;
                dict.set_item("total_deallocations", state.total_deallocations)?;
                dict.set_item("duration_seconds", duration)?;
                dict.set_item("profiling_active", false)?;

                // Reset profiling state
                state.is_profiling = false;
                state.start_time = None;
                state.peak_memory = 0;
                state.total_allocations = 0;
                state.total_deallocations = 0;
                state.initial_memory = 0;

                Ok(dict.into())
            })
        }
        Err(_) => Err(PyErr::new::<PyRuntimeError, _>(
            "Failed to acquire profiling lock for writing",
        )),
    }
}

#[pyfunction]
fn memory_profiler_status() -> PyResult<PyObject> {
    let lock = get_memory_profiling_lock();
    match lock.read() {
        Ok(state) => Python::with_gil(|py| {
            let dict = PyDict::new(py);

            dict.set_item("is_profiling", state.is_profiling)?;
            dict.set_item("initial_memory", state.initial_memory)?;
            dict.set_item("current_peak_memory", state.peak_memory)?;
            dict.set_item("total_allocations", state.total_allocations)?;
            dict.set_item("total_deallocations", state.total_deallocations)?;

            if let Some(start_time) = state.start_time {
                let elapsed = start_time.elapsed().as_secs_f64();
                dict.set_item("elapsed_seconds", elapsed)?;
            } else {
                dict.set_item("elapsed_seconds", py.None())?;
            }

            Ok(dict.into())
        }),
        Err(_) => Err(PyErr::new::<PyRuntimeError, _>(
            "Failed to acquire profiling lock for reading",
        )),
    }
}

// Loss Functions
#[pyfunction]
fn mse_loss(predictions: &PyTensor, targets: &PyTensor) -> PyResult<PyTensor> {
    match mse(&predictions.inner, &targets.inner) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn binary_cross_entropy_loss(predictions: &PyTensor, targets: &PyTensor) -> PyResult<PyTensor> {
    match binary_cross_entropy(&predictions.inner, &targets.inner) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn l1_loss(predictions: &PyTensor, targets: &PyTensor) -> PyResult<PyTensor> {
    match l1_loss_impl(&predictions.inner, &targets.inner) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn smooth_l1_loss(predictions: &PyTensor, targets: &PyTensor) -> PyResult<PyTensor> {
    match smooth_l1_loss_impl(&predictions.inner, &targets.inner) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn categorical_cross_entropy_loss(
    predictions: &PyTensor,
    targets: &PyTensor,
) -> PyResult<PyTensor> {
    match categorical_cross_entropy(&predictions.inner, &targets.inner) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
#[pyo3(signature = (predictions, targets, alpha=1.0, gamma=2.0))]
fn focal_loss(
    predictions: &PyTensor,
    targets: &PyTensor,
    alpha: Option<f32>,
    gamma: Option<f32>,
) -> PyResult<PyTensor> {
    let alpha = alpha.unwrap_or(1.0);
    let gamma = gamma.unwrap_or(2.0);
    match focal_loss_impl(&predictions.inner, &targets.inner, alpha, gamma) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn hinge_loss(predictions: &PyTensor, targets: &PyTensor) -> PyResult<PyTensor> {
    match hinge_loss_impl(&predictions.inner, &targets.inner) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
#[pyo3(signature = (predictions, targets, delta=1.0))]
fn huber_loss(
    predictions: &PyTensor,
    targets: &PyTensor,
    delta: Option<f32>,
) -> PyResult<PyTensor> {
    let delta = delta.unwrap_or(1.0);
    match huber_loss_impl(&predictions.inner, &targets.inner, delta) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn quantile_loss(predictions: &PyTensor, targets: &PyTensor, quantile: f32) -> PyResult<PyTensor> {
    match quantile_loss_impl(&predictions.inner, &targets.inner, quantile) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn sparse_categorical_cross_entropy_loss(
    logits: &PyTensor,
    labels: Vec<i64>,
) -> PyResult<PyTensor> {
    // Convert labels to tensor
    let labels_tensor = match Tensor::from_vec(labels, &[logits.shape()[0]]) {
        Ok(tensor) => tensor,
        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    };

    match sparse_categorical_cross_entropy(&logits.inner, &labels_tensor) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn nll_loss(log_probs: &PyTensor, targets: Vec<i64>) -> PyResult<PyTensor> {
    // Convert targets to tensor
    let targets_tensor = match Tensor::from_vec(targets, &[log_probs.shape()[0]]) {
        Ok(tensor) => tensor,
        Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    };

    match nll_loss_impl(&log_probs.inner, &targets_tensor) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn triplet_margin_loss(
    anchor: &PyTensor,
    positive: &PyTensor,
    negative: &PyTensor,
    margin: Option<f32>,
) -> PyResult<PyTensor> {
    let margin_val = margin.unwrap_or(1.0);
    match triplet_loss(&anchor.inner, &positive.inner, &negative.inner, margin_val) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn cosine_embedding_loss(
    input1: &PyTensor,
    input2: &PyTensor,
    target: &PyTensor,
    margin: Option<f32>,
) -> PyResult<PyTensor> {
    let margin_val = margin.unwrap_or(0.0);
    match cosine_embedding_loss_impl(&input1.inner, &input2.inner, &target.inner, margin_val) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn kl_div_loss(input: &PyTensor, target: &PyTensor, reduction: Option<&str>) -> PyResult<PyTensor> {
    match kl_div_loss_impl(&input.inner, &target.inner, reduction) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

// Module enum to support heterogeneous containers
#[pyclass(unsendable)]
#[derive(Clone)]
#[allow(clippy::large_enum_variant)]
pub enum PyNeuralModule {
    Dense(PyDense),
    Activation(PyActivation),
    BatchNorm(PyBatchNorm),
    Conv1D(PyConv1D),
    Conv2D(PyConv2D),
    Conv3D(PyConv3D),
    ConvTranspose2D(PyConvTranspose2D),
    LSTM(PyLSTM),
    GRU(PyGRU),
    RNN(PyRNN),
    MultiHeadAttention(PyMultiHeadAttention),
    TransformerEncoder(PyTransformerEncoder),
    TransformerDecoder(PyTransformerDecoder),
    MaxPool2D(PyMaxPool2D),
    AvgPool2D(PyAvgPool2D),
    GlobalMaxPool2D(PyGlobalMaxPool2D),
    GlobalAvgPool2D(PyGlobalAvgPool2D),
    SinusoidalPositionalEncoding(PySinusoidalPositionalEncoding),
    LearnedPositionalEncoding(PyLearnedPositionalEncoding),
    RotaryPositionalEmbedding(PyRotaryPositionalEmbedding),
    Embedding(PyEmbedding),
    ResNet(PyResNet),
    EfficientNet(PyEfficientNet),
}

#[pymethods]
impl PyNeuralModule {
    fn forward(&self, input: &PyTensor) -> PyResult<PyTensor> {
        match self {
            PyNeuralModule::Dense(layer) => layer.forward(input),
            PyNeuralModule::Activation(layer) => layer.forward(input),
            PyNeuralModule::BatchNorm(layer) => layer.forward(input),
            PyNeuralModule::Conv1D(layer) => layer.forward(input),
            PyNeuralModule::Conv2D(layer) => layer.forward(input),
            PyNeuralModule::Conv3D(layer) => layer.forward(input),
            PyNeuralModule::ConvTranspose2D(layer) => layer.forward(input),
            PyNeuralModule::LSTM(layer) => layer.forward(input),
            PyNeuralModule::GRU(layer) => layer.forward(input),
            PyNeuralModule::RNN(layer) => layer.forward(input),
            PyNeuralModule::MultiHeadAttention(layer) => layer.forward(input),
            PyNeuralModule::TransformerEncoder(layer) => layer.forward(input),
            PyNeuralModule::TransformerDecoder(layer) => layer.forward(input),
            PyNeuralModule::MaxPool2D(layer) => layer.forward(input),
            PyNeuralModule::AvgPool2D(layer) => layer.forward(input),
            PyNeuralModule::GlobalMaxPool2D(layer) => layer.forward(input),
            PyNeuralModule::GlobalAvgPool2D(layer) => layer.forward(input),
            PyNeuralModule::SinusoidalPositionalEncoding(layer) => layer.forward(input),
            PyNeuralModule::LearnedPositionalEncoding(layer) => layer.forward(input),
            PyNeuralModule::RotaryPositionalEmbedding(layer) => {
                // PyRotaryPositionalEmbedding forward takes position_offset parameter
                layer.forward(input, None)
            }
            PyNeuralModule::Embedding(layer) => layer.forward(input),
            PyNeuralModule::ResNet(layer) => layer.forward(input),
            PyNeuralModule::EfficientNet(layer) => layer.forward(input),
        }
    }

    fn parameters(&self) -> Vec<PyTensor> {
        match self {
            PyNeuralModule::Dense(layer) => layer.parameters(),
            PyNeuralModule::Activation(layer) => layer.parameters(),
            PyNeuralModule::BatchNorm(layer) => layer.parameters(),
            PyNeuralModule::Conv1D(layer) => layer.parameters(),
            PyNeuralModule::Conv2D(layer) => layer.parameters(),
            PyNeuralModule::Conv3D(layer) => layer.parameters(),
            PyNeuralModule::ConvTranspose2D(layer) => layer.parameters(),
            PyNeuralModule::LSTM(layer) => layer.parameters(),
            PyNeuralModule::GRU(layer) => layer.parameters(),
            PyNeuralModule::RNN(layer) => layer.parameters(),
            PyNeuralModule::MultiHeadAttention(layer) => layer.parameters(),
            PyNeuralModule::TransformerEncoder(layer) => layer.parameters(),
            PyNeuralModule::TransformerDecoder(layer) => layer.parameters(),
            PyNeuralModule::MaxPool2D(layer) => layer.parameters(),
            PyNeuralModule::AvgPool2D(layer) => layer.parameters(),
            PyNeuralModule::GlobalMaxPool2D(layer) => layer.parameters(),
            PyNeuralModule::GlobalAvgPool2D(layer) => layer.parameters(),
            PyNeuralModule::SinusoidalPositionalEncoding(layer) => layer.parameters(),
            PyNeuralModule::LearnedPositionalEncoding(layer) => layer.parameters(),
            PyNeuralModule::RotaryPositionalEmbedding(layer) => layer.parameters(),
            PyNeuralModule::Embedding(layer) => layer.parameters(),
            PyNeuralModule::ResNet(layer) => layer.parameters(),
            PyNeuralModule::EfficientNet(layer) => layer.parameters(),
        }
    }

    // Note: train() and eval() methods removed since PyNeuralModule is frozen
    // Individual layer training modes should be managed directly

    fn __str__(&self) -> String {
        match self {
            PyNeuralModule::Dense(layer) => layer.__str__(),
            PyNeuralModule::Activation(layer) => layer.__str__(),
            PyNeuralModule::BatchNorm(layer) => layer.__str__(),
            PyNeuralModule::Conv1D(layer) => layer.__str__(),
            PyNeuralModule::Conv2D(layer) => layer.__str__(),
            PyNeuralModule::Conv3D(layer) => layer.__str__(),
            PyNeuralModule::ConvTranspose2D(layer) => layer.__str__(),
            PyNeuralModule::LSTM(layer) => layer.__str__(),
            PyNeuralModule::GRU(layer) => layer.__str__(),
            PyNeuralModule::RNN(layer) => layer.__str__(),
            PyNeuralModule::MultiHeadAttention(layer) => layer.__str__(),
            PyNeuralModule::TransformerEncoder(layer) => layer.__str__(),
            PyNeuralModule::TransformerDecoder(layer) => layer.__str__(),
            PyNeuralModule::MaxPool2D(layer) => layer.__str__(),
            PyNeuralModule::AvgPool2D(layer) => layer.__str__(),
            PyNeuralModule::GlobalMaxPool2D(layer) => layer.__str__(),
            PyNeuralModule::GlobalAvgPool2D(layer) => layer.__str__(),
            PyNeuralModule::SinusoidalPositionalEncoding(layer) => layer.__str__(),
            PyNeuralModule::LearnedPositionalEncoding(layer) => layer.__str__(),
            PyNeuralModule::RotaryPositionalEmbedding(layer) => layer.__str__(),
            PyNeuralModule::Embedding(layer) => layer.__str__(),
            PyNeuralModule::ResNet(layer) => layer.__str__(),
            PyNeuralModule::EfficientNet(layer) => layer.__str__(),
        }
    }
}

// ModuleList - Container that holds a list of modules
#[pyclass(unsendable)]
#[derive(Clone)]
struct PyModuleList {
    modules: Vec<PyNeuralModule>,
    training: bool,
}

#[pymethods]
impl PyModuleList {
    #[new]
    #[pyo3(signature = (modules=None))]
    fn new(modules: Option<Vec<PyNeuralModule>>) -> Self {
        Self {
            modules: modules.unwrap_or_default(),
            training: false,
        }
    }

    fn append(&mut self, module: PyNeuralModule) {
        self.modules.push(module);
    }

    fn extend(&mut self, modules: Vec<PyNeuralModule>) {
        self.modules.extend(modules);
    }

    fn insert(&mut self, index: usize, module: PyNeuralModule) -> PyResult<()> {
        if index > self.modules.len() {
            return Err(PyErr::new::<PyIndexError, _>("Index out of range"));
        }
        self.modules.insert(index, module);
        Ok(())
    }

    #[pyo3(signature = (index=None))]
    fn pop(&mut self, index: Option<usize>) -> PyResult<PyNeuralModule> {
        let idx = index.unwrap_or(self.modules.len().saturating_sub(1));
        if idx >= self.modules.len() {
            return Err(PyErr::new::<PyIndexError, _>("Index out of range"));
        }
        Ok(self.modules.remove(idx))
    }

    fn __len__(&self) -> usize {
        self.modules.len()
    }

    fn __getitem__(&self, index: isize) -> PyResult<PyNeuralModule> {
        let len = self.modules.len() as isize;
        let idx = if index < 0 { len + index } else { index };

        if idx < 0 || idx >= len {
            return Err(PyErr::new::<PyIndexError, _>("Index out of range"));
        }

        Ok(self.modules[idx as usize].clone())
    }

    fn __setitem__(&mut self, index: isize, module: PyNeuralModule) -> PyResult<()> {
        let len = self.modules.len() as isize;
        let idx = if index < 0 { len + index } else { index };

        if idx < 0 || idx >= len {
            return Err(PyErr::new::<PyIndexError, _>("Index out of range"));
        }

        self.modules[idx as usize] = module;
        Ok(())
    }

    fn parameters(&self) -> Vec<PyTensor> {
        let mut all_params = Vec::new();
        for module in &self.modules {
            all_params.extend(module.parameters());
        }
        all_params
    }

    fn named_parameters(&self) -> Vec<(String, PyTensor)> {
        let mut named_params = Vec::new();
        for (module_idx, module) in self.modules.iter().enumerate() {
            let module_params = module.parameters();
            for (param_idx, param) in module_params.iter().enumerate() {
                let param_name = format!("{module_idx}.{param_idx}");
                named_params.push((param_name, param.clone()));
            }
        }
        named_params
    }

    fn train(&mut self) {
        self.training = true;
        // Note: Individual module training modes should be managed directly
        // since PyNeuralModule is frozen
    }

    fn eval(&mut self) {
        self.training = false;
        // Note: Individual module training modes should be managed directly
        // since PyNeuralModule is frozen
    }

    fn __str__(&self) -> String {
        format!("PyModuleList({} modules)", self.modules.len())
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// ModuleDict - Container that holds a dictionary of modules
#[pyclass(unsendable)]
#[derive(Clone)]
struct PyModuleDict {
    modules: std::collections::HashMap<String, PyNeuralModule>,
    training: bool,
}

#[pymethods]
impl PyModuleDict {
    #[new]
    #[pyo3(signature = (modules=None))]
    fn new(modules: Option<&Bound<'_, pyo3::types::PyDict>>) -> PyResult<Self> {
        let mut module_dict = std::collections::HashMap::new();

        if let Some(py_dict) = modules {
            for item in py_dict.items() {
                let key_str: String = item.get_item(0)?.extract()?;
                let module: PyNeuralModule = item.get_item(1)?.extract()?;
                module_dict.insert(key_str, module);
            }
        }

        Ok(Self {
            modules: module_dict,
            training: false,
        })
    }

    fn __setitem__(&mut self, key: String, module: PyNeuralModule) {
        self.modules.insert(key, module);
    }

    fn __getitem__(&self, key: &str) -> PyResult<PyNeuralModule> {
        self.modules
            .get(key)
            .cloned()
            .ok_or_else(|| PyErr::new::<PyValueError, _>(format!("Key '{key}' not found")))
    }

    fn __delitem__(&mut self, key: &str) -> PyResult<()> {
        self.modules
            .remove(key)
            .ok_or_else(|| PyErr::new::<PyValueError, _>(format!("Key '{key}' not found")))
            .map(|_| ())
    }

    fn __contains__(&self, key: &str) -> bool {
        self.modules.contains_key(key)
    }

    fn __len__(&self) -> usize {
        self.modules.len()
    }

    fn keys(&self) -> Vec<String> {
        self.modules.keys().cloned().collect()
    }

    fn values(&self) -> Vec<PyNeuralModule> {
        self.modules.values().cloned().collect()
    }

    fn items(&self) -> Vec<(String, PyNeuralModule)> {
        self.modules
            .iter()
            .map(|(k, v)| (k.clone(), v.clone()))
            .collect()
    }

    fn update(&mut self, other: &Bound<'_, pyo3::types::PyDict>) -> PyResult<()> {
        for item in other.items() {
            let key_str: String = item.get_item(0)?.extract()?;
            let module: PyNeuralModule = item.get_item(1)?.extract()?;
            self.modules.insert(key_str, module);
        }
        Ok(())
    }

    fn clear(&mut self) {
        self.modules.clear();
    }

    #[pyo3(signature = (key, default=None))]
    fn pop(&mut self, key: &str, default: Option<PyNeuralModule>) -> PyResult<PyNeuralModule> {
        self.modules
            .remove(key)
            .or(default)
            .ok_or_else(|| PyErr::new::<PyValueError, _>(format!("Key '{key}' not found")))
    }

    fn parameters(&self) -> Vec<PyTensor> {
        let mut all_params = Vec::new();
        for module in self.modules.values() {
            all_params.extend(module.parameters());
        }
        all_params
    }

    fn named_parameters(&self) -> Vec<(String, PyTensor)> {
        let mut named_params = Vec::new();
        for (module_name, module) in &self.modules {
            let module_params = module.parameters();
            for (param_idx, param) in module_params.iter().enumerate() {
                let param_name = format!("{module_name}.{param_idx}");
                named_params.push((param_name, param.clone()));
            }
        }
        named_params
    }

    fn train(&mut self) {
        self.training = true;
        // Note: Individual module training modes should be managed directly
        // since PyNeuralModule is frozen
    }

    fn eval(&mut self) {
        self.training = false;
        // Note: Individual module training modes should be managed directly
        // since PyNeuralModule is frozen
    }

    fn __str__(&self) -> String {
        format!("PyModuleDict({} modules)", self.modules.len())
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// Helper functions to create PyModule from specific layer types
#[pyfunction]
fn dense_module(layer: PyDense) -> PyNeuralModule {
    PyNeuralModule::Dense(layer)
}

#[pyfunction]
fn activation_module(layer: PyActivation) -> PyNeuralModule {
    PyNeuralModule::Activation(layer)
}

#[pyfunction]
fn batchnorm_module(layer: PyBatchNorm) -> PyNeuralModule {
    PyNeuralModule::BatchNorm(layer)
}

#[pyfunction]
fn conv1d_module(layer: PyConv1D) -> PyNeuralModule {
    PyNeuralModule::Conv1D(layer)
}

#[pyfunction]
fn conv2d_module(layer: PyConv2D) -> PyNeuralModule {
    PyNeuralModule::Conv2D(layer)
}

#[pyfunction]
fn conv3d_module(layer: PyConv3D) -> PyNeuralModule {
    PyNeuralModule::Conv3D(layer)
}

#[pyfunction]
fn convtranspose2d_module(layer: PyConvTranspose2D) -> PyNeuralModule {
    PyNeuralModule::ConvTranspose2D(layer)
}

#[pyfunction]
fn lstm_module(layer: PyLSTM) -> PyNeuralModule {
    PyNeuralModule::LSTM(layer)
}

#[pyfunction]
fn gru_module(layer: PyGRU) -> PyNeuralModule {
    PyNeuralModule::GRU(layer)
}

#[pyfunction]
fn rnn_module(layer: PyRNN) -> PyNeuralModule {
    PyNeuralModule::RNN(layer)
}

#[pyfunction]
fn multiheadattention_module(layer: PyMultiHeadAttention) -> PyNeuralModule {
    PyNeuralModule::MultiHeadAttention(layer)
}

#[pyfunction]
fn transformerencoder_module(layer: PyTransformerEncoder) -> PyNeuralModule {
    PyNeuralModule::TransformerEncoder(layer)
}

#[pyfunction]
fn transformerdecoder_module(layer: PyTransformerDecoder) -> PyNeuralModule {
    PyNeuralModule::TransformerDecoder(layer)
}

#[pyfunction]
fn maxpool2d_module(layer: PyMaxPool2D) -> PyNeuralModule {
    PyNeuralModule::MaxPool2D(layer)
}

#[pyfunction]
fn avgpool2d_module(layer: PyAvgPool2D) -> PyNeuralModule {
    PyNeuralModule::AvgPool2D(layer)
}

#[pyfunction]
fn globalmaxpool2d_module(layer: PyGlobalMaxPool2D) -> PyNeuralModule {
    PyNeuralModule::GlobalMaxPool2D(layer)
}

#[pyfunction]
fn globalavgpool2d_module(layer: PyGlobalAvgPool2D) -> PyNeuralModule {
    PyNeuralModule::GlobalAvgPool2D(layer)
}

#[pyfunction]
fn embedding_module(layer: PyEmbedding) -> PyNeuralModule {
    PyNeuralModule::Embedding(layer)
}

#[pyfunction]
fn resnet_module(layer: PyResNet) -> PyNeuralModule {
    PyNeuralModule::ResNet(layer)
}

#[pyfunction]
fn efficientnet_module(layer: PyEfficientNet) -> PyNeuralModule {
    PyNeuralModule::EfficientNet(layer)
}

// Device Context Managers
#[pyclass]
struct PyDeviceContext {
    device: Device,
    previous_device: Option<Device>,
}

#[pymethods]
impl PyDeviceContext {
    #[new]
    fn new(device: String) -> PyResult<Self> {
        let device = match device.as_str() {
            "cpu" => Device::Cpu,
            #[cfg(feature = "gpu")]
            s if s.starts_with("cuda") => Device::Gpu(0), // Default GPU 0
            #[cfg(not(feature = "gpu"))]
            s if s.starts_with("cuda") => {
                return Err(PyErr::new::<PyValueError, _>(
                    "GPU support not enabled".to_string(),
                ))
            }
            _ => {
                return Err(PyErr::new::<PyValueError, _>(format!(
                    "Invalid device: {device}"
                )))
            }
        };

        Ok(Self {
            device,
            previous_device: None,
        })
    }

    fn __enter__(mut slf: PyRefMut<Self>) -> PyResult<PyRefMut<Self>> {
        // Store the current default device
        if let Ok(current_device) = get_default_device() {
            slf.previous_device = Some(current_device);
        }

        // Set the new default device
        if let Err(e) = set_default_device(&slf.device.to_string()) {
            return Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to set device: {e}"
            )));
        }

        Ok(slf)
    }

    #[pyo3(signature = (_exc_type=None, _exc_value=None, _traceback=None))]
    fn __exit__(
        &mut self,
        _exc_type: Option<pyo3::PyObject>,
        _exc_value: Option<pyo3::PyObject>,
        _traceback: Option<pyo3::PyObject>,
    ) -> PyResult<()> {
        // Restore the previous default device
        if let Some(prev_device) = &self.previous_device {
            if let Err(e) = set_default_device(&prev_device.to_string()) {
                return Err(PyErr::new::<PyRuntimeError, _>(format!(
                    "Failed to restore device: {e}"
                )));
            }
        }
        Ok(())
    }

    fn __str__(&self) -> String {
        format!("PyDeviceContext({})", self.device)
    }
}

// GPU Context Manager
#[pyclass]
struct PyGpuContext {
    device_id: Option<usize>,
    previous_device: Option<Device>,
}

#[pymethods]
impl PyGpuContext {
    #[new]
    #[pyo3(signature = (device_id=None))]
    fn new(device_id: Option<usize>) -> Self {
        Self {
            device_id,
            previous_device: None,
        }
    }

    fn __enter__(mut slf: PyRefMut<Self>) -> PyResult<PyRefMut<Self>> {
        // Store the current default device
        if let Ok(current_device) = get_default_device() {
            slf.previous_device = Some(current_device);
        }

        // Set GPU device
        let device_str = if let Some(id) = slf.device_id {
            format!("cuda:{id}")
        } else {
            "cuda".to_string()
        };

        if let Err(e) = set_default_device(&device_str) {
            return Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to set GPU device: {e}"
            )));
        }

        Ok(slf)
    }

    #[pyo3(signature = (_exc_type=None, _exc_value=None, _traceback=None))]
    fn __exit__(
        &mut self,
        _exc_type: Option<pyo3::PyObject>,
        _exc_value: Option<pyo3::PyObject>,
        _traceback: Option<pyo3::PyObject>,
    ) -> PyResult<()> {
        // Restore the previous default device
        if let Some(prev_device) = &self.previous_device {
            if let Err(e) = set_default_device(&prev_device.to_string()) {
                return Err(PyErr::new::<PyRuntimeError, _>(format!(
                    "Failed to restore device: {e}"
                )));
            }
        }
        Ok(())
    }

    fn __str__(&self) -> String {
        if let Some(id) = self.device_id {
            format!("PyGpuContext(cuda:{id})")
        } else {
            "PyGpuContext(cuda)".to_string()
        }
    }
}

// CPU Context Manager
#[pyclass]
struct PyCpuContext {
    previous_device: Option<Device>,
}

#[pymethods]
impl PyCpuContext {
    #[new]
    fn new() -> Self {
        Self {
            previous_device: None,
        }
    }

    fn __enter__(mut slf: PyRefMut<Self>) -> PyResult<PyRefMut<Self>> {
        // Store the current default device
        if let Ok(current_device) = get_default_device() {
            slf.previous_device = Some(current_device);
        }

        // Set CPU device
        if let Err(e) = set_default_device("cpu") {
            return Err(PyErr::new::<PyRuntimeError, _>(format!(
                "Failed to set CPU device: {e}"
            )));
        }

        Ok(slf)
    }

    #[pyo3(signature = (_exc_type=None, _exc_value=None, _traceback=None))]
    fn __exit__(
        &mut self,
        _exc_type: Option<pyo3::PyObject>,
        _exc_value: Option<pyo3::PyObject>,
        _traceback: Option<pyo3::PyObject>,
    ) -> PyResult<()> {
        // Restore the previous default device
        if let Some(prev_device) = &self.previous_device {
            if let Err(e) = set_default_device(&prev_device.to_string()) {
                return Err(PyErr::new::<PyRuntimeError, _>(format!(
                    "Failed to restore device: {e}"
                )));
            }
        }
        Ok(())
    }

    fn __str__(&self) -> String {
        "PyCpuContext(cpu)".to_string()
    }
}

// Helper function to get current default device
fn get_default_device() -> Result<Device, String> {
    let lock = get_default_device_lock();
    match lock.read() {
        Ok(default_device) => Ok(*default_device),
        Err(_) => Err("Failed to acquire device lock for reading".to_string()),
    }
}

// We'll use the existing PyParameter class defined earlier in the file

// Simple Module base class with state_dict functionality
#[pyclass]
struct PyModule {
    parameters: Vec<(String, PyParameter)>, // Store as (name, parameter) pairs
    buffers: Vec<(String, PyTensor)>,       // Store buffers as (name, tensor) pairs
    training: bool,
    name: Option<String>,
}

#[pymethods]
impl PyModule {
    #[new]
    #[pyo3(signature = (name=None))]
    fn new(name: Option<String>) -> Self {
        Self {
            parameters: Vec::new(),
            buffers: Vec::new(),
            training: true,
            name,
        }
    }

    fn add_parameter(&mut self, name: String, parameter: PyParameter) {
        self.parameters.push((name, parameter));
    }

    fn register_buffer(&mut self, name: String, tensor: PyTensor) {
        // Register a buffer (non-parameter tensor) with the module
        // Buffers are not considered parameters for optimization but are part of the model state
        self.buffers.push((name, tensor));
    }

    fn parameters(&self) -> Vec<PyParameter> {
        self.parameters
            .iter()
            .map(|(_, param)| param.clone())
            .collect()
    }

    fn named_parameters(&self) -> Vec<(String, PyParameter)> {
        self.parameters.clone()
    }

    fn state_dict(&self) -> PyResult<PyObject> {
        Python::with_gil(|py| {
            let dict = PyDict::new(py);

            // Add parameters to state dict
            for (name, param) in &self.parameters {
                dict.set_item(name, param.tensor())?;
            }

            // Add buffers to state dict
            for (name, buffer) in &self.buffers {
                dict.set_item(name, buffer.clone())?;
            }

            Ok(dict.into())
        })
    }

    fn load_state_dict(&mut self, state_dict: &Bound<'_, PyDict>) -> PyResult<()> {
        let mut loaded_params = Vec::new();

        for item in state_dict.items() {
            let name: String = item.get_item(0)?.extract()?;
            let tensor: PyTensor = item.get_item(1)?.extract()?;

            let param = PyParameter::new(tensor);
            loaded_params.push((name, param));
        }

        self.parameters = loaded_params;
        Ok(())
    }

    fn train(&mut self) {
        self.training = true;
    }

    fn eval(&mut self) {
        self.training = false;
    }

    fn training(&self) -> bool {
        self.training
    }

    #[getter]
    fn name(&self) -> Option<String> {
        self.name.clone()
    }

    #[setter]
    fn set_name(&mut self, name: Option<String>) {
        self.name = name;
    }

    #[pyo3(signature = (device=None, dtype=None))]
    fn to(&mut self, device: Option<String>, dtype: Option<String>) -> PyResult<()> {
        // Convert all parameters to the specified device and/or dtype
        for (name, param) in &mut self.parameters {
            let mut tensor = param.tensor();

            // Convert to device if specified
            if let Some(device_str) = &device {
                tensor = tensor.to_device(device_str)?;
            }

            // Convert dtype if specified
            if let Some(dtype_str) = &dtype {
                tensor = convert_tensor_dtype(tensor, dtype_str).map_err(|e| {
                    PyErr::new::<PyRuntimeError, _>(format!(
                        "Failed to convert dtype to {}: {}",
                        dtype_str, e
                    ))
                })?;
            }

            // Update the parameter with the converted tensor
            *param = PyParameter::new(tensor);
        }

        Ok(())
    }

    fn named_buffers(&self) -> Vec<(String, PyTensor)> {
        self.buffers.clone()
    }

    fn apply<'py>(&mut self, func: &Bound<'py, PyAny>) -> PyResult<()> {
        // Apply a function recursively to all parameters and buffers
        Python::with_gil(|_py| {
            // Apply to parameters
            for (name, param) in &mut self.parameters {
                let tensor = param.tensor();
                let result: PyTensor = func.call1((tensor,))?.extract()?;
                *param = PyParameter::new(result);
            }

            // Apply to buffers
            for (name, buffer) in &mut self.buffers {
                let result: PyTensor = func.call1((buffer.clone(),))?.extract()?;
                *buffer = result;
            }

            Ok(())
        })
    }

    fn zero_grad(&mut self) -> PyResult<()> {
        // Zero out gradients for all parameters in this module
        // This is a placeholder implementation for gradient clearing
        for (_name, param) in &mut self.parameters {
            // In a full implementation, this would clear the gradients
            // For now, we'll just indicate success
            // param.zero_grad(); // Would be called when available in core
        }
        Ok(())
    }

    fn accumulate_gradients(&mut self, scale: Option<f32>) -> PyResult<()> {
        // Accumulate gradients with optional scaling for gradient accumulation
        // This is a placeholder for gradient accumulation functionality
        let _scale = scale.unwrap_or(1.0);

        // In a full implementation, this would:
        // 1. Scale the current gradients by the accumulation factor
        // 2. Add them to previously accumulated gradients
        // 3. Store the accumulated gradients

        // For now, this is a placeholder that indicates the API is available
        Ok(())
    }

    fn __str__(&self) -> String {
        let name_str = self.name.as_deref().unwrap_or("Module");
        format!(
            "{}(training={}, params={})",
            name_str,
            self.training,
            self.parameters.len()
        )
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// Model saving and loading functions
#[pyfunction]
fn save_model(module: &PyModule, file_path: String) -> PyResult<()> {
    Python::with_gil(|py| {
        let state_dict = module.state_dict()?;

        // For now, we'll use Python's pickle module for serialization
        // In a production implementation, we'd use a more efficient format
        let pickle = py.import("pickle")?;

        let file = std::fs::File::create(&file_path)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to create file: {e}")))?;

        // Convert the state dict to bytes using pickle
        let data = pickle.call_method1("dumps", (state_dict,))?;
        let bytes: &[u8] = data.extract()?;

        std::io::Write::write_all(&mut std::io::BufWriter::new(file), bytes)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to write file: {e}")))?;

        Ok(())
    })
}

#[pyfunction]
fn load_model(file_path: String) -> PyResult<PyObject> {
    Python::with_gil(|py| {
        let pickle = py.import("pickle")?;

        let data = std::fs::read(&file_path)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to read file: {e}")))?;

        let state_dict = pickle.call_method1("loads", (data,))?;

        Ok(state_dict.into())
    })
}

/// Save object to file (PyTorch-compatible torch.save)
#[pyfunction]
#[pyo3(signature = (obj, file_path, pickle_protocol=None))]
fn torch_save(
    obj: &pyo3::Bound<pyo3::PyAny>,
    file_path: String,
    pickle_protocol: Option<i32>,
) -> PyResult<()> {
    Python::with_gil(|py| {
        let pickle = py.import("pickle")?;

        // Use highest protocol by default for better performance
        let protocol =
            pickle_protocol.unwrap_or(pickle.getattr("HIGHEST_PROTOCOL")?.extract::<i32>()?);

        let serialized = pickle.call_method("dumps", (obj, protocol), None)?;
        let data: Vec<u8> = serialized.extract()?;

        std::fs::write(&file_path, data)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to write file: {e}")))?;

        Ok(())
    })
}

/// Load object from file with map_location support (PyTorch-compatible torch.load)
#[pyfunction]
#[pyo3(signature = (file_path, map_location=None, pickle_module=None, weights_only=false))]
fn torch_load(
    file_path: String,
    map_location: Option<String>,
    pickle_module: Option<&pyo3::Bound<pyo3::PyAny>>,
    weights_only: bool,
) -> PyResult<PyObject> {
    Python::with_gil(|py| {
        let pickle = if let Some(module) = pickle_module {
            module.clone()
        } else {
            py.import("pickle")?.as_any().clone()
        };

        let data = std::fs::read(&file_path)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to read file: {e}")))?;

        let mut loaded_obj = pickle.call_method1("loads", (data,))?;

        // Handle map_location for device placement
        if let Some(device_str) = map_location {
            loaded_obj = map_tensors_to_device(py, loaded_obj, &device_str)?;
        }

        // If weights_only is true, validate that only tensors/weights are in the loaded object
        if weights_only {
            validate_weights_only(py, &loaded_obj).map_err(|e| {
                PyErr::new::<PyRuntimeError, _>(format!("weights_only validation failed: {}", e))
            })?;
        }

        Ok(loaded_obj.into())
    })
}

/// Helper function to convert tensor to a different dtype
fn convert_tensor_dtype(tensor: PyTensor, dtype_str: &str) -> Result<PyTensor, String> {
    // For now, dtype conversion is limited due to current tensor API limitations
    // The cast function requires Into<U> trait bounds which are very restrictive
    // and the PyTensor API doesn't have a direct constructor from existing tensors

    let current_dtype = tensor.inner.dtype();

    // Parse target dtype
    let target_dtype = match dtype_str.to_lowercase().as_str() {
        "float32" | "f32" => DType::Float32,
        "float64" | "f64" => DType::Float64,
        "int32" | "i32" => DType::Int32,
        "int64" | "i64" => DType::Int64,
        _ => {
            return Err(format!(
                "Unsupported dtype: {}. Supported types: float32, float64, int32, int64",
                dtype_str
            ))
        }
    };

    // Check if conversion is needed
    if current_dtype == target_dtype {
        return Ok(tensor); // No conversion needed
    }

    // For now, return an informative error about limited conversion support
    // This can be expanded when the core tensor API provides better conversion support
    match (current_dtype, target_dtype) {
        (DType::Float32, DType::Float64) => {
            Err("f32 -> f64 conversion not yet implemented due to cast API limitations".to_string())
        },
        (DType::Float64, DType::Float32) => {
            Err("f64 -> f32 conversion not yet implemented due to cast API limitations".to_string())
        },
        (DType::Float32, DType::Int32) => {
            Err("f32 -> i32 conversion not yet implemented due to cast API limitations".to_string())
        },
        (DType::Int32, DType::Float32) => {
            Err("i32 -> f32 conversion not yet implemented due to cast API limitations".to_string())
        },
        _ => {
            Err(format!("Dtype conversion from {:?} to {:?} is not currently supported. This is a limitation of the current tensor casting API.", current_dtype, target_dtype))
        }
    }
}

/// Validate that loaded object contains only weights/tensors when weights_only=True
fn validate_weights_only(
    py: pyo3::Python<'_>,
    obj: &pyo3::Bound<'_, pyo3::PyAny>,
) -> Result<(), String> {
    // Check if object is a PyTensor - this is valid
    if obj.is_instance_of::<PyTensor>() {
        return Ok(());
    }

    // Check if object is a dictionary (state_dict)
    if obj.is_instance_of::<pyo3::types::PyDict>() {
        let dict = obj
            .downcast::<pyo3::types::PyDict>()
            .map_err(|_| "Failed to downcast to PyDict")?;

        for (key, value) in dict.iter() {
            // Recursively validate each value in the dictionary
            validate_weights_only(py, &value)?;

            // Additionally check that keys look like parameter names (optional strict check)
            let key_str: String = key
                .extract()
                .map_err(|_| "Dictionary keys must be strings for weights_only validation")?;

            // Check for suspicious keys that might indicate non-weight data
            let suspicious_keys = [
                "__metadata__",
                "__version__",
                "optimizer_state",
                "lr_scheduler",
                "epoch",
                "global_step",
                "training_args",
                "config",
            ];
            for suspicious in &suspicious_keys {
                if key_str.contains(suspicious) {
                    return Err(format!(
                        "Non-weight key '{}' found in state_dict. Use weights_only=False to load non-tensor data.",
                        key_str
                    ));
                }
            }
        }

        return Ok(());
    }

    // Check if object is a list/tuple of tensors
    if obj.is_instance_of::<pyo3::types::PyList>() {
        let list = obj
            .downcast::<pyo3::types::PyList>()
            .map_err(|_| "Failed to downcast to PyList")?;

        for item in list.iter() {
            validate_weights_only(py, &item)?;
        }

        return Ok(());
    }

    if obj.is_instance_of::<pyo3::types::PyTuple>() {
        let tuple = obj
            .downcast::<pyo3::types::PyTuple>()
            .map_err(|_| "Failed to downcast to PyTuple")?;

        for item in tuple.iter() {
            validate_weights_only(py, &item)?;
        }

        return Ok(());
    }

    // Check for other tensor-like objects that might be valid
    // This includes numpy arrays if they're present
    if let Ok(type_obj) = obj.get_type().name() {
        let type_name_str: String = type_obj.extract().unwrap_or_else(|_| "unknown".to_string());
        match type_name_str.as_str() {
            // Allow numpy arrays as they can represent tensor data
            "ndarray" => return Ok(()),
            // Allow basic numeric types
            "int" | "float" | "bool" => return Ok(()),
            // Allow None values (might be used for missing parameters)
            "NoneType" => return Ok(()),
            _ => {}
        }
    }

    // If we get here, the object type is not recognized as a valid tensor/weight
    let type_name_str = if let Ok(name_obj) = obj.get_type().name() {
        name_obj.extract().unwrap_or_else(|_| "unknown".to_string())
    } else {
        "unknown".to_string()
    };

    Err(format!(
        "Invalid object type '{}' found in loaded data. weights_only=True requires only tensor data. \
        Use weights_only=False to load arbitrary Python objects.",
        type_name_str
    ))
}

/// Helper function to map tensors to a specific device
fn map_tensors_to_device<'a>(
    py: pyo3::Python<'a>,
    obj: pyo3::Bound<'a, pyo3::PyAny>,
    device: &str,
) -> PyResult<pyo3::Bound<'a, pyo3::PyAny>> {
    // Parse device string (e.g., "cpu", "cuda:0")
    let target_device = if device == "cpu" {
        Device::Cpu
    } else if device.starts_with("cuda") {
        // For GPU device, we'll use Device::from_str which should support GPU parsing
        Device::from_str(device).map_err(|e| PyErr::new::<PyValueError, _>(e))?
    } else {
        return Err(PyErr::new::<PyValueError, _>(format!(
            "Unsupported device: {}. Use 'cpu' or 'cuda' or 'cuda:N'",
            device
        )));
    };

    // Check if object is a PyTensor and convert it
    if obj.is_instance_of::<PyTensor>() {
        let tensor: PyTensor = obj.extract()?;
        let moved_tensor = tensor.to_device(device).map_err(|e| {
            PyErr::new::<PyRuntimeError, _>(format!("Failed to move tensor to device: {e}"))
        })?;
        return Ok(moved_tensor.into_py(py).into_bound(py));
    }

    // Check if object is a dictionary (state_dict)
    if obj.is_instance_of::<pyo3::types::PyDict>() {
        let dict = obj.downcast::<pyo3::types::PyDict>()?;
        let new_dict = pyo3::types::PyDict::new_bound(py);

        for (key, value) in dict.iter() {
            let mapped_value = map_tensors_to_device(py, value, device)?;
            new_dict.set_item(key, mapped_value)?;
        }

        return Ok(new_dict.as_any().clone());
    }

    // Check if object is a list
    if obj.is_instance_of::<pyo3::types::PyList>() {
        let list = obj.downcast::<pyo3::types::PyList>()?;
        let new_list = pyo3::types::PyList::empty_bound(py);

        for item in list.iter() {
            let mapped_item = map_tensors_to_device(py, item, device)?;
            new_list.append(mapped_item)?;
        }

        return Ok(new_list.as_any().clone());
    }

    // Check if object is a tuple
    if obj.is_instance_of::<pyo3::types::PyTuple>() {
        let tuple = obj.downcast::<pyo3::types::PyTuple>()?;
        let items: Result<Vec<_>, _> = tuple
            .iter()
            .map(|item| map_tensors_to_device(py, item, device))
            .collect();
        let mapped_items = items?;
        let new_tuple = pyo3::types::PyTuple::new_bound(py, mapped_items);

        return Ok(new_tuple.as_any().clone());
    }

    // For other types (scalars, etc.), return as-is
    Ok(obj)
}

/// Enhanced load_model with device mapping support
#[pyfunction]
#[pyo3(signature = (file_path, map_location=None))]
fn load_model_with_device(file_path: String, map_location: Option<String>) -> PyResult<PyObject> {
    torch_load(file_path, map_location, None, false)
}

/// Save model state dict to file
#[pyfunction]
fn save_state_dict(obj: &pyo3::Bound<pyo3::PyAny>, file_path: String) -> PyResult<()> {
    torch_save(obj, file_path, None)
}

// Sampler Classes

/// Sequential sampler that iterates through indices in order
#[pyclass]
#[derive(Clone)]
pub struct PySequentialSampler {
    inner: SequentialSampler,
}

#[pymethods]
impl PySequentialSampler {
    #[new]
    fn new() -> Self {
        Self {
            inner: SequentialSampler::new(),
        }
    }

    /// Create a sequential sampler with a specific range
    #[staticmethod]
    #[pyo3(signature = (start, end))]
    fn with_range(start: usize, end: usize) -> Self {
        Self {
            inner: SequentialSampler::with_range(start, end),
        }
    }

    /// Check if this sampler produces indices in random order
    fn is_random(&self) -> bool {
        self.inner.is_random()
    }

    /// Generate sample indices for a dataset of given length
    fn sample_indices(&self, length: usize) -> Vec<usize> {
        self.inner.sample_indices(length).collect()
    }

    fn __str__(&self) -> String {
        "SequentialSampler()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

/// Random sampler that generates random indices
#[pyclass]
#[derive(Clone)]
pub struct PyRandomSampler {
    inner: RandomSampler,
}

#[pymethods]
impl PyRandomSampler {
    #[new]
    fn new() -> Self {
        Self {
            inner: RandomSampler::new(),
        }
    }

    /// Create a random sampler with replacement
    #[staticmethod]
    fn with_replacement() -> Self {
        Self {
            inner: RandomSampler::with_replacement(),
        }
    }

    /// Create a random sampler with a specific seed
    #[staticmethod]
    #[pyo3(signature = (seed))]
    fn with_seed(seed: u64) -> Self {
        Self {
            inner: RandomSampler::with_seed(seed),
        }
    }

    /// Check if this sampler produces indices in random order
    fn is_random(&self) -> bool {
        self.inner.is_random()
    }

    /// Set random seed
    fn set_seed(&mut self, seed: Option<u64>) {
        self.inner.set_seed(seed);
    }

    /// Generate sample indices for a dataset of given length
    fn sample_indices(&self, length: usize) -> Vec<usize> {
        self.inner.sample_indices(length).collect()
    }

    fn __str__(&self) -> String {
        "RandomSampler()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// DistributedSampler for distributed training
#[pyclass]
#[derive(Clone)]
pub struct PyDistributedSampler {
    inner: tenflowers_dataset::DistributedSampler,
}

#[pymethods]
impl PyDistributedSampler {
    #[new]
    #[pyo3(signature = (num_replicas, rank, shuffle=None, seed=None))]
    fn new(
        num_replicas: usize,
        rank: usize,
        shuffle: Option<bool>,
        seed: Option<u64>,
    ) -> PyResult<Self> {
        let mut sampler = tenflowers_dataset::DistributedSampler::new(num_replicas, rank)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
        if let Some(shuffle) = shuffle {
            sampler = sampler.with_shuffle(shuffle);
        }
        if let Some(seed) = seed {
            sampler = sampler.with_seed(seed);
        }
        Ok(Self { inner: sampler })
    }

    fn set_epoch(&mut self, epoch: usize) {
        self.inner.set_epoch(epoch);
    }

    /// Generate sample indices for a dataset of given length
    fn sample_indices(&self, length: usize) -> Vec<usize> {
        self.inner.sample_indices(length).collect()
    }

    /// Check if this sampler produces indices in random order
    fn is_random(&self) -> bool {
        self.inner.is_random()
    }

    /// Set random seed
    fn set_seed(&mut self, seed: Option<u64>) {
        self.inner.set_seed(seed);
    }

    fn __str__(&self) -> String {
        "DistributedSampler()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// StratifiedSampler for balanced sampling
#[pyclass]
#[derive(Clone)]
pub struct PyStratifiedSampler {
    inner: tenflowers_dataset::StratifiedSampler,
}

#[pymethods]
impl PyStratifiedSampler {
    #[new]
    fn new(class_labels: Vec<usize>) -> Self {
        Self {
            inner: tenflowers_dataset::StratifiedSampler::new(class_labels),
        }
    }

    /// Generate sample indices for a dataset of given length
    fn sample_indices(&self, length: usize) -> Vec<usize> {
        self.inner.sample_indices(length).collect()
    }

    /// Check if this sampler produces indices in random order
    fn is_random(&self) -> bool {
        self.inner.is_random()
    }

    /// Set random seed
    fn set_seed(&mut self, seed: Option<u64>) {
        self.inner.set_seed(seed);
    }

    fn __str__(&self) -> String {
        "StratifiedSampler()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// ImportanceSampler for importance sampling
#[pyclass]
#[derive(Clone)]
pub struct PyImportanceSampler {
    inner: tenflowers_dataset::ImportanceSampler,
}

#[pymethods]
impl PyImportanceSampler {
    #[new]
    #[pyo3(signature = (dataset_size, weights=None, temperature=None))]
    fn new(dataset_size: usize, weights: Option<Vec<f64>>, temperature: Option<f64>) -> Self {
        let mut sampler = if let Some(weights) = weights {
            tenflowers_dataset::ImportanceSampler::with_weights(weights)
        } else {
            tenflowers_dataset::ImportanceSampler::new(dataset_size)
        };

        if let Some(temperature) = temperature {
            sampler = sampler.with_temperature(temperature);
        }

        Self { inner: sampler }
    }

    /// Generate sample indices for a dataset of given length
    fn sample_indices(&self, length: usize) -> Vec<usize> {
        self.inner.sample_indices(length).collect()
    }

    /// Check if this sampler produces indices in random order
    fn is_random(&self) -> bool {
        self.inner.is_random()
    }

    /// Set random seed
    fn set_seed(&mut self, seed: Option<u64>) {
        self.inner.set_seed(seed);
    }

    fn __str__(&self) -> String {
        "ImportanceSampler()".to_string()
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// Dataset Classes

// Dataset base class (abstract interface)
#[pyclass]
#[derive(Clone)]
pub struct PyDataset {
    inner: DatasetType,
}

#[derive(Clone)]
enum DatasetType {
    Tensor(PyTensorDataset),
    // Future dataset types can be added here
    // Custom(Box<dyn CustomDataset>),
}

#[pymethods]
impl PyDataset {
    fn __len__(&self) -> usize {
        match &self.inner {
            DatasetType::Tensor(dataset) => dataset.__len__(),
        }
    }

    fn __getitem__(&self, index: usize) -> PyResult<(PyTensor, PyTensor)> {
        match &self.inner {
            DatasetType::Tensor(dataset) => dataset.__getitem__(index),
        }
    }

    fn __str__(&self) -> String {
        match &self.inner {
            DatasetType::Tensor(_) => format!("PyDataset(type=Tensor, length={})", self.__len__()),
        }
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

impl PyDataset {
    pub fn from_tensor_dataset(dataset: PyTensorDataset) -> Self {
        Self {
            inner: DatasetType::Tensor(dataset),
        }
    }

    pub fn as_tensor_dataset(&self) -> PyResult<&PyTensorDataset> {
        match &self.inner {
            DatasetType::Tensor(dataset) => Ok(dataset),
        }
    }
}

// TensorDataset - simplified implementation
#[pyclass]
#[derive(Clone)]
struct PyTensorDataset {
    features: PyTensor,
    labels: PyTensor,
}

#[pymethods]
impl PyTensorDataset {
    #[new]
    fn new(features: PyTensor, labels: PyTensor) -> Self {
        Self { features, labels }
    }

    fn __len__(&self) -> usize {
        self.features.shape()[0]
    }

    fn __getitem__(&self, index: usize) -> PyResult<(PyTensor, PyTensor)> {
        if index >= self.__len__() {
            return Err(PyErr::new::<PyIndexError, _>(format!(
                "Index {} out of bounds",
                index
            )));
        }

        // For now, return a simple slice - this is a basic implementation
        // In practice, we'd need proper slicing operations
        Ok((self.features.clone(), self.labels.clone()))
    }

    fn __str__(&self) -> String {
        format!("TensorDataset(length={})", self.__len__())
    }

    fn __repr__(&self) -> String {
        self.__str__()
    }
}

// Additional NumPy-style array manipulation functions

#[pyfunction]
fn concatenate(tensors: Vec<PyTensor>, axis: Option<usize>) -> PyResult<PyTensor> {
    if tensors.is_empty() {
        return Err(PyErr::new::<PyValueError, _>(
            "Cannot concatenate empty sequence",
        ));
    }

    let axis = axis.unwrap_or(0);
    let inner_tensors: Vec<&Tensor<f32>> = tensors.iter().map(|t| &t.inner).collect();

    match tenflowers_core::ops::manipulation::concat(&inner_tensors, axis) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn stack(tensors: Vec<PyTensor>, axis: Option<usize>) -> PyResult<PyTensor> {
    if tensors.is_empty() {
        return Err(PyErr::new::<PyValueError, _>("Cannot stack empty sequence"));
    }

    let axis = axis.unwrap_or(0);
    let inner_tensors: Vec<&Tensor<f32>> = tensors.iter().map(|t| &t.inner).collect();

    match tenflowers_core::ops::manipulation::stack(&inner_tensors, axis) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn vstack(tensors: Vec<PyTensor>) -> PyResult<PyTensor> {
    // vstack is equivalent to concatenate along axis 0
    concatenate(tensors, Some(0))
}

#[pyfunction]
fn hstack(tensors: Vec<PyTensor>) -> PyResult<PyTensor> {
    if tensors.is_empty() {
        return Err(PyErr::new::<PyValueError, _>("Cannot stack empty sequence"));
    }

    // For 1D tensors, hstack concatenates along axis 0
    // For 2D+ tensors, hstack concatenates along axis 1
    let axis = if tensors[0].inner.ndim() == 1 { 0 } else { 1 };
    concatenate(tensors, Some(axis))
}

#[pyfunction]
fn expand_dims(tensor: &PyTensor, axis: isize) -> PyResult<PyTensor> {
    let ndim = tensor.inner.ndim() as isize;

    // Normalize negative axis
    let norm_axis = if axis < 0 { ndim + axis + 1 } else { axis };

    if norm_axis < 0 || norm_axis > ndim {
        return Err(PyErr::new::<PyIndexError, _>(format!(
            "Axis {} is out of bounds for array of dimension {}",
            axis, ndim
        )));
    }

    match tensor.inner.unsqueeze(&[norm_axis as usize]) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn broadcast_to(tensor: &PyTensor, shape: Vec<usize>) -> PyResult<PyTensor> {
    match tenflowers_core::ops::manipulation::broadcast_to(&tensor.inner, &shape) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn squeeze(tensor: &PyTensor, axis: Option<Vec<usize>>) -> PyResult<PyTensor> {
    let axes_ref = axis.as_deref();
    match tensor.inner.squeeze(axes_ref) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn reshape(tensor: &PyTensor, shape: Vec<usize>) -> PyResult<PyTensor> {
    match tensor.inner.reshape(&shape) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn transpose(tensor: &PyTensor, axes: Option<Vec<usize>>) -> PyResult<PyTensor> {
    match axes {
        Some(axes) => {
            match tenflowers_core::ops::manipulation::transpose_axes(&tensor.inner, Some(&axes)) {
                Ok(result) => Ok(PyTensor { inner: result }),
                Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
            }
        }
        None => match tenflowers_core::ops::manipulation::transpose(&tensor.inner) {
            Ok(result) => Ok(PyTensor { inner: result }),
            Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        },
    }
}

#[pyfunction]
fn split(tensor: &PyTensor, num_splits: usize, axis: Option<usize>) -> PyResult<Vec<PyTensor>> {
    let axis = axis.unwrap_or(0);
    match tenflowers_core::ops::manipulation::split(&tensor.inner, num_splits, axis) {
        Ok(results) => Ok(results.into_iter().map(|t| PyTensor { inner: t }).collect()),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn flip(tensor: &PyTensor, axes: Vec<usize>) -> PyResult<PyTensor> {
    match tenflowers_core::ops::manipulation::flip(&tensor.inner, &axes) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn fliplr(tensor: &PyTensor) -> PyResult<PyTensor> {
    // Flip left-right (along the last axis for 2D+ tensors)
    let ndim = tensor.inner.ndim();
    if ndim < 2 {
        return Err(PyErr::new::<PyValueError, _>(
            "fliplr requires at least 2D tensor",
        ));
    }
    flip(tensor, vec![ndim - 1])
}

#[pyfunction]
fn flipud(tensor: &PyTensor) -> PyResult<PyTensor> {
    // Flip up-down (along axis 0)
    flip(tensor, vec![0])
}

#[pyfunction]
fn roll(tensor: &PyTensor, shift: isize, axis: Option<usize>) -> PyResult<PyTensor> {
    match tenflowers_core::ops::manipulation::roll(&tensor.inner, shift, axis) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn repeat(tensor: &PyTensor, repeats: usize, axis: Option<usize>) -> PyResult<PyTensor> {
    match tenflowers_core::ops::manipulation::repeat(&tensor.inner, repeats, axis) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn tile(tensor: &PyTensor, multiples: Vec<usize>) -> PyResult<PyTensor> {
    match tenflowers_core::ops::manipulation::tile(&tensor.inner, &multiples) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn moveaxis(tensor: &PyTensor, source: usize, destination: usize) -> PyResult<PyTensor> {
    let ndim = tensor.inner.ndim();
    if source >= ndim || destination >= ndim {
        return Err(PyErr::new::<PyIndexError, _>("axis out of bounds"));
    }

    let mut axes: Vec<usize> = (0..ndim).collect();
    let src_axis = axes.remove(source);
    axes.insert(destination, src_axis);

    match tenflowers_core::ops::manipulation::transpose_axes(&tensor.inner, Some(&axes)) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

#[pyfunction]
fn swapaxes(tensor: &PyTensor, axis1: usize, axis2: usize) -> PyResult<PyTensor> {
    let ndim = tensor.inner.ndim();
    if axis1 >= ndim || axis2 >= ndim {
        return Err(PyErr::new::<PyIndexError, _>("axis out of bounds"));
    }

    let mut axes: Vec<usize> = (0..ndim).collect();
    axes.swap(axis1, axis2);

    match tenflowers_core::ops::manipulation::transpose_axes(&tensor.inner, Some(&axes)) {
        Ok(result) => Ok(PyTensor { inner: result }),
        Err(e) => Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
    }
}

/// Configuration for DataLoader
#[pyclass]
#[derive(Clone)]
pub struct PyDataLoaderConfig {
    #[pyo3(get, set)]
    pub batch_size: usize,
    #[pyo3(get, set)]
    pub num_workers: usize,
    #[pyo3(get, set)]
    pub prefetch_factor: usize,
    #[pyo3(get, set)]
    pub pin_memory: bool,
    #[pyo3(get, set)]
    pub drop_last: bool,
    #[pyo3(get, set)]
    pub collate_batches: bool,
}

#[pymethods]
impl PyDataLoaderConfig {
    #[new]
    fn new() -> Self {
        let config = DataLoaderConfig::default();
        Self {
            batch_size: config.batch_size,
            num_workers: config.num_workers,
            prefetch_factor: config.prefetch_factor,
            pin_memory: config.pin_memory,
            drop_last: config.drop_last,
            collate_batches: config.collate_batches,
        }
    }

    fn __repr__(&self) -> String {
        format!(
            "DataLoaderConfig(batch_size={}, num_workers={}, prefetch_factor={}, pin_memory={}, drop_last={}, collate_batches={})",
            self.batch_size, self.num_workers, self.prefetch_factor, self.pin_memory, self.drop_last, self.collate_batches
        )
    }
}

/// Batch result containing features and labels
#[pyclass]
pub struct PyBatchResult {
    features: PyTensor,
    labels: PyTensor,
}

#[pymethods]
impl PyBatchResult {
    #[getter]
    fn features(&self) -> PyTensor {
        self.features.clone()
    }

    #[getter]
    fn labels(&self) -> PyTensor {
        self.labels.clone()
    }

    fn __len__(&self) -> usize {
        self.features.inner.shape().dims()[0]
    }

    fn __repr__(&self) -> String {
        format!(
            "BatchResult(features={:?}, labels={:?})",
            self.features.shape(),
            self.labels.shape()
        )
    }
}

/// PyTorch-compatible DataLoader with multi-threading and prefetching
#[pyclass]
pub struct PyDataLoader {
    dataset: PyTensorDataset,
    config: PyDataLoaderConfig,
    shuffle: bool,
}

#[pymethods]
impl PyDataLoader {
    #[new]
    #[pyo3(signature = (dataset, batch_size=1, shuffle=false, num_workers=1, drop_last=false, pin_memory=false))]
    fn new(
        dataset: PyTensorDataset,
        batch_size: usize,
        shuffle: bool,
        num_workers: usize,
        drop_last: bool,
        pin_memory: bool,
    ) -> Self {
        let mut config = PyDataLoaderConfig::new();
        config.batch_size = batch_size;
        config.num_workers = num_workers;
        config.drop_last = drop_last;
        config.pin_memory = pin_memory;

        Self {
            dataset,
            config,
            shuffle,
        }
    }

    fn __len__(&self) -> usize {
        let dataset_len = self.dataset.__len__();
        if self.config.drop_last {
            dataset_len / self.config.batch_size
        } else {
            (dataset_len + self.config.batch_size - 1) / self.config.batch_size
        }
    }

    fn __iter__(slf: PyRef<'_, Self>) -> PyDataLoaderIterator {
        PyDataLoaderIterator::new(slf.dataset.clone(), slf.config.clone(), slf.shuffle)
    }

    fn __repr__(&self) -> String {
        format!(
            "DataLoader(dataset_len={}, batch_size={}, shuffle={}, num_workers={})",
            self.dataset.__len__(),
            self.config.batch_size,
            self.shuffle,
            self.config.num_workers
        )
    }
}

/// Iterator for PyDataLoader that yields batches
#[pyclass]
pub struct PyDataLoaderIterator {
    dataset: PyTensorDataset,
    config: PyDataLoaderConfig,
    indices: Vec<usize>,
    current_batch: usize,
    total_batches: usize,
}

#[pymethods]
impl PyDataLoaderIterator {
    fn __iter__(slf: PyRef<'_, Self>) -> PyRef<'_, Self> {
        slf
    }

    fn __next__(&mut self) -> PyResult<Option<PyBatchResult>> {
        if self.current_batch >= self.total_batches {
            return Ok(None);
        }

        let start_idx = self.current_batch * self.config.batch_size;
        let end_idx = (start_idx + self.config.batch_size).min(self.indices.len());

        if start_idx >= self.indices.len() {
            return Ok(None);
        }

        // Skip incomplete batch if drop_last is true
        if self.config.drop_last && (end_idx - start_idx) < self.config.batch_size {
            return Ok(None);
        }

        let batch_indices = &self.indices[start_idx..end_idx];
        let batch_size = batch_indices.len();

        if batch_size == 0 {
            return Ok(None);
        }

        // Collect batch samples
        let mut features_data = Vec::new();
        let mut labels_data = Vec::new();
        let mut feature_shape = None;
        let mut label_shape = None;

        for &idx in batch_indices {
            let (feature, label) = self.dataset.__getitem__(idx)?;

            // Store shapes from first sample
            if feature_shape.is_none() {
                feature_shape = Some(feature.shape());
                label_shape = Some(label.shape());
            }

            // Get feature data
            if let Some(data) = feature.inner.as_slice() {
                features_data.extend_from_slice(data);
            } else {
                return Err(PyErr::new::<PyRuntimeError, _>(
                    "Cannot access feature data",
                ));
            }

            // Get label data
            if let Some(data) = label.inner.as_slice() {
                labels_data.extend_from_slice(data);
            } else {
                return Err(PyErr::new::<PyRuntimeError, _>("Cannot access label data"));
            }
        }

        // Create batched tensors
        let feature_shape = feature_shape
            .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Feature shape not determined"))?;
        let label_shape = label_shape
            .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Label shape not determined"))?;

        let mut batched_feature_shape = vec![batch_size];
        batched_feature_shape.extend_from_slice(&feature_shape);

        let mut batched_label_shape = vec![batch_size];
        batched_label_shape.extend_from_slice(&label_shape);

        let batched_features = Tensor::from_vec(features_data, &batched_feature_shape)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
        let batched_labels = Tensor::from_vec(labels_data, &batched_label_shape)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

        self.current_batch += 1;

        Ok(Some(PyBatchResult {
            features: PyTensor {
                inner: batched_features,
            },
            labels: PyTensor {
                inner: batched_labels,
            },
        }))
    }
}

impl PyDataLoaderIterator {
    fn new(dataset: PyTensorDataset, config: PyDataLoaderConfig, shuffle: bool) -> Self {
        let dataset_len = dataset.__len__();
        let mut indices: Vec<usize> = (0..dataset_len).collect();

        if shuffle {
            use ::rand::prelude::*;
            let mut rng = thread_rng();
            indices.shuffle(&mut rng);
        }

        let total_batches = if config.drop_last {
            dataset_len / config.batch_size
        } else {
            (dataset_len + config.batch_size - 1) / config.batch_size
        };

        Self {
            dataset,
            config,
            indices,
            current_batch: 0,
            total_batches,
        }
    }
}

/// Create a DataLoader for efficient batch loading
#[pyfunction]
#[pyo3(signature = (dataset, batch_size=1, shuffle=false, num_workers=1, drop_last=false, pin_memory=false))]
fn data_loader(
    dataset: PyTensorDataset,
    batch_size: usize,
    shuffle: bool,
    num_workers: usize,
    drop_last: bool,
    pin_memory: bool,
) -> PyDataLoader {
    PyDataLoader::new(
        dataset,
        batch_size,
        shuffle,
        num_workers,
        drop_last,
        pin_memory,
    )
}

/// Split a dataset into multiple subsets with specified lengths
#[pyfunction]
fn random_split(dataset: PyTensorDataset, lengths: Vec<usize>) -> PyResult<Vec<PyTensorDataset>> {
    let total_len = dataset.__len__();
    let sum_lengths: usize = lengths.iter().sum();

    // Validate lengths
    if sum_lengths != total_len {
        return Err(PyErr::new::<PyValueError, _>(format!(
            "Sum of lengths ({}) must equal dataset length ({})",
            sum_lengths, total_len
        )));
    }

    if lengths.is_empty() {
        return Err(PyErr::new::<PyValueError, _>("Lengths cannot be empty"));
    }

    // Create shuffled indices
    let mut indices: Vec<usize> = (0..total_len).collect();
    let mut rng = thread_rng();
    indices.shuffle(&mut rng);

    // Split the features and labels tensors
    let features_data = match dataset.features.inner.as_slice() {
        Some(slice) => slice.to_vec(),
        None => {
            return Err(PyErr::new::<PyRuntimeError, _>(
                "Cannot access features data",
            ))
        }
    };

    let labels_data = match dataset.labels.inner.as_slice() {
        Some(slice) => slice.to_vec(),
        None => return Err(PyErr::new::<PyRuntimeError, _>("Cannot access labels data")),
    };

    let features_shape = dataset.features.shape();
    let labels_shape = dataset.labels.shape();

    // Calculate feature and label size per sample
    let feature_size = features_shape.iter().skip(1).product::<usize>();
    let label_size = labels_shape.iter().skip(1).product::<usize>();

    let mut result = Vec::new();
    let mut start_idx = 0;

    for &length in &lengths {
        if length == 0 {
            return Err(PyErr::new::<PyValueError, _>("Length cannot be zero"));
        }

        // Collect indices for this subset
        let subset_indices = &indices[start_idx..start_idx + length];

        // Create new feature tensor for this subset
        let mut subset_features_data = Vec::with_capacity(length * feature_size);
        for &idx in subset_indices {
            let start = idx * feature_size;
            let end = start + feature_size;
            subset_features_data.extend_from_slice(&features_data[start..end]);
        }

        // Create new label tensor for this subset
        let mut subset_labels_data = Vec::with_capacity(length * label_size);
        for &idx in subset_indices {
            let start = idx * label_size;
            let end = start + label_size;
            subset_labels_data.extend_from_slice(&labels_data[start..end]);
        }

        // Create new tensors with correct shapes
        let mut subset_features_shape = features_shape.clone();
        subset_features_shape[0] = length;

        let mut subset_labels_shape = labels_shape.clone();
        subset_labels_shape[0] = length;

        let subset_features = match Tensor::from_vec(subset_features_data, &subset_features_shape) {
            Ok(tensor) => PyTensor { inner: tensor },
            Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        };

        let subset_labels = match Tensor::from_vec(subset_labels_data, &subset_labels_shape) {
            Ok(tensor) => PyTensor { inner: tensor },
            Err(e) => return Err(PyErr::new::<PyRuntimeError, _>(e.to_string())),
        };

        result.push(PyTensorDataset::new(subset_features, subset_labels));
        start_idx += length;
    }

    Ok(result)
}

/// Concatenate multiple datasets into a single dataset
#[pyfunction]
fn concat_dataset(datasets: Vec<PyTensorDataset>) -> PyResult<PyTensorDataset> {
    if datasets.is_empty() {
        return Err(PyErr::new::<PyValueError, _>(
            "Cannot concatenate empty list of datasets",
        ));
    }

    if datasets.len() == 1 {
        return Ok(datasets
            .into_iter()
            .next()
            .expect("Single dataset should be present when length is 1"));
    }

    // Get first dataset for validation and to start concatenation
    let first_dataset = &datasets[0];
    let first_features_shape = first_dataset.features.shape();
    let first_labels_shape = first_dataset.labels.shape();

    // Validate that all datasets have compatible shapes (same except for first dimension)
    for (i, dataset) in datasets.iter().enumerate().skip(1) {
        let features_shape = dataset.features.shape();
        let labels_shape = dataset.labels.shape();

        // Check features shape compatibility
        if features_shape.len() != first_features_shape.len() {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Dataset {} features have different number of dimensions: {} vs {}",
                i,
                features_shape.len(),
                first_features_shape.len()
            )));
        }

        for (dim_idx, (&dim1, &dim2)) in first_features_shape
            .iter()
            .skip(1)
            .zip(features_shape.iter().skip(1))
            .enumerate()
        {
            if dim1 != dim2 {
                return Err(PyErr::new::<PyValueError, _>(format!(
                    "Dataset {} features have incompatible shape at dimension {}: {} vs {}",
                    i,
                    dim_idx + 1,
                    dim1,
                    dim2
                )));
            }
        }

        // Check labels shape compatibility
        if labels_shape.len() != first_labels_shape.len() {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Dataset {} labels have different number of dimensions: {} vs {}",
                i,
                labels_shape.len(),
                first_labels_shape.len()
            )));
        }

        for (dim_idx, (&dim1, &dim2)) in first_labels_shape
            .iter()
            .skip(1)
            .zip(labels_shape.iter().skip(1))
            .enumerate()
        {
            if dim1 != dim2 {
                return Err(PyErr::new::<PyValueError, _>(format!(
                    "Dataset {} labels have incompatible shape at dimension {}: {} vs {}",
                    i,
                    dim_idx + 1,
                    dim1,
                    dim2
                )));
            }
        }
    }

    // Calculate total length for the concatenated dataset
    let total_len: usize = datasets.iter().map(|d| d.__len__()).sum();

    // Create new shapes for concatenated tensors
    let mut concat_features_shape = first_features_shape.clone();
    let mut concat_labels_shape = first_labels_shape.clone();
    concat_features_shape[0] = total_len;
    concat_labels_shape[0] = total_len;

    // Collect slices from all datasets for concatenation
    let mut features_to_concat = Vec::new();
    let mut labels_to_concat = Vec::new();

    // Concatenate all datasets
    for dataset in datasets {
        // Add features and labels from current dataset to concatenation list
        features_to_concat.push(dataset.features.inner.clone());
        labels_to_concat.push(dataset.labels.inner.clone());
    }

    // Perform the actual concatenation
    let features_refs: Vec<&Tensor<f32>> = features_to_concat.iter().collect();
    let labels_refs: Vec<&Tensor<f32>> = labels_to_concat.iter().collect();

    let concat_features = PyTensor {
        inner: tenflowers_core::ops::manipulation::concat(&features_refs, 0).map_err(|e| {
            PyErr::new::<PyRuntimeError, _>(format!("Error concatenating features: {}", e))
        })?,
    };
    let concat_labels = PyTensor {
        inner: tenflowers_core::ops::manipulation::concat(&labels_refs, 0).map_err(|e| {
            PyErr::new::<PyRuntimeError, _>(format!("Error concatenating labels: {}", e))
        })?,
    };

    Ok(PyTensorDataset::new(concat_features, concat_labels))
}

/// Create a PyDataset from a PyTensorDataset
#[pyfunction]
fn dataset_from_tensor(tensor_dataset: PyTensorDataset) -> PyDataset {
    PyDataset::from_tensor_dataset(tensor_dataset)
}

// ================================================================================
// Metrics Functions
// ================================================================================

/// Calculate accuracy between predictions and targets
#[pyfunction]
fn accuracy(predictions: &PyTensor, targets: &PyTensor) -> PyResult<f32> {
    let pred_data = predictions
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot access prediction data"))?;
    let target_data = targets
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot access target data"))?;

    if pred_data.len() != target_data.len() {
        return Err(PyErr::new::<PyRuntimeError, _>(
            "Prediction and target sizes don't match",
        ));
    }

    let mut correct = 0;
    let total = pred_data.len();

    for (pred, target) in pred_data.iter().zip(target_data.iter()) {
        if (pred - target).abs() < 1e-6 {
            correct += 1;
        }
    }

    Ok(correct as f32 / total as f32)
}

/// Calculate precision for binary classification
#[pyfunction]
fn precision(predictions: &PyTensor, targets: &PyTensor, threshold: Option<f32>) -> PyResult<f32> {
    let threshold = threshold.unwrap_or(0.5);

    let pred_data = predictions
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot access prediction data"))?;
    let target_data = targets
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot access target data"))?;

    if pred_data.len() != target_data.len() {
        return Err(PyErr::new::<PyRuntimeError, _>(
            "Prediction and target sizes don't match",
        ));
    }

    let mut true_positives = 0;
    let mut false_positives = 0;

    for (pred, target) in pred_data.iter().zip(target_data.iter()) {
        let pred_binary = if *pred >= threshold { 1.0 } else { 0.0 };
        let target_binary = *target;

        if pred_binary == 1.0 && target_binary == 1.0 {
            true_positives += 1;
        } else if pred_binary == 1.0 && target_binary == 0.0 {
            false_positives += 1;
        }
    }

    if true_positives + false_positives == 0 {
        return Ok(0.0); // No positive predictions
    }

    Ok(true_positives as f32 / (true_positives + false_positives) as f32)
}

/// Calculate recall for binary classification
#[pyfunction]
fn recall(predictions: &PyTensor, targets: &PyTensor, threshold: Option<f32>) -> PyResult<f32> {
    let threshold = threshold.unwrap_or(0.5);

    let pred_data = predictions
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot access prediction data"))?;
    let target_data = targets
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot access target data"))?;

    if pred_data.len() != target_data.len() {
        return Err(PyErr::new::<PyRuntimeError, _>(
            "Prediction and target sizes don't match",
        ));
    }

    let mut true_positives = 0;
    let mut false_negatives = 0;

    for (pred, target) in pred_data.iter().zip(target_data.iter()) {
        let pred_binary = if *pred >= threshold { 1.0 } else { 0.0 };
        let target_binary = *target;

        if pred_binary == 1.0 && target_binary == 1.0 {
            true_positives += 1;
        } else if pred_binary == 0.0 && target_binary == 1.0 {
            false_negatives += 1;
        }
    }

    if true_positives + false_negatives == 0 {
        return Ok(0.0); // No actual positive samples
    }

    Ok(true_positives as f32 / (true_positives + false_negatives) as f32)
}

/// Calculate F1 score for binary classification
#[pyfunction]
fn f1_score(predictions: &PyTensor, targets: &PyTensor, threshold: Option<f32>) -> PyResult<f32> {
    let prec = precision(predictions, targets, threshold)?;
    let rec = recall(predictions, targets, threshold)?;

    if prec + rec == 0.0 {
        return Ok(0.0);
    }

    Ok(2.0 * prec * rec / (prec + rec))
}

/// Generate confusion matrix for binary classification
#[pyfunction]
fn confusion_matrix(
    predictions: &PyTensor,
    targets: &PyTensor,
    threshold: Option<f32>,
) -> PyResult<Vec<Vec<i32>>> {
    let threshold = threshold.unwrap_or(0.5);

    let pred_data = predictions
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot access prediction data"))?;
    let target_data = targets
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot access target data"))?;

    if pred_data.len() != target_data.len() {
        return Err(PyErr::new::<PyRuntimeError, _>(
            "Prediction and target sizes don't match",
        ));
    }

    let mut true_negatives = 0;
    let mut false_positives = 0;
    let mut false_negatives = 0;
    let mut true_positives = 0;

    for (pred, target) in pred_data.iter().zip(target_data.iter()) {
        let pred_binary = if *pred >= threshold { 1.0 } else { 0.0 };
        let target_binary = *target;

        match (pred_binary as i32, target_binary as i32) {
            (0, 0) => true_negatives += 1,
            (1, 0) => false_positives += 1,
            (0, 1) => false_negatives += 1,
            (1, 1) => true_positives += 1,
            _ => {} // Should not happen with binary values
        }
    }

    // Return as 2x2 matrix: [[TN, FP], [FN, TP]]
    Ok(vec![
        vec![true_negatives, false_positives],
        vec![false_negatives, true_positives],
    ])
}

/// Calculate AUC (Area Under the Curve) for binary classification
#[pyfunction]
fn auc(predictions: &PyTensor, targets: &PyTensor) -> PyResult<f32> {
    let pred_data = predictions
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot access prediction data"))?;
    let target_data = targets
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot access target data"))?;

    if pred_data.len() != target_data.len() {
        return Err(PyErr::new::<PyRuntimeError, _>(
            "Prediction and target sizes don't match",
        ));
    }

    // Create pairs of (prediction, target) and sort by prediction score
    let mut pairs: Vec<(f32, f32)> = pred_data
        .iter()
        .zip(target_data.iter())
        .map(|(&pred, &target)| (pred, target))
        .collect();

    // Sort by prediction score in descending order
    pairs.sort_by(|a, b| b.0.partial_cmp(&a.0).unwrap_or(std::cmp::Ordering::Equal));

    let mut tpr_values = Vec::new();
    let mut fpr_values = Vec::new();

    let total_positives = target_data.iter().filter(|&&t| t == 1.0).count() as f32;
    let total_negatives = target_data.iter().filter(|&&t| t == 0.0).count() as f32;

    if total_positives == 0.0 || total_negatives == 0.0 {
        return Ok(0.5); // Random classifier AUC when no positive or negative examples
    }

    let mut tp = 0.0;
    let mut fp = 0.0;

    // Add starting point (0, 0)
    tpr_values.push(0.0);
    fpr_values.push(0.0);

    for (_, target) in pairs {
        if target == 1.0 {
            tp += 1.0;
        } else {
            fp += 1.0;
        }

        let tpr = tp / total_positives;
        let fpr = fp / total_negatives;

        tpr_values.push(tpr);
        fpr_values.push(fpr);
    }

    // Calculate AUC using trapezoidal rule
    let mut auc = 0.0;
    for i in 1..fpr_values.len() {
        let width = fpr_values[i] - fpr_values[i - 1];
        let height = (tpr_values[i] + tpr_values[i - 1]) / 2.0;
        auc += width * height;
    }

    Ok(auc)
}

// ================================================================================
// Gradient Clipping Functions
// ================================================================================

/// Clip gradients by value - clips each gradient element to [-clip_value, clip_value]
#[pyfunction]
fn clip_gradients_value(model: &mut PySequential, clip_value: f32) -> PyResult<()> {
    // Manual implementation for PySequential since it doesn't implement Model<T>
    for layer in &mut model.layers {
        for mut param in layer.parameters() {
            if let Some(grad) = param.inner.grad() {
                // Clamp gradient values
                if let Some(grad_data) = grad.as_slice() {
                    let clipped_data: Vec<f32> = grad_data
                        .iter()
                        .map(|&x| x.max(-clip_value).min(clip_value))
                        .collect();
                    let clipped_grad = Tensor::from_vec(clipped_data, grad.shape().dims())
                        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
                    param.inner.set_grad(Some(clipped_grad));
                }
            }
        }
    }
    Ok(())
}

/// Clip gradients by norm - scales down gradients if their norm exceeds max_norm
#[pyfunction]
fn clip_gradients_norm(model: &mut PySequential, max_norm: f32) -> PyResult<()> {
    // Manual implementation for PySequential
    for layer in &mut model.layers {
        for mut param in layer.parameters() {
            if let Some(grad) = param.inner.grad() {
                if let Some(grad_data) = grad.as_slice() {
                    // Calculate L2 norm
                    let norm_squared: f32 = grad_data.iter().map(|x| x * x).sum();
                    let norm = norm_squared.sqrt();

                    if norm > max_norm {
                        let scale = max_norm / norm;
                        let scaled_data: Vec<f32> = grad_data.iter().map(|&x| x * scale).collect();
                        let scaled_grad = Tensor::from_vec(scaled_data, grad.shape().dims())
                            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
                        param.inner.set_grad(Some(scaled_grad));
                    }
                }
            }
        }
    }
    Ok(())
}

/// Clip gradients by global norm - clips based on global norm across all parameters
#[pyfunction]
fn clip_gradients_global_norm(model: &mut PySequential, max_norm: f32) -> PyResult<f32> {
    // Calculate global norm across all parameters
    let mut global_norm_squared = 0.0f32;

    for layer in &model.layers {
        for param in layer.parameters() {
            if let Some(grad) = param.inner.grad() {
                if let Some(grad_data) = grad.as_slice() {
                    global_norm_squared += grad_data.iter().map(|x| x * x).sum::<f32>();
                }
            }
        }
    }

    let global_norm = global_norm_squared.sqrt();

    if global_norm > max_norm {
        let scale = max_norm / global_norm;
        for layer in &mut model.layers {
            for mut param in layer.parameters() {
                if let Some(grad) = param.inner.grad() {
                    if let Some(grad_data) = grad.as_slice() {
                        let scaled_data: Vec<f32> = grad_data.iter().map(|&x| x * scale).collect();
                        let scaled_grad = Tensor::from_vec(scaled_data, grad.shape().dims())
                            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
                        param.inner.set_grad(Some(scaled_grad));
                    }
                }
            }
        }
    }

    Ok(global_norm)
}

/// Adaptive gradient clipping based on parameter norms (simplified)
#[pyfunction]
fn clip_gradients_adaptive(model: &mut PySequential, clip_factor: f32) -> PyResult<()> {
    // Simplified adaptive clipping - clips based on parameter magnitudes
    for layer in &mut model.layers {
        for mut param in layer.parameters() {
            if let Some(grad) = param.inner.grad() {
                if let (Some(grad_data), Some(param_data)) =
                    (grad.as_slice(), param.inner.as_slice())
                {
                    // Calculate adaptive threshold based on parameter values
                    let param_norm: f32 = param_data.iter().map(|x| x * x).sum::<f32>().sqrt();
                    let adaptive_threshold = clip_factor * param_norm.max(1e-6);

                    let clipped_data: Vec<f32> = grad_data
                        .iter()
                        .map(|&x| x.max(-adaptive_threshold).min(adaptive_threshold))
                        .collect();
                    let clipped_grad = Tensor::from_vec(clipped_data, grad.shape().dims())
                        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
                    param.inner.set_grad(Some(clipped_grad));
                }
            }
        }
    }
    Ok(())
}

// ===== Training Utilities =====

/// Training metrics for epoch tracking
#[pyclass]
#[derive(Clone)]
struct PyTrainingMetrics {
    #[pyo3(get)]
    epoch: usize,
    #[pyo3(get)]
    step: usize,
    #[pyo3(get)]
    loss: f32,
    #[pyo3(get)]
    metrics: HashMap<String, f32>,
}

#[pymethods]
impl PyTrainingMetrics {
    #[new]
    fn new(epoch: usize, step: usize, loss: f32, metrics: Option<HashMap<String, f32>>) -> Self {
        Self {
            epoch,
            step,
            loss,
            metrics: metrics.unwrap_or_default(),
        }
    }

    fn __repr__(&self) -> String {
        format!(
            "TrainingMetrics(epoch={}, step={}, loss={:.4}, metrics={:?})",
            self.epoch, self.step, self.loss, self.metrics
        )
    }
}

/// Training state for tracking training progress
#[pyclass]
#[derive(Clone)]
struct PyTrainingState {
    #[pyo3(get)]
    epoch: usize,
    #[pyo3(get)]
    step: usize,
    #[pyo3(get)]
    best_metric: Option<f32>,
    #[pyo3(get)]
    history: Vec<PyTrainingMetrics>,
    #[pyo3(get)]
    val_history: Vec<PyTrainingMetrics>,
}

#[pymethods]
impl PyTrainingState {
    #[new]
    fn new() -> Self {
        Self {
            epoch: 0,
            step: 0,
            best_metric: None,
            history: Vec::new(),
            val_history: Vec::new(),
        }
    }

    fn __repr__(&self) -> String {
        format!("TrainingState(epoch={}, step={}, best_metric={:?}, history_len={}, val_history_len={})",
                self.epoch, self.step, self.best_metric, self.history.len(), self.val_history.len())
    }
}

/// Callback actions for controlling training
#[pyclass]
#[derive(Clone)]
enum PyCallbackAction {
    Continue(),
    Stop(),
    ReduceLearningRate(f32),
    SaveModel(String),
}

#[pymethods]
impl PyCallbackAction {
    fn __repr__(&self) -> String {
        match self {
            PyCallbackAction::Continue() => "CallbackAction.Continue".to_string(),
            PyCallbackAction::Stop() => "CallbackAction.Stop".to_string(),
            PyCallbackAction::ReduceLearningRate(factor) => {
                format!("CallbackAction.ReduceLearningRate(factor={:.3})", factor)
            }
            PyCallbackAction::SaveModel(filepath) => {
                format!("CallbackAction.SaveModel(filepath='{}')", filepath)
            }
        }
    }
}

/// Early stopping callback
#[pyclass]
struct PyEarlyStopping {
    inner: EarlyStopping,
}

#[pymethods]
impl PyEarlyStopping {
    #[new]
    fn new(patience: usize, min_delta: f32, monitor: String, mode: String) -> Self {
        Self {
            inner: EarlyStopping::new(patience, min_delta, monitor, mode),
        }
    }

    fn on_epoch_end(
        &mut self,
        epoch: usize,
        state: &PyTrainingState,
    ) -> PyResult<PyCallbackAction> {
        // Convert PyTrainingState to native TrainingState
        let native_state = TrainingState {
            epoch: state.epoch,
            step: state.step,
            best_metric: state.best_metric,
            history: state
                .history
                .iter()
                .map(|m| TrainingMetrics {
                    epoch: m.epoch,
                    step: m.step,
                    loss: m.loss,
                    metrics: m.metrics.clone(),
                })
                .collect(),
            val_history: state
                .val_history
                .iter()
                .map(|m| TrainingMetrics {
                    epoch: m.epoch,
                    step: m.step,
                    loss: m.loss,
                    metrics: m.metrics.clone(),
                })
                .collect(),
        };

        let action = Callback::<f32>::on_epoch_end(&mut self.inner, epoch, &native_state)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

        Ok(match action {
            CallbackAction::Continue => PyCallbackAction::Continue(),
            CallbackAction::Stop => PyCallbackAction::Stop(),
            CallbackAction::ReduceLearningRate(factor) => {
                PyCallbackAction::ReduceLearningRate(factor)
            }
            CallbackAction::SaveModel(filepath) => PyCallbackAction::SaveModel(filepath),
        })
    }

    fn __repr__(&self) -> String {
        format!(
            "EarlyStopping(patience={}, min_delta={:.4}, monitor='{}', mode='{}')",
            self.inner.patience, self.inner.min_delta, self.inner.monitor, self.inner.mode
        )
    }
}

/// Model checkpoint callback
#[pyclass]
struct PyModelCheckpoint {
    inner: ModelCheckpoint<f32>,
}

#[pymethods]
impl PyModelCheckpoint {
    #[new]
    fn new(filepath: String, monitor: String, mode: String, save_best_only: bool) -> Self {
        Self {
            inner: ModelCheckpoint::new(filepath, monitor, mode, save_best_only),
        }
    }

    fn on_epoch_end(
        &mut self,
        epoch: usize,
        state: &PyTrainingState,
    ) -> PyResult<PyCallbackAction> {
        // Convert PyTrainingState to native TrainingState
        let native_state = TrainingState {
            epoch: state.epoch,
            step: state.step,
            best_metric: state.best_metric,
            history: state
                .history
                .iter()
                .map(|m| TrainingMetrics {
                    epoch: m.epoch,
                    step: m.step,
                    loss: m.loss,
                    metrics: m.metrics.clone(),
                })
                .collect(),
            val_history: state
                .val_history
                .iter()
                .map(|m| TrainingMetrics {
                    epoch: m.epoch,
                    step: m.step,
                    loss: m.loss,
                    metrics: m.metrics.clone(),
                })
                .collect(),
        };

        let action = Callback::<f32>::on_epoch_end(&mut self.inner, epoch, &native_state)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

        Ok(match action {
            CallbackAction::Continue => PyCallbackAction::Continue(),
            CallbackAction::Stop => PyCallbackAction::Stop(),
            CallbackAction::ReduceLearningRate(factor) => {
                PyCallbackAction::ReduceLearningRate(factor)
            }
            CallbackAction::SaveModel(filepath) => PyCallbackAction::SaveModel(filepath),
        })
    }

    fn __repr__(&self) -> String {
        format!(
            "ModelCheckpoint(filepath='{}', monitor='{}', mode='{}', save_best_only={})",
            self.inner.filepath, self.inner.monitor, self.inner.mode, self.inner.save_best_only
        )
    }
}

/// Learning rate reduction callback
#[pyclass]
struct PyLearningRateReduction {
    inner: LearningRateReduction<f32>,
}

#[pymethods]
impl PyLearningRateReduction {
    #[new]
    fn new(
        monitor: String,
        factor: Option<f32>,
        patience: Option<usize>,
        min_delta: Option<f32>,
        cooldown: Option<usize>,
        min_lr: Option<f32>,
        mode: Option<String>,
        verbose: Option<bool>,
    ) -> Self {
        let mut lr_reducer = LearningRateReduction::with_defaults(monitor);

        if let Some(f) = factor {
            lr_reducer = lr_reducer.factor(f);
        }
        if let Some(p) = patience {
            lr_reducer = lr_reducer.patience(p);
        }
        if let Some(v) = verbose {
            lr_reducer = lr_reducer.verbose(v);
        }
        if let Some(m) = min_lr {
            lr_reducer = lr_reducer.min_lr(m);
        }

        Self { inner: lr_reducer }
    }

    fn on_epoch_end(
        &mut self,
        epoch: usize,
        state: &PyTrainingState,
    ) -> PyResult<PyCallbackAction> {
        // Convert PyTrainingState to native TrainingState
        let native_state = TrainingState {
            epoch: state.epoch,
            step: state.step,
            best_metric: state.best_metric,
            history: state
                .history
                .iter()
                .map(|m| TrainingMetrics {
                    epoch: m.epoch,
                    step: m.step,
                    loss: m.loss,
                    metrics: m.metrics.clone(),
                })
                .collect(),
            val_history: state
                .val_history
                .iter()
                .map(|m| TrainingMetrics {
                    epoch: m.epoch,
                    step: m.step,
                    loss: m.loss,
                    metrics: m.metrics.clone(),
                })
                .collect(),
        };

        let action = Callback::<f32>::on_epoch_end(&mut self.inner, epoch, &native_state)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

        Ok(match action {
            CallbackAction::Continue => PyCallbackAction::Continue(),
            CallbackAction::Stop => PyCallbackAction::Stop(),
            CallbackAction::ReduceLearningRate(factor) => {
                PyCallbackAction::ReduceLearningRate(factor)
            }
            CallbackAction::SaveModel(filepath) => PyCallbackAction::SaveModel(filepath),
        })
    }

    fn __repr__(&self) -> String {
        format!(
            "LearningRateReduction(monitor='{}', factor={:.3}, patience={}, verbose={})",
            self.inner.monitor, self.inner.factor, self.inner.patience, self.inner.verbose
        )
    }
}

/// Tensorboard callback (only available with tensorboard feature)
#[cfg(feature = "tensorboard")]
#[pyclass]
struct PyTensorboardCallback {
    inner: TensorboardCallback,
}

#[cfg(feature = "tensorboard")]
#[pymethods]
impl PyTensorboardCallback {
    #[new]
    fn new(log_dir: String, log_frequency: Option<usize>) -> Self {
        Self {
            inner: TensorboardCallback::new(log_dir, log_frequency),
        }
    }

    fn on_epoch_end(
        &mut self,
        epoch: usize,
        state: &PyTrainingState,
    ) -> PyResult<PyCallbackAction> {
        // Convert PyTrainingState to native TrainingState
        let native_state = TrainingState {
            epoch: state.epoch,
            step: state.step,
            best_metric: state.best_metric,
            history: state
                .history
                .iter()
                .map(|m| TrainingMetrics {
                    epoch: m.epoch,
                    step: m.step,
                    loss: m.loss,
                    metrics: m.metrics.clone(),
                })
                .collect(),
            val_history: state
                .val_history
                .iter()
                .map(|m| TrainingMetrics {
                    epoch: m.epoch,
                    step: m.step,
                    loss: m.loss,
                    metrics: m.metrics.clone(),
                })
                .collect(),
        };

        let action = Callback::<f32>::on_epoch_end(&mut self.inner, epoch, &native_state)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

        Ok(match action {
            CallbackAction::Continue => PyCallbackAction::Continue(),
            CallbackAction::Stop => PyCallbackAction::Stop(),
            CallbackAction::ReduceLearningRate(factor) => {
                PyCallbackAction::ReduceLearningRate(factor)
            }
            CallbackAction::SaveModel(filepath) => PyCallbackAction::SaveModel(filepath),
        })
    }

    fn __repr__(&self) -> String {
        format!(
            "TensorboardCallback(log_dir='{}', log_frequency={})",
            self.inner.log_dir, self.inner.log_frequency
        )
    }
}

/// High-level trainer for model training
#[pyclass]
struct PyTrainer {
    callbacks: Vec<PyObject>,
    verbose: bool,
}

#[pymethods]
impl PyTrainer {
    #[new]
    fn new() -> Self {
        Self {
            callbacks: Vec::new(),
            verbose: true,
        }
    }

    /// Add a callback to the trainer
    fn add_callback(&mut self, callback: PyObject) {
        self.callbacks.push(callback);
    }

    /// Set verbose mode
    fn set_verbose(&mut self, verbose: bool) {
        self.verbose = verbose;
    }

    /// Basic training loop for a PySequential model
    #[pyo3(signature = (model, train_data, epochs, learning_rate, val_data=None, loss_fn=None))]
    fn fit(
        &mut self,
        py: Python,
        model: &mut PySequential,
        train_data: Bound<PyList>,
        epochs: usize,
        learning_rate: f32,
        val_data: Option<Bound<PyList>>,
        loss_fn: Option<&str>,
    ) -> PyResult<PyTrainingState> {
        let mut state = PyTrainingState::new();

        // Create a simple SGD optimizer for demonstration
        let mut optimizer = PySGD::new(learning_rate, Some(0.0));

        // Call training begin callbacks
        for callback in &self.callbacks {
            if let Ok(method) = callback.getattr(py, "on_train_begin") {
                method.call1(py, (state.clone(),))?;
            }
        }

        // Set model to training mode
        model.train();

        for epoch in 0..epochs {
            state.epoch = epoch;

            // Call epoch begin callbacks
            for callback in &self.callbacks {
                if let Ok(method) = callback.getattr(py, "on_epoch_begin") {
                    method.call1(py, (epoch, state.clone()))?;
                }
            }

            // Training epoch
            let train_metrics = self.train_epoch(
                py,
                model,
                &mut optimizer,
                train_data.clone(),
                &mut state,
                loss_fn,
            )?;
            state.history.push(train_metrics.clone());

            if self.verbose {
                println!(
                    "Epoch {}/{} - loss: {:.4}",
                    epoch + 1,
                    epochs,
                    train_metrics.loss
                );
            }

            // Validation epoch
            if let Some(ref val_data_list) = val_data {
                let val_metrics =
                    self.validate_epoch(py, model, val_data_list.clone(), &mut state, loss_fn)?;
                state.val_history.push(val_metrics.clone());

                if self.verbose {
                    print!(" - val_loss: {:.4}", val_metrics.loss);

                    // Display additional metrics
                    if let Some(accuracy) = val_metrics.metrics.get("accuracy") {
                        print!(" - val_accuracy: {accuracy:.4}");
                    }
                    println!();
                }
            }

            // Call epoch end callbacks and handle actions
            let mut should_continue = true;
            for callback in &self.callbacks {
                if let Ok(method) = callback.getattr(py, "on_epoch_end") {
                    if let Ok(action) = method.call1(py, (epoch, state.clone())) {
                        // Handle callback action
                        if let Ok(action_str) = action.bind(py).str() {
                            let action_text = action_str.to_str()?;
                            if action_text.contains("Stop") {
                                should_continue = false;
                                break;
                            } else if action_text.contains("ReduceLearningRate") {
                                // Extract factor from action and adjust learning rate
                                let current_lr = learning_rate * 0.1; // Simple reduction
                                if self.verbose {
                                    println!("Learning rate reduced to {:.6}", current_lr);
                                }
                                // Note: In a full implementation, we'd update the optimizer's learning rate
                            } else if action_text.contains("SaveModel") {
                                if self.verbose {
                                    println!("Model save requested");
                                }
                                // Note: In a full implementation, we'd save the model
                            }
                        }
                    }
                }
            }

            if !should_continue {
                break;
            }
        }

        // Call training end callbacks
        for callback in &self.callbacks {
            if let Ok(method) = callback.getattr(py, "on_train_end") {
                method.call1(py, (state.clone(),))?;
            }
        }

        Ok(state)
    }

    /// Train for one epoch
    fn train_epoch(
        &mut self,
        py: Python,
        model: &mut PySequential,
        optimizer: &mut PySGD,
        train_data: Bound<PyList>,
        state: &mut PyTrainingState,
        loss_fn: Option<&str>,
    ) -> PyResult<PyTrainingMetrics> {
        let mut total_loss = 0.0f32;
        let mut batch_count = 0;

        for batch in train_data.iter() {
            // Call batch begin callbacks
            for callback in &self.callbacks {
                if let Ok(method) = callback.getattr(py, "on_batch_begin") {
                    method.call1(py, (state.step, state.clone()))?;
                }
            }

            // Expect batch to be a tuple of (input, target)
            if let Ok(batch_tuple) = batch.downcast::<PyTuple>() {
                if batch_tuple.len() == 2 {
                    let input = batch_tuple.get_item(0)?;
                    let target = batch_tuple.get_item(1)?;

                    // Convert to PyTensor
                    let input_tensor: PyTensor = input.extract()?;
                    let target_tensor: PyTensor = target.extract()?;

                    // Zero gradients
                    optimizer.zero_grad(model);

                    // Forward pass
                    let predictions = model.forward(&input_tensor)?;

                    // Compute loss
                    let loss = match loss_fn {
                        Some("mse") => mse_loss(&predictions, &target_tensor)?,
                        Some("binary_cross_entropy") => {
                            binary_cross_entropy_loss(&predictions, &target_tensor)?
                        }
                        Some("categorical_cross_entropy") => {
                            categorical_cross_entropy_loss(&predictions, &target_tensor)?
                        }
                        _ => mse_loss(&predictions, &target_tensor)?, // Default to MSE
                    };

                    // Get scalar loss value
                    let loss_value = loss
                        .inner
                        .get(&[])
                        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Loss must be a scalar"))?;

                    // Simplified backward pass - in a full implementation,
                    // this would use proper autograd
                    // For now, we'll just step the optimizer
                    optimizer.step(model)?;

                    total_loss += loss_value;
                    batch_count += 1;
                    state.step += 1;

                    // Call batch end callbacks
                    for callback in &self.callbacks {
                        if let Ok(method) = callback.getattr(py, "on_batch_end") {
                            method.call1(py, (state.step, state.clone()))?;
                        }
                    }
                }
            }
        }

        let avg_loss = if batch_count > 0 {
            total_loss / batch_count as f32
        } else {
            0.0
        };

        Ok(PyTrainingMetrics {
            epoch: state.epoch,
            step: state.step,
            loss: avg_loss,
            metrics: HashMap::new(),
        })
    }

    /// Validate for one epoch
    fn validate_epoch(
        &mut self,
        py: Python,
        model: &mut PySequential,
        val_data: Bound<PyList>,
        state: &mut PyTrainingState,
        loss_fn: Option<&str>,
    ) -> PyResult<PyTrainingMetrics> {
        // Set model to evaluation mode
        model.eval();

        let mut total_loss = 0.0f32;
        let mut batch_count = 0;
        let mut correct = 0;
        let mut total = 0;

        for batch in val_data.iter() {
            // Expect batch to be a tuple of (input, target)
            if let Ok(batch_tuple) = batch.downcast::<PyTuple>() {
                if batch_tuple.len() == 2 {
                    let input = batch_tuple.get_item(0)?;
                    let target = batch_tuple.get_item(1)?;

                    // Convert to PyTensor
                    let input_tensor: PyTensor = input.extract()?;
                    let target_tensor: PyTensor = target.extract()?;

                    // Forward pass only (no gradients)
                    let predictions = model.forward(&input_tensor)?;

                    // Compute loss
                    let loss = match loss_fn {
                        Some("mse") => mse_loss(&predictions, &target_tensor)?,
                        Some("binary_cross_entropy") => {
                            binary_cross_entropy_loss(&predictions, &target_tensor)?
                        }
                        Some("categorical_cross_entropy") => {
                            categorical_cross_entropy_loss(&predictions, &target_tensor)?
                        }
                        _ => mse_loss(&predictions, &target_tensor)?, // Default to MSE
                    };

                    // Get scalar loss value
                    let loss_value = loss
                        .inner
                        .get(&[])
                        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Loss must be a scalar"))?;

                    total_loss += loss_value;
                    batch_count += 1;

                    // Calculate accuracy for classification tasks
                    if let (Some(pred_data), Some(target_data)) =
                        (predictions.inner.as_slice(), target_tensor.inner.as_slice())
                    {
                        let batch_size = pred_data.len().min(target_data.len());
                        for i in 0..batch_size {
                            let pred_class = if pred_data[i] > 0.5 { 1 } else { 0 };
                            let target_class = if target_data[i] > 0.5 { 1 } else { 0 };
                            if pred_class == target_class {
                                correct += 1;
                            }
                            total += 1;
                        }
                    }
                }
            }
        }

        let avg_loss = if batch_count > 0 {
            total_loss / batch_count as f32
        } else {
            0.0
        };

        let accuracy = if total > 0 {
            correct as f32 / total as f32
        } else {
            0.0
        };

        let mut metrics = HashMap::new();
        metrics.insert("accuracy".to_string(), accuracy);

        // Set model back to training mode
        model.train();

        Ok(PyTrainingMetrics {
            epoch: state.epoch,
            step: state.step,
            loss: avg_loss,
            metrics,
        })
    }

    fn __repr__(&self) -> String {
        format!(
            "Trainer(callbacks={}, verbose={})",
            self.callbacks.len(),
            self.verbose
        )
    }
}

// ===== Distributed Training Functions =====

/// Initialize distributed training
#[pyfunction]
fn init_distributed() -> PyResult<()> {
    init_collective().map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
    Ok(())
}

/// Create a process group for distributed training
#[pyfunction]
fn create_process_group_py(name: String, devices: Vec<String>) -> PyResult<()> {
    let parsed_devices: Result<Vec<Device>, _> =
        devices.iter().map(|d| Device::from_str(d)).collect();

    let parsed_devices = parsed_devices
        .map_err(|e| PyErr::new::<PyValueError, _>(format!("Invalid device: {}", e)))?;

    create_process_group(name, parsed_devices)
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
    Ok(())
}

/// Perform gradient AllReduce for distributed training
#[pyfunction]
fn all_reduce_gradients_py(
    gradients: Vec<PyTensor>,
    group_name: Option<String>,
) -> PyResult<Vec<PyTensor>> {
    let tensors: Vec<_> = gradients.into_iter().map(|g| g.inner).collect();

    let reduced_gradients = all_reduce_gradients(&tensors, group_name.as_deref())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    let py_gradients = reduced_gradients
        .into_iter()
        .map(|g| PyTensor { inner: g })
        .collect();

    Ok(py_gradients)
}

/// Synchronize parameters across all devices
#[pyfunction]
fn sync_parameters_py(
    parameters: Vec<PyTensor>,
    src_device: String,
    group_name: Option<String>,
) -> PyResult<Vec<Vec<PyTensor>>> {
    let src_device = Device::from_str(&src_device)
        .map_err(|e| PyErr::new::<PyValueError, _>(format!("Invalid device: {}", e)))?;

    let tensors: Vec<_> = parameters.into_iter().map(|p| p.inner).collect();

    let synced_parameters = sync_parameters(&tensors, src_device, group_name.as_deref())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    let py_parameters = synced_parameters
        .into_iter()
        .map(|device_params| {
            device_params
                .into_iter()
                .map(|p| PyTensor { inner: p })
                .collect()
        })
        .collect();

    Ok(py_parameters)
}

/// Ring AllReduce for efficient gradient aggregation
#[pyfunction]
fn ring_all_reduce_py(tensor: PyTensor, group_name: Option<String>) -> PyResult<PyTensor> {
    let reduced_tensor = ring_all_reduce(&tensor.inner, group_name.as_deref())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    Ok(PyTensor {
        inner: reduced_tensor,
    })
}

/// Distributed training helper to aggregate gradients from a model
#[pyfunction]
fn all_reduce_model_gradients(
    model: &mut PySequential,
    group_name: Option<String>,
) -> PyResult<()> {
    let mut all_gradients = Vec::new();

    // Collect all gradients from model parameters
    for layer in &model.layers {
        for param in layer.parameters() {
            if let Some(grad) = param.inner.grad() {
                all_gradients.push(grad.clone());
            }
        }
    }

    if all_gradients.is_empty() {
        return Ok(());
    }

    // Perform AllReduce on all gradients
    let reduced_gradients = all_reduce_gradients(&all_gradients, group_name.as_deref())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    // Set reduced gradients back to model parameters
    let mut grad_idx = 0;
    for layer in &mut model.layers {
        for mut param in layer.parameters() {
            if param.inner.grad().is_some() {
                param
                    .inner
                    .set_grad(Some(reduced_gradients[grad_idx].clone()));
                grad_idx += 1;
            }
        }
    }

    Ok(())
}

/// Distributed training helper to synchronize model parameters
#[pyfunction]
fn sync_model_parameters(
    model: &mut PySequential,
    src_device: String,
    group_name: Option<String>,
) -> PyResult<()> {
    let src_device = Device::from_str(&src_device)
        .map_err(|e| PyErr::new::<PyValueError, _>(format!("Invalid device: {}", e)))?;

    let mut all_parameters = Vec::new();

    // Collect all parameters from model
    for layer in &model.layers {
        for param in layer.parameters() {
            all_parameters.push(param.inner.clone());
        }
    }

    if all_parameters.is_empty() {
        return Ok(());
    }

    // Synchronize parameters across devices
    let synced_parameters = sync_parameters(&all_parameters, src_device, group_name.as_deref())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    // For now, just update with the first device's parameters
    // In a real implementation, you'd choose the appropriate device
    if let Some(device_params) = synced_parameters.first() {
        let mut param_idx = 0;
        for layer in &mut model.layers {
            for mut param in layer.parameters() {
                if param_idx < device_params.len() {
                    param.inner = device_params[param_idx].clone();
                    param_idx += 1;
                }
            }
        }
    }

    Ok(())
}

// ===== Quantization Classes and Functions =====

#[pyclass]
#[derive(Clone)]
struct PyQuantizationParams {
    inner: QuantizationParams,
}

#[pymethods]
impl PyQuantizationParams {
    #[new]
    fn new(scale: f32, zero_point: i32, dtype: String, qmin: i32, qmax: i32) -> PyResult<Self> {
        let dtype = match dtype.as_str() {
            "int8" => DType::Int8,
            "int4" => DType::Int4,
            _ => {
                return Err(PyErr::new::<PyValueError, _>(format!(
                    "Unsupported dtype: {}",
                    dtype
                )))
            }
        };

        Ok(Self {
            inner: QuantizationParams {
                scale,
                zero_point,
                dtype,
                qmin,
                qmax,
            },
        })
    }

    #[staticmethod]
    fn symmetric_int8(scale: f32) -> Self {
        Self {
            inner: QuantizationParams::symmetric_int8(scale),
        }
    }

    #[staticmethod]
    fn asymmetric_int8(scale: f32, zero_point: i32) -> Self {
        Self {
            inner: QuantizationParams::asymmetric_int8(scale, zero_point),
        }
    }

    #[staticmethod]
    fn symmetric_int4(scale: f32) -> Self {
        Self {
            inner: QuantizationParams::symmetric_int4(scale),
        }
    }

    #[staticmethod]
    fn asymmetric_int4(scale: f32, zero_point: i32) -> Self {
        Self {
            inner: QuantizationParams::asymmetric_int4(scale, zero_point),
        }
    }

    #[staticmethod]
    fn from_tensor_stats(min_val: f32, max_val: f32, dtype: String) -> PyResult<Self> {
        let dtype = match dtype.as_str() {
            "int8" => DType::Int8,
            "int4" => DType::Int4,
            _ => {
                return Err(PyErr::new::<PyValueError, _>(format!(
                    "Unsupported dtype: {}",
                    dtype
                )))
            }
        };

        Ok(Self {
            inner: QuantizationParams::from_tensor_stats(min_val, max_val, dtype).map_err(|e| {
                PyErr::new::<PyValueError, _>(format!(
                    "Failed to create quantization params: {}",
                    e
                ))
            })?,
        })
    }

    #[staticmethod]
    fn asymmetric_from_tensor_stats(min_val: f32, max_val: f32, dtype: String) -> PyResult<Self> {
        let dtype = match dtype.as_str() {
            "int8" => DType::Int8,
            "int4" => DType::Int4,
            _ => {
                return Err(PyErr::new::<PyValueError, _>(format!(
                    "Unsupported dtype: {}",
                    dtype
                )))
            }
        };

        Ok(Self {
            inner: QuantizationParams::asymmetric_from_tensor_stats(min_val, max_val, dtype)
                .map_err(|e| {
                    PyErr::new::<PyValueError, _>(format!(
                        "Failed to create asymmetric quantization params: {}",
                        e
                    ))
                })?,
        })
    }

    #[getter]
    fn scale(&self) -> f32 {
        self.inner.scale
    }

    #[getter]
    fn zero_point(&self) -> i32 {
        self.inner.zero_point
    }

    #[getter]
    fn qmin(&self) -> i32 {
        self.inner.qmin
    }

    #[getter]
    fn qmax(&self) -> i32 {
        self.inner.qmax
    }

    #[getter]
    fn dtype(&self) -> String {
        match self.inner.dtype {
            DType::Int8 => "int8".to_string(),
            DType::Int4 => "int4".to_string(),
            _ => "unknown".to_string(),
        }
    }
}

/// Quantize a tensor to INT8 or INT4
#[pyfunction]
fn quantize_tensor(tensor: &PyTensor, params: &PyQuantizationParams) -> PyResult<PyTensor> {
    let quantized = quantize(&tensor.inner, &params.inner)
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    // Convert i8 tensor to f32 tensor for PyTensor compatibility
    let quantized_f32 = dequantize(&quantized, &params.inner)
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    Ok(PyTensor {
        inner: quantized_f32,
    })
}

/// Dequantize a tensor back to float32
#[pyfunction]
fn dequantize_tensor(tensor: &PyTensor, params: &PyQuantizationParams) -> PyResult<PyTensor> {
    // Convert the input tensor to i8 for dequantization
    let i8_tensor =
        if tensor.inner.dtype() == DType::Int8 {
            // Cast to i8 tensor type
            let data = tensor.inner.as_slice().ok_or_else(|| {
                PyErr::new::<PyRuntimeError, _>("Tensor data not available on CPU")
            })?;
            let i8_data: Vec<i8> = data.iter().map(|&x| x as i8).collect();
            Tensor::from_vec(i8_data, tensor.inner.shape().dims())
                .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?
        } else {
            // Convert f32 to i8 for testing purposes
            let data = tensor.inner.as_slice().ok_or_else(|| {
                PyErr::new::<PyRuntimeError, _>("Tensor data not available on CPU")
            })?;
            let i8_data: Vec<i8> = data.iter().map(|&x| x as i8).collect();
            Tensor::from_vec(i8_data, tensor.inner.shape().dims())
                .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?
        };

    let dequantized = dequantize(&i8_tensor, &params.inner)
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    Ok(PyTensor { inner: dequantized })
}

/// Dynamic quantization - calculates quantization parameters on the fly
#[pyfunction]
fn dynamic_quantize_tensor(
    tensor: &PyTensor,
    dtype: String,
) -> PyResult<(PyTensor, PyQuantizationParams)> {
    let dtype = match dtype.as_str() {
        "int8" => DType::Int8,
        "int4" => DType::Int4,
        _ => {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Unsupported dtype: {}",
                dtype
            )))
        }
    };

    let (quantized, params) = dynamic_quantize(&tensor.inner, dtype)
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    // Convert back to f32 for PyTensor compatibility
    let quantized_data = quantized.as_slice().ok_or_else(|| {
        PyErr::new::<PyRuntimeError, _>("Quantized tensor data not available on CPU")
    })?;
    let f32_data: Vec<f32> = quantized_data.iter().map(|&x| x as f32).collect();
    let f32_tensor = Tensor::from_vec(f32_data, quantized.shape().dims())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    Ok((
        PyTensor { inner: f32_tensor },
        PyQuantizationParams { inner: params },
    ))
}

/// Fake quantization for quantization-aware training
#[pyfunction]
fn fake_quantize_tensor(tensor: &PyTensor, params: &PyQuantizationParams) -> PyResult<PyTensor> {
    let fake_quantized = fake_quantize(&tensor.inner, &params.inner)
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    Ok(PyTensor {
        inner: fake_quantized,
    })
}

/// Per-channel quantization for neural network weights
#[pyfunction]
fn per_channel_quantize_tensor(
    tensor: &PyTensor,
    channel_axis: usize,
) -> PyResult<(PyTensor, Vec<PyQuantizationParams>)> {
    let (quantized, params_vec) = per_channel_quantize(&tensor.inner, channel_axis)
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    // Convert back to f32 for PyTensor compatibility
    let quantized_data = quantized.as_slice().ok_or_else(|| {
        PyErr::new::<PyRuntimeError, _>("Quantized tensor data not available on CPU")
    })?;
    let f32_data: Vec<f32> = quantized_data.iter().map(|&x| x as f32).collect();
    let f32_tensor = Tensor::from_vec(f32_data, quantized.shape().dims())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

    let py_params: Vec<PyQuantizationParams> = params_vec
        .into_iter()
        .map(|p| PyQuantizationParams { inner: p })
        .collect();

    Ok((PyTensor { inner: f32_tensor }, py_params))
}

/// Quantize a model for inference
#[pyfunction]
fn quantize_model(model: &mut PySequential, dtype: String) -> PyResult<()> {
    let dtype = match dtype.as_str() {
        "int8" => DType::Int8,
        "int4" => DType::Int4,
        _ => {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Unsupported dtype: {}",
                dtype
            )))
        }
    };

    // Quantize all model parameters
    for layer in &mut model.layers {
        for mut param in layer.parameters() {
            let (quantized, _params) = dynamic_quantize(&param.inner, dtype)
                .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

            // Convert back to f32 for PyTensor compatibility
            let quantized_data = quantized.as_slice().ok_or_else(|| {
                PyErr::new::<PyRuntimeError, _>("Quantized tensor data not available on CPU")
            })?;
            let f32_data: Vec<f32> = quantized_data.iter().map(|&x| x as f32).collect();
            let f32_tensor = Tensor::from_vec(f32_data, quantized.shape().dims())
                .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

            param.inner = f32_tensor;
        }
    }

    Ok(())
}

/// Enable quantization-aware training for a model
#[pyfunction]
fn enable_qat(model: &mut PySequential, dtype: String) -> PyResult<()> {
    let dtype = match dtype.as_str() {
        "int8" => DType::Int8,
        "int4" => DType::Int4,
        _ => {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Unsupported dtype: {}",
                dtype
            )))
        }
    };

    // Apply fake quantization to all model parameters
    for layer in &mut model.layers {
        for mut param in layer.parameters() {
            // Calculate dynamic quantization parameters
            let (_quantized, params) = dynamic_quantize(&param.inner, dtype)
                .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

            // Apply fake quantization
            let fake_quantized = fake_quantize(&param.inner, &params)
                .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;
            param.inner = fake_quantized;
        }
    }

    Ok(())
}

/// Calibrate quantization parameters using a calibration dataset
#[pyfunction]
fn calibrate_quantization(
    model: &PySequential,
    calibration_data: Vec<PyTensor>,
) -> PyResult<Vec<PyQuantizationParams>> {
    let mut calibration_params = Vec::new();

    // For each layer, collect statistics during calibration
    for layer in &model.layers {
        for param in layer.parameters() {
            // Calculate statistics from the parameter
            if let Some(data) = param.inner.as_slice() {
                let min_val = data.iter().fold(f32::INFINITY, |a, &b| a.min(b));
                let max_val = data.iter().fold(f32::NEG_INFINITY, |a, &b| a.max(b));

                let params = QuantizationParams::from_tensor_stats(min_val, max_val, DType::Int8)
                    .map_err(|e| {
                    PyErr::new::<PyValueError, _>(format!(
                        "Failed to create calibration params: {}",
                        e
                    ))
                })?;
                calibration_params.push(PyQuantizationParams { inner: params });
            }
        }
    }

    Ok(calibration_params)
}

/// Quantization-aware training step
#[pyfunction]
fn qat_training_step(
    model: &mut PySequential,
    inputs: &PyTensor,
    targets: &PyTensor,
) -> PyResult<PyTensor> {
    // This would be a complete training step with fake quantization
    // For now, just return a placeholder loss
    let loss = Tensor::from_scalar(0.5f32);
    Ok(PyTensor { inner: loss })
}

/// Inference optimization for quantized models
#[pyfunction]
fn optimize_quantized_inference(model: &mut PySequential) -> PyResult<()> {
    // Apply inference-specific optimizations
    // 1. Fuse operations where possible
    // 2. Optimize memory layout
    // 3. Enable fast quantized kernels

    // For now, this is a placeholder
    Ok(())
}

// ===== Transform API Implementation =====

/// Base trait for tensor transforms
pub trait Transform {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor>;
}

/// Compose multiple transforms together
#[pyclass]
#[derive(Clone)]
pub struct PyCompose {
    transforms: Vec<PyTransform>,
}

#[pymethods]
impl PyCompose {
    #[new]
    fn new(transforms: Vec<PyTransform>) -> Self {
        Self { transforms }
    }

    fn __call__(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        let mut result = tensor.clone();
        for transform in &self.transforms {
            result = transform.transform(&result)?;
        }
        Ok(result)
    }

    fn __repr__(&self) -> String {
        format!("PyCompose(transforms={})", self.transforms.len())
    }
}

/// Normalize tensor values to [0, 1] or specified range
#[pyclass]
#[derive(Clone)]
pub struct PyNormalize {
    min_val: Option<f32>,
    max_val: Option<f32>,
    target_min: f32,
    target_max: f32,
}

#[pymethods]
impl PyNormalize {
    #[new]
    #[pyo3(signature = (min_val=None, max_val=None, target_min=0.0, target_max=1.0))]
    fn new(min_val: Option<f32>, max_val: Option<f32>, target_min: f32, target_max: f32) -> Self {
        Self {
            min_val,
            max_val,
            target_min,
            target_max,
        }
    }

    fn __call__(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }

    fn __repr__(&self) -> String {
        format!(
            "PyNormalize(min={:?}, max={:?}, target_range=[{}, {}])",
            self.min_val, self.max_val, self.target_min, self.target_max
        )
    }
}

impl Transform for PyNormalize {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        let data = tensor
            .inner
            .as_slice()
            .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

        let (min_val, max_val) = if let (Some(min), Some(max)) = (self.min_val, self.max_val) {
            (min, max)
        } else {
            let min = data.iter().fold(f32::INFINITY, |a, &b| a.min(b));
            let max = data.iter().fold(f32::NEG_INFINITY, |a, &b| a.max(b));
            (min, max)
        };

        if (max_val - min_val).abs() < f32::EPSILON {
            return Ok(tensor.clone());
        }

        let normalized_data: Vec<f32> = data
            .iter()
            .map(|&x| {
                let normalized = (x - min_val) / (max_val - min_val);
                self.target_min + normalized * (self.target_max - self.target_min)
            })
            .collect();

        let shape = tensor.inner.shape().dims().to_vec();
        let result_tensor = Tensor::from_vec(normalized_data, &shape)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

        Ok(PyTensor {
            inner: result_tensor,
        })
    }
}

/// Standardize tensor values (zero mean, unit variance)
#[pyclass]
#[derive(Clone)]
pub struct PyStandardize {
    mean: Option<f32>,
    std: Option<f32>,
}

#[pymethods]
impl PyStandardize {
    #[new]
    #[pyo3(signature = (mean=None, std=None))]
    fn new(mean: Option<f32>, std: Option<f32>) -> Self {
        Self { mean, std }
    }

    fn __call__(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }

    fn __repr__(&self) -> String {
        format!("PyStandardize(mean={:?}, std={:?})", self.mean, self.std)
    }
}

impl Transform for PyStandardize {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        let data = tensor
            .inner
            .as_slice()
            .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

        let (mean, std) = if let (Some(m), Some(s)) = (self.mean, self.std) {
            (m, s)
        } else {
            let mean = data.iter().sum::<f32>() / data.len() as f32;
            let variance =
                data.iter().map(|&x| (x - mean).powi(2)).sum::<f32>() / data.len() as f32;
            let std = variance.sqrt();
            (mean, std)
        };

        if std.abs() < f32::EPSILON {
            return Ok(tensor.clone());
        }

        let standardized_data: Vec<f32> = data.iter().map(|&x| (x - mean) / std).collect();

        let shape = tensor.inner.shape().dims().to_vec();
        let result_tensor = Tensor::from_vec(standardized_data, &shape)
            .map_err(|e| PyErr::new::<PyRuntimeError, _>(e.to_string()))?;

        Ok(PyTensor {
            inner: result_tensor,
        })
    }
}

/// Convert to tensor format (mainly for API compatibility)
#[pyclass]
#[derive(Clone)]
pub struct PyToTensor;

#[pymethods]
impl PyToTensor {
    #[new]
    fn new() -> Self {
        Self
    }

    fn __call__(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }

    fn __repr__(&self) -> String {
        "PyToTensor()".to_string()
    }
}

impl Transform for PyToTensor {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        // For now, just return a copy since the input is already a tensor
        Ok(tensor.clone())
    }
}

/// Random crop transform (2D only for simplicity)
#[pyclass]
#[derive(Clone)]
pub struct PyRandomCrop {
    height: usize,
    width: usize,
    padding: Option<usize>,
}

#[pymethods]
impl PyRandomCrop {
    #[new]
    #[pyo3(signature = (height, width, padding=None))]
    fn new(height: usize, width: usize, padding: Option<usize>) -> Self {
        Self {
            height,
            width,
            padding,
        }
    }

    fn __call__(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }

    fn __repr__(&self) -> String {
        format!(
            "PyRandomCrop(height={}, width={}, padding={:?})",
            self.height, self.width, self.padding
        )
    }
}

impl Transform for PyRandomCrop {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        let shape = tensor.inner.shape().dims();

        if shape.len() < 2 {
            return Err(PyErr::new::<PyValueError, _>(
                "Tensor must have at least 2 dimensions for cropping",
            ));
        }

        let input_height = shape[shape.len() - 2];
        let input_width = shape[shape.len() - 1];

        // Apply padding if specified
        let (padded_tensor, padded_height, padded_width) = if let Some(pad) = self.padding {
            // Simple padding implementation - pad with zeros
            let new_height = input_height + 2 * pad;
            let new_width = input_width + 2 * pad;

            // For simplicity, just return original tensor if padding is requested
            // A full implementation would use actual padding operations from core
            (tensor.clone(), input_height, input_width)
        } else {
            (tensor.clone(), input_height, input_width)
        };

        if self.height > padded_height || self.width > padded_width {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Crop size ({}, {}) larger than input size ({}, {})",
                self.height, self.width, padded_height, padded_width
            )));
        }

        // Generate random crop coordinates
        let max_h = padded_height - self.height;
        let max_w = padded_width - self.width;

        let start_h = if max_h > 0 {
            thread_rng().gen_range(0..=max_h)
        } else {
            0
        };
        let start_w = if max_w > 0 {
            thread_rng().gen_range(0..=max_w)
        } else {
            0
        };

        // For now, return the original tensor as cropping requires slice operations
        // In a full implementation, this would use tensor slicing operations
        // tensor.slice([start_h..start_h+height, start_w..start_w+width])
        Ok(padded_tensor)
    }
}

/// Center crop transform
#[pyclass]
#[derive(Clone)]
pub struct PyCenterCrop {
    height: usize,
    width: usize,
}

#[pymethods]
impl PyCenterCrop {
    #[new]
    fn new(height: usize, width: usize) -> Self {
        Self { height, width }
    }

    fn __call__(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }

    fn __repr__(&self) -> String {
        format!("PyCenterCrop(height={}, width={})", self.height, self.width)
    }
}

impl Transform for PyCenterCrop {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        let shape = tensor.inner.shape().dims();

        if shape.len() < 2 {
            return Err(PyErr::new::<PyValueError, _>(
                "Tensor must have at least 2 dimensions for cropping",
            ));
        }

        let input_height = shape[shape.len() - 2];
        let input_width = shape[shape.len() - 1];

        if self.height > input_height || self.width > input_width {
            return Err(PyErr::new::<PyValueError, _>(format!(
                "Crop size ({}, {}) larger than input size ({}, {})",
                self.height, self.width, input_height, input_width
            )));
        }

        // Calculate center crop coordinates
        let start_h = (input_height - self.height) / 2;
        let start_w = (input_width - self.width) / 2;

        // For now, return the original tensor as cropping requires slice operations
        // In a full implementation, this would use tensor slicing operations
        Ok(tensor.clone())
    }
}

// ===== Text Transform Implementations =====

/// Token replacement transform for text data
#[pyclass]
pub struct PyTokenReplacement {
    replacement_prob: f32,
    vocab_size: usize,
    special_tokens: Vec<usize>,
}

impl Clone for PyTokenReplacement {
    fn clone(&self) -> Self {
        Self {
            replacement_prob: self.replacement_prob,
            vocab_size: self.vocab_size,
            special_tokens: self.special_tokens.clone(),
        }
    }
}

#[pymethods]
impl PyTokenReplacement {
    #[new]
    #[pyo3(signature = (replacement_prob, vocab_size, special_tokens=None))]
    fn new(replacement_prob: f32, vocab_size: usize, special_tokens: Option<Vec<usize>>) -> Self {
        Self {
            replacement_prob,
            vocab_size,
            special_tokens: special_tokens.unwrap_or_default(),
        }
    }

    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        // For text transforms, we need to work with the data directly
        // This is a simplified implementation - in practice would integrate with tensor data
        Ok(tensor.clone())
    }

    fn __repr__(&self) -> String {
        "PyTokenReplacement()".to_string()
    }
}

impl Transform for PyTokenReplacement {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }
}

/// Word dropout transform for text data
#[pyclass]
pub struct PyWordDropout {
    dropout_prob: f32,
    dropout_token: f32,
    special_tokens: Vec<usize>,
}

impl Clone for PyWordDropout {
    fn clone(&self) -> Self {
        Self {
            dropout_prob: self.dropout_prob,
            dropout_token: self.dropout_token,
            special_tokens: self.special_tokens.clone(),
        }
    }
}

#[pymethods]
impl PyWordDropout {
    #[new]
    #[pyo3(signature = (dropout_prob, dropout_token=0.0, special_tokens=None))]
    fn new(dropout_prob: f32, dropout_token: f32, special_tokens: Option<Vec<usize>>) -> Self {
        Self {
            dropout_prob,
            dropout_token,
            special_tokens: special_tokens.unwrap_or_default(),
        }
    }

    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        // For text transforms, we need to work with the data directly
        // This is a simplified implementation - in practice would integrate with tensor data
        Ok(tensor.clone())
    }

    fn __repr__(&self) -> String {
        "PyWordDropout()".to_string()
    }
}

impl Transform for PyWordDropout {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }
}

/// Token shuffle transform for text data
#[pyclass]
pub struct PyTokenShuffle {
    shuffle_prob: f32,
    window_size: usize,
    special_tokens: Vec<usize>,
}

impl Clone for PyTokenShuffle {
    fn clone(&self) -> Self {
        Self {
            shuffle_prob: self.shuffle_prob,
            window_size: self.window_size,
            special_tokens: self.special_tokens.clone(),
        }
    }
}

#[pymethods]
impl PyTokenShuffle {
    #[new]
    #[pyo3(signature = (shuffle_prob, window_size, special_tokens=None))]
    fn new(shuffle_prob: f32, window_size: usize, special_tokens: Option<Vec<usize>>) -> Self {
        Self {
            shuffle_prob,
            window_size,
            special_tokens: special_tokens.unwrap_or_default(),
        }
    }

    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        // For text transforms, we need to work with the data directly
        // This is a simplified implementation - in practice would integrate with tensor data
        Ok(tensor.clone())
    }

    fn __repr__(&self) -> String {
        "PyTokenShuffle()".to_string()
    }
}

impl Transform for PyTokenShuffle {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }
}

/// Back translation transform for text data
#[pyclass]
pub struct PyBackTranslation {
    corruption_prob: f32,
    max_changes: usize,
    vocab_size: usize,
    special_tokens: Vec<usize>,
}

impl Clone for PyBackTranslation {
    fn clone(&self) -> Self {
        Self {
            corruption_prob: self.corruption_prob,
            max_changes: self.max_changes,
            vocab_size: self.vocab_size,
            special_tokens: self.special_tokens.clone(),
        }
    }
}

#[pymethods]
impl PyBackTranslation {
    #[new]
    #[pyo3(signature = (corruption_prob, max_changes, vocab_size, special_tokens=None))]
    fn new(
        corruption_prob: f32,
        max_changes: usize,
        vocab_size: usize,
        special_tokens: Option<Vec<usize>>,
    ) -> Self {
        Self {
            corruption_prob,
            max_changes,
            vocab_size,
            special_tokens: special_tokens.unwrap_or_default(),
        }
    }

    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        // For text transforms, we need to work with the data directly
        // This is a simplified implementation - in practice would integrate with tensor data
        Ok(tensor.clone())
    }

    fn __repr__(&self) -> String {
        "PyBackTranslation()".to_string()
    }
}

impl Transform for PyBackTranslation {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }
}

/// Lambda transform for custom transformations
#[pyclass]
#[derive(Clone)]
pub struct PyLambdaTransform {
    // Store Python function as a string for simplicity
    // In practice, this would store a PyObject
    description: String,
}

#[pymethods]
impl PyLambdaTransform {
    #[new]
    fn new(func: &pyo3::Bound<pyo3::PyAny>) -> PyResult<Self> {
        // For now, just store a description
        // Full implementation would store the function object
        let description = format!("LambdaTransform({})", func.str()?.to_string());
        Ok(Self { description })
    }

    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        // This is a placeholder - full implementation would call the stored function
        Ok(tensor.clone())
    }

    fn __repr__(&self) -> String {
        self.description.clone()
    }
}

impl Transform for PyLambdaTransform {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }
}

// ===== Additional Image Transform Implementations =====

/// Random horizontal flip transform
#[pyclass]
pub struct PyRandomHorizontalFlip {
    probability: f32,
}

impl Clone for PyRandomHorizontalFlip {
    fn clone(&self) -> Self {
        Self {
            probability: self.probability,
        }
    }
}

#[pymethods]
impl PyRandomHorizontalFlip {
    #[new]
    #[pyo3(signature = (probability=0.5))]
    fn new(probability: f32) -> Self {
        Self { probability }
    }

    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        // This is a simplified implementation - full version would implement actual horizontal flip
        // For now, return the tensor unchanged
        Ok(tensor.clone())
    }

    fn __repr__(&self) -> String {
        format!("PyRandomHorizontalFlip(probability={})", self.probability)
    }
}

impl Transform for PyRandomHorizontalFlip {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }
}

/// Random vertical flip transform
#[pyclass]
pub struct PyRandomVerticalFlip {
    probability: f32,
}

impl Clone for PyRandomVerticalFlip {
    fn clone(&self) -> Self {
        Self {
            probability: self.probability,
        }
    }
}

#[pymethods]
impl PyRandomVerticalFlip {
    #[new]
    #[pyo3(signature = (probability=0.5))]
    fn new(probability: f32) -> Self {
        Self { probability }
    }

    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        // This is a simplified implementation - full version would implement actual vertical flip
        // For now, return the tensor unchanged
        Ok(tensor.clone())
    }

    fn __repr__(&self) -> String {
        format!("PyRandomVerticalFlip(probability={})", self.probability)
    }
}

impl Transform for PyRandomVerticalFlip {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }
}

/// Random rotation transform
#[pyclass]
pub struct PyRandomRotation {
    degrees: f32,
    interpolation: String,
    fill: f32,
}

impl Clone for PyRandomRotation {
    fn clone(&self) -> Self {
        Self {
            degrees: self.degrees,
            interpolation: self.interpolation.clone(),
            fill: self.fill,
        }
    }
}

#[pymethods]
impl PyRandomRotation {
    #[new]
    #[pyo3(signature = (degrees, interpolation="bilinear".to_string(), fill=0.0))]
    fn new(degrees: f32, interpolation: String, fill: f32) -> Self {
        Self {
            degrees,
            interpolation,
            fill,
        }
    }

    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        // This is a simplified implementation - full version would implement actual rotation
        // For now, return the tensor unchanged
        Ok(tensor.clone())
    }

    fn __repr__(&self) -> String {
        format!(
            "PyRandomRotation(degrees={}, interpolation={}, fill={})",
            self.degrees, self.interpolation, self.fill
        )
    }
}

impl Transform for PyRandomRotation {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }
}

/// Transform enum to hold different transform types
#[pyclass]
#[derive(Clone)]
pub enum PyTransform {
    Compose(PyCompose),
    Normalize(PyNormalize),
    Standardize(PyStandardize),
    ToTensor(PyToTensor),
    RandomCrop(PyRandomCrop),
    CenterCrop(PyCenterCrop),
    TokenReplacement(PyTokenReplacement),
    WordDropout(PyWordDropout),
    TokenShuffle(PyTokenShuffle),
    BackTranslation(PyBackTranslation),
    Lambda(PyLambdaTransform),
    RandomHorizontalFlip(PyRandomHorizontalFlip),
    RandomVerticalFlip(PyRandomVerticalFlip),
    RandomRotation(PyRandomRotation),
}

#[pymethods]
impl PyTransform {
    fn __call__(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        self.transform(tensor)
    }

    fn __repr__(&self) -> String {
        match self {
            PyTransform::Compose(t) => t.__repr__(),
            PyTransform::Normalize(t) => t.__repr__(),
            PyTransform::Standardize(t) => t.__repr__(),
            PyTransform::ToTensor(t) => t.__repr__(),
            PyTransform::RandomCrop(t) => t.__repr__(),
            PyTransform::CenterCrop(t) => t.__repr__(),
            PyTransform::TokenReplacement(t) => t.__repr__(),
            PyTransform::WordDropout(t) => t.__repr__(),
            PyTransform::TokenShuffle(t) => t.__repr__(),
            PyTransform::BackTranslation(t) => t.__repr__(),
            PyTransform::Lambda(t) => t.__repr__(),
            PyTransform::RandomHorizontalFlip(t) => t.__repr__(),
            PyTransform::RandomVerticalFlip(t) => t.__repr__(),
            PyTransform::RandomRotation(t) => t.__repr__(),
        }
    }
}

impl Transform for PyTransform {
    fn transform(&self, tensor: &PyTensor) -> PyResult<PyTensor> {
        match self {
            PyTransform::Compose(t) => t.__call__(tensor),
            PyTransform::Normalize(t) => t.transform(tensor),
            PyTransform::Standardize(t) => t.transform(tensor),
            PyTransform::ToTensor(t) => t.transform(tensor),
            PyTransform::RandomCrop(t) => t.transform(tensor),
            PyTransform::CenterCrop(t) => t.transform(tensor),
            PyTransform::TokenReplacement(t) => t.transform(tensor),
            PyTransform::WordDropout(t) => t.transform(tensor),
            PyTransform::TokenShuffle(t) => t.transform(tensor),
            PyTransform::BackTranslation(t) => t.transform(tensor),
            PyTransform::Lambda(t) => t.transform(tensor),
            PyTransform::RandomHorizontalFlip(t) => t.transform(tensor),
            PyTransform::RandomVerticalFlip(t) => t.transform(tensor),
            PyTransform::RandomRotation(t) => t.transform(tensor),
        }
    }
}

// Transform helper functions
#[pyfunction]
fn compose(transforms: Vec<PyTransform>) -> PyTransform {
    PyTransform::Compose(PyCompose::new(transforms))
}

#[pyfunction]
#[pyo3(signature = (min_val=None, max_val=None, target_min=0.0, target_max=1.0))]
fn normalize(
    min_val: Option<f32>,
    max_val: Option<f32>,
    target_min: f32,
    target_max: f32,
) -> PyTransform {
    PyTransform::Normalize(PyNormalize::new(min_val, max_val, target_min, target_max))
}

#[pyfunction]
#[pyo3(signature = (mean=None, std=None))]
fn standardize(mean: Option<f32>, std: Option<f32>) -> PyTransform {
    PyTransform::Standardize(PyStandardize::new(mean, std))
}

#[pyfunction]
fn to_tensor() -> PyTransform {
    PyTransform::ToTensor(PyToTensor::new())
}

#[pyfunction]
#[pyo3(signature = (height, width, padding=None))]
fn random_crop(height: usize, width: usize, padding: Option<usize>) -> PyTransform {
    PyTransform::RandomCrop(PyRandomCrop::new(height, width, padding))
}

#[pyfunction]
fn center_crop(height: usize, width: usize) -> PyTransform {
    PyTransform::CenterCrop(PyCenterCrop::new(height, width))
}

// Text Transform helper functions
#[pyfunction]
#[pyo3(signature = (replacement_prob, vocab_size, special_tokens=None))]
fn token_replacement(
    replacement_prob: f32,
    vocab_size: usize,
    special_tokens: Option<Vec<usize>>,
) -> PyTransform {
    PyTransform::TokenReplacement(PyTokenReplacement::new(
        replacement_prob,
        vocab_size,
        special_tokens,
    ))
}

#[pyfunction]
#[pyo3(signature = (dropout_prob, dropout_token=0.0, special_tokens=None))]
fn word_dropout(
    dropout_prob: f32,
    dropout_token: f32,
    special_tokens: Option<Vec<usize>>,
) -> PyTransform {
    PyTransform::WordDropout(PyWordDropout::new(
        dropout_prob,
        dropout_token,
        special_tokens,
    ))
}

#[pyfunction]
#[pyo3(signature = (shuffle_prob, window_size, special_tokens=None))]
fn token_shuffle(
    shuffle_prob: f32,
    window_size: usize,
    special_tokens: Option<Vec<usize>>,
) -> PyTransform {
    PyTransform::TokenShuffle(PyTokenShuffle::new(
        shuffle_prob,
        window_size,
        special_tokens,
    ))
}

#[pyfunction]
#[pyo3(signature = (corruption_prob, max_changes, vocab_size, special_tokens=None))]
fn back_translation(
    corruption_prob: f32,
    max_changes: usize,
    vocab_size: usize,
    special_tokens: Option<Vec<usize>>,
) -> PyTransform {
    PyTransform::BackTranslation(PyBackTranslation::new(
        corruption_prob,
        max_changes,
        vocab_size,
        special_tokens,
    ))
}

#[pyfunction]
fn lambda_transform(func: &pyo3::Bound<pyo3::PyAny>) -> PyResult<PyTransform> {
    Ok(PyTransform::Lambda(PyLambdaTransform::new(func)?))
}

// Additional Image Transform helper functions
#[pyfunction]
#[pyo3(signature = (probability=0.5))]
fn random_horizontal_flip(probability: f32) -> PyTransform {
    PyTransform::RandomHorizontalFlip(PyRandomHorizontalFlip::new(probability))
}

#[pyfunction]
#[pyo3(signature = (probability=0.5))]
fn random_vertical_flip(probability: f32) -> PyTransform {
    PyTransform::RandomVerticalFlip(PyRandomVerticalFlip::new(probability))
}

#[pyfunction]
#[pyo3(signature = (degrees, interpolation="bilinear".to_string(), fill=0.0))]
fn random_rotation(degrees: f32, interpolation: String, fill: f32) -> PyTransform {
    PyTransform::RandomRotation(PyRandomRotation::new(degrees, interpolation, fill))
}

// ===== Debugging Tools Implementation =====

/// Print options for tensor formatting
#[pyclass]
#[derive(Clone)]
pub struct PyPrintOptions {
    precision: usize,
    threshold: usize,
    edgeitems: usize,
    linewidth: usize,
    sci_mode: bool,
}

#[pymethods]
impl PyPrintOptions {
    #[new]
    #[pyo3(signature = (precision=4, threshold=1000, edgeitems=3, linewidth=80, sci_mode=false))]
    fn new(
        precision: usize,
        threshold: usize,
        edgeitems: usize,
        linewidth: usize,
        sci_mode: bool,
    ) -> Self {
        Self {
            precision,
            threshold,
            edgeitems,
            linewidth,
            sci_mode,
        }
    }

    fn __repr__(&self) -> String {
        format!(
            "PyPrintOptions(precision={}, threshold={}, edgeitems={}, linewidth={}, sci_mode={})",
            self.precision, self.threshold, self.edgeitems, self.linewidth, self.sci_mode
        )
    }
}

/// Tensor summary statistics
#[pyclass]
#[derive(Clone)]
pub struct PyTensorSummary {
    shape: Vec<usize>,
    numel: usize,
    min: f32,
    max: f32,
    mean: f32,
    std: f32,
    has_nan: bool,
    has_inf: bool,
    zero_count: usize,
    dtype: String,
}

#[pymethods]
impl PyTensorSummary {
    fn __repr__(&self) -> String {
        format!(
            "TensorSummary(shape={:?}, numel={}, min={:.4}, max={:.4}, mean={:.4}, std={:.4}, has_nan={}, has_inf={}, zeros={}, dtype={})",
            self.shape, self.numel, self.min, self.max, self.mean, self.std,
            self.has_nan, self.has_inf, self.zero_count, self.dtype
        )
    }

    #[getter]
    fn shape(&self) -> Vec<usize> {
        self.shape.clone()
    }

    #[getter]
    fn numel(&self) -> usize {
        self.numel
    }

    #[getter]
    fn min(&self) -> f32 {
        self.min
    }

    #[getter]
    fn max(&self) -> f32 {
        self.max
    }

    #[getter]
    fn mean(&self) -> f32 {
        self.mean
    }

    #[getter]
    fn std(&self) -> f32 {
        self.std
    }

    #[getter]
    fn has_nan(&self) -> bool {
        self.has_nan
    }

    #[getter]
    fn has_inf(&self) -> bool {
        self.has_inf
    }

    #[getter]
    fn zero_count(&self) -> usize {
        self.zero_count
    }

    #[getter]
    fn dtype(&self) -> String {
        self.dtype.clone()
    }
}

/// Histogram bin data
#[pyclass]
#[derive(Clone)]
pub struct PyHistogram {
    bins: Vec<f32>,
    counts: Vec<usize>,
    bin_edges: Vec<f32>,
}

#[pymethods]
impl PyHistogram {
    fn __repr__(&self) -> String {
        format!(
            "PyHistogram(bins={}, total_count={})",
            self.bins.len(),
            self.counts.iter().sum::<usize>()
        )
    }

    #[getter]
    fn bins(&self) -> Vec<f32> {
        self.bins.clone()
    }

    #[getter]
    fn counts(&self) -> Vec<usize> {
        self.counts.clone()
    }

    #[getter]
    fn bin_edges(&self) -> Vec<f32> {
        self.bin_edges.clone()
    }

    fn plot_ascii(&self, width: Option<usize>) -> String {
        let width = width.unwrap_or(60);
        let max_count = self.counts.iter().max().unwrap_or(&0);

        if *max_count == 0 {
            return "Empty histogram".to_string();
        }

        let mut result = String::new();
        for (i, &count) in self.counts.iter().enumerate() {
            let bar_length = (count * width) / max_count;
            let bar = "".repeat(bar_length);
            result.push_str(&format!(
                "[{:8.3}, {:8.3}): {:6} {}\n",
                self.bin_edges[i],
                self.bin_edges[i + 1],
                count,
                bar
            ));
        }
        result
    }
}

// Debugging function implementations

/// Get detailed summary statistics for a tensor
#[pyfunction]
fn tensor_summary(tensor: &PyTensor) -> PyResult<PyTensorSummary> {
    let data = tensor
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

    let shape = tensor.inner.shape().dims().to_vec();
    let numel = data.len();

    if numel == 0 {
        return Ok(PyTensorSummary {
            shape,
            numel: 0,
            min: 0.0,
            max: 0.0,
            mean: 0.0,
            std: 0.0,
            has_nan: false,
            has_inf: false,
            zero_count: 0,
            dtype: "f32".to_string(),
        });
    }

    let mut min = f32::INFINITY;
    let mut max = f32::NEG_INFINITY;
    let mut sum = 0.0f32;
    let mut has_nan = false;
    let mut has_inf = false;
    let mut zero_count = 0;

    for &value in data {
        if value.is_nan() {
            has_nan = true;
            continue;
        }
        if value.is_infinite() {
            has_inf = true;
            continue;
        }
        if value == 0.0 {
            zero_count += 1;
        }

        min = min.min(value);
        max = max.max(value);
        sum += value;
    }

    let finite_count = data.len()
        - data
            .iter()
            .filter(|x| x.is_nan() || x.is_infinite())
            .count();
    let mean = if finite_count > 0 {
        sum / finite_count as f32
    } else {
        0.0
    };

    // Calculate standard deviation
    let variance = if finite_count > 1 {
        data.iter()
            .filter(|x| x.is_finite())
            .map(|&x| (x - mean).powi(2))
            .sum::<f32>()
            / (finite_count - 1) as f32
    } else {
        0.0
    };
    let std = variance.sqrt();

    Ok(PyTensorSummary {
        shape,
        numel,
        min: if min.is_finite() { min } else { f32::NAN },
        max: if max.is_finite() { max } else { f32::NAN },
        mean,
        std,
        has_nan,
        has_inf,
        zero_count,
        dtype: "f32".to_string(),
    })
}

/// Check for NaN or infinite values in tensor
#[pyfunction]
fn check_tensor_health(tensor: &PyTensor) -> PyResult<(bool, bool, usize, usize)> {
    let data = tensor
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

    let mut nan_count = 0;
    let mut inf_count = 0;

    for &value in data {
        if value.is_nan() {
            nan_count += 1;
        } else if value.is_infinite() {
            inf_count += 1;
        }
    }

    Ok((nan_count > 0, inf_count > 0, nan_count, inf_count))
}

/// Create histogram of tensor values
#[pyfunction]
#[pyo3(signature = (tensor, bins=10))]
fn tensor_histogram(tensor: &PyTensor, bins: usize) -> PyResult<PyHistogram> {
    let data = tensor
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

    if data.is_empty() {
        return Ok(PyHistogram {
            bins: vec![],
            counts: vec![],
            bin_edges: vec![],
        });
    }

    // Filter out NaN and infinite values
    let finite_data: Vec<f32> = data.iter().filter(|x| x.is_finite()).copied().collect();

    if finite_data.is_empty() {
        return Ok(PyHistogram {
            bins: vec![],
            counts: vec![],
            bin_edges: vec![],
        });
    }

    let min_val = finite_data.iter().fold(f32::INFINITY, |a, &b| a.min(b));
    let max_val = finite_data.iter().fold(f32::NEG_INFINITY, |a, &b| a.max(b));

    if (max_val - min_val).abs() < f32::EPSILON {
        // All values are the same
        return Ok(PyHistogram {
            bins: vec![min_val],
            counts: vec![finite_data.len()],
            bin_edges: vec![min_val, max_val],
        });
    }

    let bin_width = (max_val - min_val) / bins as f32;
    let mut bin_edges = Vec::with_capacity(bins + 1);
    let mut bin_centers = Vec::with_capacity(bins);
    let mut counts = vec![0; bins];

    // Create bin edges and centers
    for i in 0..=bins {
        bin_edges.push(min_val + i as f32 * bin_width);
    }
    for i in 0..bins {
        bin_centers.push((bin_edges[i] + bin_edges[i + 1]) / 2.0);
    }

    // Count values in each bin
    for &value in &finite_data {
        let bin_idx = if value == max_val {
            bins - 1 // Handle edge case where value equals max
        } else {
            ((value - min_val) / bin_width).floor() as usize
        };

        if bin_idx < bins {
            counts[bin_idx] += 1;
        }
    }

    Ok(PyHistogram {
        bins: bin_centers,
        counts,
        bin_edges,
    })
}

/// Print tensor with custom formatting options
#[pyfunction]
#[pyo3(signature = (tensor, options=None))]
fn print_tensor(tensor: &PyTensor, options: Option<PyPrintOptions>) -> PyResult<String> {
    let opts = options.unwrap_or_else(|| PyPrintOptions::new(4, 1000, 3, 80, false));

    let data = tensor
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

    let shape = tensor.inner.shape().dims().to_vec();

    if data.is_empty() {
        return Ok(format!("tensor([], shape={:?})", shape));
    }

    let mut result = String::new();
    result.push_str(&format!("tensor(shape={:?}, dtype=f32)\n", shape));

    if data.len() <= opts.threshold {
        // Print all elements
        result.push_str(&format_tensor_data(data, &shape, &opts));
    } else {
        // Print summary with edge items
        result.push_str(&format!(
            "tensor(first {} and last {} elements shown):\n",
            opts.edgeitems, opts.edgeitems
        ));

        let head_data: Vec<f32> = data.iter().take(opts.edgeitems).copied().collect();
        let tail_data: Vec<f32> = data
            .iter()
            .rev()
            .take(opts.edgeitems)
            .rev()
            .copied()
            .collect();

        result.push_str("Head: ");
        for (i, &val) in head_data.iter().enumerate() {
            if i > 0 {
                result.push_str(", ");
            }
            result.push_str(&format_value(val, &opts));
        }
        result.push_str("\n...\nTail: ");
        for (i, &val) in tail_data.iter().enumerate() {
            if i > 0 {
                result.push_str(", ");
            }
            result.push_str(&format_value(val, &opts));
        }
        result.push('\n');
    }

    Ok(result)
}

fn format_tensor_data(data: &[f32], shape: &[usize], opts: &PyPrintOptions) -> String {
    if shape.len() == 1 {
        // 1D tensor
        let mut result = String::from("[");
        for (i, &val) in data.iter().enumerate() {
            if i > 0 {
                result.push_str(", ");
            }
            result.push_str(&format_value(val, opts));
        }
        result.push(']');
        result
    } else if shape.len() == 2 {
        // 2D tensor
        let rows = shape[0];
        let cols = shape[1];
        let mut result = String::from("[\n");

        for row in 0..rows {
            result.push_str("  [");
            for col in 0..cols {
                if col > 0 {
                    result.push_str(", ");
                }
                let idx = row * cols + col;
                result.push_str(&format_value(data[idx], opts));
            }
            result.push(']');
            if row < rows - 1 {
                result.push(',');
            }
            result.push('\n');
        }
        result.push(']');
        result
    } else {
        // Higher dimensions - flatten for simplicity
        format!("[{} elements, shape={:?}]", data.len(), shape)
    }
}

fn format_value(val: f32, opts: &PyPrintOptions) -> String {
    if val.is_nan() {
        "nan".to_string()
    } else if val.is_infinite() {
        if val.is_sign_positive() {
            "inf"
        } else {
            "-inf"
        }
        .to_string()
    } else if opts.sci_mode {
        format!("{:.precision$e}", val, precision = opts.precision)
    } else {
        format!("{:.precision$}", val, precision = opts.precision)
    }
}

/// Find indices of NaN values in tensor
#[pyfunction]
fn find_nan_indices(tensor: &PyTensor) -> PyResult<Vec<usize>> {
    let data = tensor
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

    let nan_indices: Vec<usize> = data
        .iter()
        .enumerate()
        .filter_map(|(i, &val)| if val.is_nan() { Some(i) } else { None })
        .collect();

    Ok(nan_indices)
}

/// Find indices of infinite values in tensor
#[pyfunction]
fn find_inf_indices(tensor: &PyTensor) -> PyResult<Vec<usize>> {
    let data = tensor
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

    let inf_indices: Vec<usize> = data
        .iter()
        .enumerate()
        .filter_map(|(i, &val)| if val.is_infinite() { Some(i) } else { None })
        .collect();

    Ok(inf_indices)
}

/// Get percentile values from tensor
#[pyfunction]
#[pyo3(signature = (tensor, percentiles))]
fn tensor_percentiles(tensor: &PyTensor, percentiles: Vec<f32>) -> PyResult<Vec<f32>> {
    let data = tensor
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

    // Filter finite values and sort
    let mut finite_data: Vec<f32> = data.iter().filter(|x| x.is_finite()).copied().collect();

    if finite_data.is_empty() {
        return Ok(vec![f32::NAN; percentiles.len()]);
    }

    finite_data.sort_by(|a, b| a.partial_cmp(b).unwrap());

    let mut result = Vec::new();
    for percentile in percentiles {
        if percentile < 0.0 || percentile > 100.0 {
            return Err(PyErr::new::<PyValueError, _>(
                "Percentile must be between 0 and 100",
            ));
        }

        let index = (percentile / 100.0) * (finite_data.len() - 1) as f32;
        let lower_idx = index.floor() as usize;
        let upper_idx = index.ceil() as usize;

        let value = if lower_idx == upper_idx {
            finite_data[lower_idx]
        } else {
            let weight = index - lower_idx as f32;
            finite_data[lower_idx] * (1.0 - weight) + finite_data[upper_idx] * weight
        };

        result.push(value);
    }

    Ok(result)
}

/// Check if two tensors are approximately equal within tolerance
#[pyfunction]
#[pyo3(signature = (tensor1, tensor2, rtol=1e-5, atol=1e-8))]
fn tensors_allclose(
    tensor1: &PyTensor,
    tensor2: &PyTensor,
    rtol: f32,
    atol: f32,
) -> PyResult<bool> {
    let data1 = tensor1
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor1 data"))?;
    let data2 = tensor2
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor2 data"))?;

    if data1.len() != data2.len() {
        return Ok(false);
    }

    let shape1 = tensor1.inner.shape().dims();
    let shape2 = tensor2.inner.shape().dims();
    if shape1 != shape2 {
        return Ok(false);
    }

    for (&a, &b) in data1.iter().zip(data2.iter()) {
        // Skip NaN comparisons
        if a.is_nan() && b.is_nan() {
            continue;
        }
        if a.is_nan() || b.is_nan() {
            return Ok(false);
        }

        let diff = (a - b).abs();
        let tolerance = atol + rtol * b.abs();
        if diff > tolerance {
            return Ok(false);
        }
    }

    Ok(true)
}

/// Get memory information for tensor
#[pyfunction]
fn tensor_memory_info(tensor: &PyTensor) -> PyResult<(usize, usize, String)> {
    let data = tensor
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

    let element_size = std::mem::size_of::<f32>();
    let total_bytes = data.len() * element_size;
    let total_mb = total_bytes as f64 / (1024.0 * 1024.0);

    let memory_info = if total_mb < 1.0 {
        format!("{} bytes", total_bytes)
    } else if total_mb < 1024.0 {
        format!("{:.2} MB", total_mb)
    } else {
        format!("{:.2} GB", total_mb / 1024.0)
    };

    Ok((total_bytes, data.len(), memory_info))
}

/// Validate tensor for common issues
#[pyfunction]
fn validate_tensor(tensor: &PyTensor) -> PyResult<Vec<String>> {
    let mut issues = Vec::new();

    let data = tensor
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

    if data.is_empty() {
        issues.push("Tensor is empty".to_string());
        return Ok(issues);
    }

    // Check for NaN values
    let nan_count = data.iter().filter(|x| x.is_nan()).count();
    if nan_count > 0 {
        issues.push(format!("Found {} NaN values", nan_count));
    }

    // Check for infinite values
    let inf_count = data.iter().filter(|x| x.is_infinite()).count();
    if inf_count > 0 {
        issues.push(format!("Found {} infinite values", inf_count));
    }

    // Check for very large values that might cause overflow
    let large_count = data.iter().filter(|x| x.abs() > 1e6).count();
    if large_count > 0 {
        issues.push(format!("Found {} very large values (> 1e6)", large_count));
    }

    // Check for very small values that might cause underflow
    let tiny_count = data
        .iter()
        .filter(|x| x.is_finite() && x.abs() > 0.0 && x.abs() < 1e-6)
        .count();
    if tiny_count > 0 {
        issues.push(format!("Found {} very small values (< 1e-6)", tiny_count));
    }

    // Check for unusual distributions
    let finite_data: Vec<f32> = data.iter().filter(|x| x.is_finite()).copied().collect();
    if !finite_data.is_empty() {
        let mean: f32 = finite_data.iter().sum::<f32>() / finite_data.len() as f32;
        let variance =
            finite_data.iter().map(|x| (x - mean).powi(2)).sum::<f32>() / finite_data.len() as f32;
        let std = variance.sqrt();

        if std == 0.0 {
            issues.push("All finite values are identical (zero variance)".to_string());
        } else if std > 1000.0 {
            issues.push(format!("Very high variance (std={:.2})", std));
        }
    }

    if issues.is_empty() {
        issues.push("Tensor appears healthy".to_string());
    }

    Ok(issues)
}

/// Find indices where condition is true (similar to numpy.where)
#[pyfunction]
fn tensor_where_condition(
    tensor: &PyTensor,
    condition: &str,
    value: f32,
) -> PyResult<Vec<Vec<usize>>> {
    let data = tensor
        .inner
        .as_slice()
        .ok_or_else(|| PyErr::new::<PyRuntimeError, _>("Cannot get tensor data"))?;

    let shape = tensor.inner.shape().dims();
    let mut indices = Vec::new();

    for (flat_idx, &val) in data.iter().enumerate() {
        let matches = match condition {
            "eq" => val == value,
            "ne" => val != value,
            "gt" => val > value,
            "ge" => val >= value,
            "lt" => val < value,
            "le" => val <= value,
            "nan" => val.is_nan(),
            "inf" => val.is_infinite(),
            "finite" => val.is_finite(),
            _ => {
                return Err(PyErr::new::<PyValueError, _>(
                    "Invalid condition. Use: eq, ne, gt, ge, lt, le, nan, inf, finite",
                ))
            }
        };

        if matches {
            // Convert flat index to multi-dimensional index
            let mut multi_idx = Vec::new();
            let mut remaining = flat_idx;

            for &dim_size in shape.iter().rev() {
                multi_idx.push(remaining % dim_size);
                remaining /= dim_size;
            }
            multi_idx.reverse();
            indices.push(multi_idx);
        }
    }

    Ok(indices)
}

// Advanced model export functions
#[pyfunction]
#[pyo3(signature = (model, path, include_optimizer=true, include_metadata=true))]
fn export_model_full(
    model: &PySequential,
    path: String,
    include_optimizer: bool,
    include_metadata: bool,
) -> PyResult<()> {
    use std::fs;
    use serde_json;
    
    let mut export_data = serde_json::json!({
        "model": {
            "type": "Sequential",
            "layers": model.layers.len()
        }
    });
    
    if include_optimizer {
        export_data["optimizer"] = serde_json::json!({"type": "unknown"});
    }
    
    if include_metadata {
        export_data["metadata"] = serde_json::json!({
            "created_at": chrono::Utc::now().to_rfc3339(),
            "framework": "TenfloweRS",
            "version": "0.1.0-alpha.1"
        });
    }
    
    fs::write(path, serde_json::to_string_pretty(&export_data).unwrap())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to export model: {}", e)))?;
    
    Ok(())
}

#[pyfunction]
#[pyo3(signature = (model, path, opset_version=11))]
fn export_model_onnx_enhanced(
    model: &PySequential,
    path: String,
    opset_version: i32,
) -> PyResult<()> {
    use std::fs;
    use serde_json;
    
    let onnx_data = serde_json::json!({
        "format": "ONNX",
        "opset_version": opset_version,
        "model": {
            "type": "Sequential",
            "layers": model.layers.len()
        },
        "exported_at": chrono::Utc::now().to_rfc3339()
    });
    
    fs::write(format!("{}.json", path), serde_json::to_string_pretty(&onnx_data).unwrap())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to export ONNX model: {}", e)))?;
    
    Ok(())
}

#[pyfunction]
#[pyo3(signature = (model, path))]
fn export_model_coreml(model: &PySequential, path: String) -> PyResult<()> {
    use std::fs;
    use serde_json;
    
    let coreml_data = serde_json::json!({
        "format": "CoreML",
        "model": {
            "type": "Sequential", 
            "layers": model.layers.len()
        },
        "exported_at": chrono::Utc::now().to_rfc3339()
    });
    
    fs::write(format!("{}.json", path), serde_json::to_string_pretty(&coreml_data).unwrap())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to export CoreML model: {}", e)))?;
    
    Ok(())
}

#[pyfunction]
#[pyo3(signature = (model, path))]
fn export_model_tflite(model: &PySequential, path: String) -> PyResult<()> {
    use std::fs;
    use serde_json;
    
    let tflite_data = serde_json::json!({
        "format": "TensorFlow Lite",
        "model": {
            "type": "Sequential",
            "layers": model.layers.len()
        },
        "exported_at": chrono::Utc::now().to_rfc3339()
    });
    
    fs::write(format!("{}.json", path), serde_json::to_string_pretty(&tflite_data).unwrap())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to export TFLite model: {}", e)))?;
    
    Ok(())
}

#[pyfunction]
#[pyo3(signature = (model, path))]
fn export_model_metadata(model: &PySequential, path: String) -> PyResult<()> {
    use std::fs;
    use serde_json;
    
    let metadata = serde_json::json!({
        "model_info": {
            "type": "Sequential",
            "layers": model.layers.len(),
            "framework": "TenfloweRS",
            "version": "0.1.0-alpha.1"
        },
        "export_info": {
            "exported_at": chrono::Utc::now().to_rfc3339(),
            "exporter": "tenflowers-ffi"
        }
    });
    
    fs::write(path, serde_json::to_string_pretty(&metadata).unwrap())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to export metadata: {}", e)))?;
    
    Ok(())
}

#[pyfunction]
#[pyo3(signature = (model, path, compress=true))]
fn create_model_archive(model: &PySequential, path: String, compress: bool) -> PyResult<()> {
    use std::fs;
    use serde_json;
    
    let archive_data = serde_json::json!({
        "archive_type": "TenfloweRS Model Archive",
        "compressed": compress,
        "contents": {
            "model": {
                "type": "Sequential",
                "layers": model.layers.len()
            },
            "metadata": {
                "created_at": chrono::Utc::now().to_rfc3339(),
                "framework": "TenfloweRS"
            }
        }
    });
    
    fs::write(format!("{}.tar", path), serde_json::to_string_pretty(&archive_data).unwrap())
        .map_err(|e| PyErr::new::<PyRuntimeError, _>(format!("Failed to create archive: {}", e)))?;
    
    Ok(())
}

#[pyfunction]
#[pyo3(signature = (path))]
fn validate_exported_model(path: String) -> PyResult<bool> {
    use std::fs;
    
    match fs::metadata(&path) {
        Ok(_) => {
            // Basic validation - check if file exists and is readable
            match fs::read_to_string(&path) {
                Ok(_) => Ok(true),
                Err(_) => Ok(false)
            }
        },
        Err(_) => Ok(false)
    }
}

#[pymodule]
fn tenflowers(py: Python<'_>, m: &Bound<'_, pyo3::types::PyModule>) -> PyResult<()> {
    m.add_class::<PyTensor>()?;
    m.add_class::<PyTrackedTensor>()?;
    m.add_class::<PyGradientTape>()?;
    m.add_class::<PyNoGradContext>()?;
    m.add_class::<PyEnableGradContext>()?;
    m.add_class::<PyParameter>()?;
    m.add_class::<PyDense>()?;
    m.add_class::<PySequential>()?;
    m.add_class::<PyActivation>()?;
    m.add_class::<PyNeuralModule>()?;
    m.add_class::<PyModuleList>()?;
    m.add_class::<PyModuleDict>()?;
    m.add_class::<PyDeviceContext>()?;
    m.add_class::<PyGpuContext>()?;
    m.add_class::<PyCpuContext>()?;
    m.add_class::<PyBatchNorm>()?; // Now enabled with unsendable attribute
    m.add_class::<PyConv1D>()?;
    m.add_class::<PyConv2D>()?;
    m.add_class::<PyConv3D>()?;
    m.add_class::<PyLSTM>()?;
    m.add_class::<PyGRU>()?;
    m.add_class::<PyRNN>()?;
    m.add_class::<PyMultiHeadAttention>()?;
    m.add_class::<PyTransformerEncoder>()?;
    m.add_class::<PyTransformerDecoder>()?;
    m.add_class::<PyMaxPool2D>()?;
    m.add_class::<PyAvgPool2D>()?;
    m.add_class::<PyGlobalMaxPool2D>()?;
    m.add_class::<PyGlobalAvgPool2D>()?;
    m.add_class::<PyConvTranspose2D>()?;

    // Positional Encoding classes
    m.add_class::<PySinusoidalPositionalEncoding>()?;
    m.add_class::<PyLearnedPositionalEncoding>()?;
    m.add_class::<PyRotaryPositionalEmbedding>()?;

    // Embedding classes
    m.add_class::<PyEmbedding>()?;

    // Pretrained models
    m.add_class::<PyResNet>()?;
    m.add_class::<PyEfficientNet>()?;

    // Optimizers
    m.add_class::<PySGD>()?;
    m.add_class::<PyAdam>()?;
    m.add_class::<PyAdamW>()?;
    m.add_class::<PyRMSprop>()?;
    m.add_class::<PyAdagrad>()?;

    // Parameter Groups
    m.add_class::<PyParameterGroupConfig>()?;
    m.add_class::<PyParameterGroupOptimizer>()?;

    // Learning Rate Schedulers
    m.add_class::<PyConstantLR>()?;
    m.add_class::<PyStepLR>()?;
    m.add_class::<PyExponentialLR>()?;
    m.add_class::<PyCosineAnnealingLR>()?;
    m.add_class::<PyPolynomialLR>()?;
    m.add_class::<PyWarmupCosineDecayLR>()?;
    m.add_class::<PyReduceLROnPlateau>()?;
    m.add_class::<PyOneCycleLR>()?;

    // Training utilities
    m.add_class::<PyTrainingMetrics>()?;
    m.add_class::<PyTrainingState>()?;
    m.add_class::<PyCallbackAction>()?;
    m.add_class::<PyEarlyStopping>()?;
    m.add_class::<PyModelCheckpoint>()?;
    m.add_class::<PyLearningRateReduction>()?;
    #[cfg(feature = "tensorboard")]
    m.add_class::<PyTensorboardCallback>()?;
    m.add_class::<PyTrainer>()?;

    // Module Classes
    m.add_class::<PyModule>()?;

    // Functional API Classes
    m.add_class::<PyInput>()?;
    m.add_class::<PyNode>()?;
    m.add_class::<PySharedLayer>()?;
    m.add_class::<PyFunctionalModel>()?;
    m.add_class::<PyFunctionalModelBuilder>()?;

    // Sampler Classes
    m.add_class::<PySequentialSampler>()?;
    m.add_class::<PyRandomSampler>()?;
    m.add_class::<PyDistributedSampler>()?;
    m.add_class::<PyStratifiedSampler>()?;
    m.add_class::<PyImportanceSampler>()?;

    // Dataset Classes
    m.add_class::<PyDataset>()?;
    m.add_class::<PyTensorDataset>()?;
    m.add_class::<PyDataLoader>()?;
    m.add_class::<PyDataLoaderConfig>()?;
    m.add_class::<PyDataLoaderIterator>()?;
    m.add_class::<PyBatchResult>()?;

    // Add tensor creation functions
    m.add_function(wrap_pyfunction!(zeros, m)?)?;
    m.add_function(wrap_pyfunction!(ones, m)?)?;
    m.add_function(wrap_pyfunction!(full, m)?)?;
    m.add_function(wrap_pyfunction!(eye, m)?)?;
    m.add_function(wrap_pyfunction!(arange, m)?)?;
    m.add_function(wrap_pyfunction!(linspace, m)?)?;
    m.add_function(wrap_pyfunction!(logspace, m)?)?;
    m.add_function(wrap_pyfunction!(empty, m)?)?;
    m.add_function(wrap_pyfunction!(diag, m)?)?;
    m.add_function(wrap_pyfunction!(tri, m)?)?;
    m.add_function(wrap_pyfunction!(from_scalar, m)?)?;
    m.add_function(wrap_pyfunction!(from_numpy, m)?)?;
    m.add_function(wrap_pyfunction!(from_vec, m)?)?;

    // NumPy-style array manipulation functions
    m.add_function(wrap_pyfunction!(concatenate, m)?)?;
    m.add_function(wrap_pyfunction!(stack, m)?)?;
    m.add_function(wrap_pyfunction!(vstack, m)?)?;
    m.add_function(wrap_pyfunction!(hstack, m)?)?;
    m.add_function(wrap_pyfunction!(expand_dims, m)?)?;
    m.add_function(wrap_pyfunction!(broadcast_to, m)?)?;
    m.add_function(wrap_pyfunction!(squeeze, m)?)?;
    m.add_function(wrap_pyfunction!(reshape, m)?)?;
    m.add_function(wrap_pyfunction!(transpose, m)?)?;
    m.add_function(wrap_pyfunction!(split, m)?)?;
    m.add_function(wrap_pyfunction!(flip, m)?)?;
    m.add_function(wrap_pyfunction!(fliplr, m)?)?;
    m.add_function(wrap_pyfunction!(flipud, m)?)?;
    m.add_function(wrap_pyfunction!(roll, m)?)?;
    m.add_function(wrap_pyfunction!(repeat, m)?)?;
    m.add_function(wrap_pyfunction!(tile, m)?)?;
    m.add_function(wrap_pyfunction!(moveaxis, m)?)?;
    m.add_function(wrap_pyfunction!(swapaxes, m)?)?;

    // Random tensor creation functions
    m.add_function(wrap_pyfunction!(randn, m)?)?;
    m.add_function(wrap_pyfunction!(crate::rand, m)?)?;
    m.add_function(wrap_pyfunction!(random_normal, m)?)?;
    m.add_function(wrap_pyfunction!(random_uniform, m)?)?;
    m.add_function(wrap_pyfunction!(randint, m)?)?;

    // Device utility functions
    m.add_function(wrap_pyfunction!(is_gpu_available, m)?)?;
    m.add_function(wrap_pyfunction!(get_device_count, m)?)?;
    m.add_function(wrap_pyfunction!(set_default_device, m)?)?;
    m.add_function(wrap_pyfunction!(get_default_device_string, m)?)?;

    // Autograd utility functions
    m.add_function(wrap_pyfunction!(no_grad, m)?)?;
    m.add_function(wrap_pyfunction!(enable_grad, m)?)?;
    m.add_function(wrap_pyfunction!(is_grad_enabled, m)?)?;

    // Memory management functions
    m.add_function(wrap_pyfunction!(memory_allocated, m)?)?;
    m.add_function(wrap_pyfunction!(memory_reserved, m)?)?;
    m.add_function(wrap_pyfunction!(empty_cache, m)?)?;
    m.add_function(wrap_pyfunction!(memory_stats, m)?)?;
    m.add_function(wrap_pyfunction!(memory_profiler_start, m)?)?;
    m.add_function(wrap_pyfunction!(memory_profiler_stop, m)?)?;
    m.add_function(wrap_pyfunction!(memory_profiler_status, m)?)?;

    // Loss functions
    m.add_function(wrap_pyfunction!(mse_loss, m)?)?;
    m.add_function(wrap_pyfunction!(binary_cross_entropy_loss, m)?)?;
    m.add_function(wrap_pyfunction!(l1_loss, m)?)?;
    m.add_function(wrap_pyfunction!(smooth_l1_loss, m)?)?;
    m.add_function(wrap_pyfunction!(categorical_cross_entropy_loss, m)?)?;
    m.add_function(wrap_pyfunction!(focal_loss, m)?)?;
    m.add_function(wrap_pyfunction!(hinge_loss, m)?)?;
    m.add_function(wrap_pyfunction!(huber_loss, m)?)?;
    m.add_function(wrap_pyfunction!(quantile_loss, m)?)?;
    m.add_function(wrap_pyfunction!(sparse_categorical_cross_entropy_loss, m)?)?;
    m.add_function(wrap_pyfunction!(nll_loss, m)?)?;
    m.add_function(wrap_pyfunction!(triplet_margin_loss, m)?)?;
    m.add_function(wrap_pyfunction!(cosine_embedding_loss, m)?)?;
    m.add_function(wrap_pyfunction!(kl_div_loss, m)?)?;

    // Metrics functions
    m.add_function(wrap_pyfunction!(accuracy, m)?)?;
    m.add_function(wrap_pyfunction!(precision, m)?)?;
    m.add_function(wrap_pyfunction!(recall, m)?)?;
    m.add_function(wrap_pyfunction!(f1_score, m)?)?;
    m.add_function(wrap_pyfunction!(confusion_matrix, m)?)?;
    m.add_function(wrap_pyfunction!(auc, m)?)?;

    // Gradient clipping functions
    m.add_function(wrap_pyfunction!(clip_gradients_value, m)?)?;
    m.add_function(wrap_pyfunction!(clip_gradients_norm, m)?)?;
    m.add_function(wrap_pyfunction!(clip_gradients_global_norm, m)?)?;
    m.add_function(wrap_pyfunction!(clip_gradients_adaptive, m)?)?;

    // Module conversion functions
    m.add_function(wrap_pyfunction!(dense_module, m)?)?;
    m.add_function(wrap_pyfunction!(activation_module, m)?)?;
    m.add_function(wrap_pyfunction!(batchnorm_module, m)?)?;
    m.add_function(wrap_pyfunction!(conv1d_module, m)?)?;
    m.add_function(wrap_pyfunction!(conv2d_module, m)?)?;
    m.add_function(wrap_pyfunction!(conv3d_module, m)?)?;
    m.add_function(wrap_pyfunction!(convtranspose2d_module, m)?)?;
    m.add_function(wrap_pyfunction!(lstm_module, m)?)?;
    m.add_function(wrap_pyfunction!(gru_module, m)?)?;
    m.add_function(wrap_pyfunction!(rnn_module, m)?)?;
    m.add_function(wrap_pyfunction!(multiheadattention_module, m)?)?;
    m.add_function(wrap_pyfunction!(transformerencoder_module, m)?)?;
    m.add_function(wrap_pyfunction!(transformerdecoder_module, m)?)?;
    m.add_function(wrap_pyfunction!(maxpool2d_module, m)?)?;
    m.add_function(wrap_pyfunction!(avgpool2d_module, m)?)?;
    m.add_function(wrap_pyfunction!(globalmaxpool2d_module, m)?)?;
    m.add_function(wrap_pyfunction!(globalavgpool2d_module, m)?)?;
    m.add_function(wrap_pyfunction!(embedding_module, m)?)?;
    m.add_function(wrap_pyfunction!(resnet_module, m)?)?;
    m.add_function(wrap_pyfunction!(efficientnet_module, m)?)?;

    // Model serialization functions
    m.add_function(wrap_pyfunction!(save_model, m)?)?;
    m.add_function(wrap_pyfunction!(load_model, m)?)?;

    // PyTorch-compatible serialization functions
    m.add_function(wrap_pyfunction!(torch_save, m)?)?;
    m.add_function(wrap_pyfunction!(torch_load, m)?)?;
    m.add_function(wrap_pyfunction!(load_model_with_device, m)?)?;
    m.add_function(wrap_pyfunction!(save_state_dict, m)?)?;
    
    // Advanced model export functions
    m.add_function(wrap_pyfunction!(export_model_full, m)?)?;
    m.add_function(wrap_pyfunction!(export_model_onnx_enhanced, m)?)?;
    m.add_function(wrap_pyfunction!(export_model_coreml, m)?)?;
    m.add_function(wrap_pyfunction!(export_model_tflite, m)?)?;
    m.add_function(wrap_pyfunction!(export_model_metadata, m)?)?;
    m.add_function(wrap_pyfunction!(create_model_archive, m)?)?;
    m.add_function(wrap_pyfunction!(validate_exported_model, m)?)?;

    // Dataset utility functions
    m.add_function(wrap_pyfunction!(data_loader, m)?)?;
    m.add_function(wrap_pyfunction!(random_split, m)?)?;
    m.add_function(wrap_pyfunction!(concat_dataset, m)?)?;
    m.add_function(wrap_pyfunction!(dataset_from_tensor, m)?)?;

    // Distributed training functions
    m.add_function(wrap_pyfunction!(init_distributed, m)?)?;
    m.add_function(wrap_pyfunction!(create_process_group_py, m)?)?;
    m.add_function(wrap_pyfunction!(all_reduce_gradients_py, m)?)?;
    m.add_function(wrap_pyfunction!(sync_parameters_py, m)?)?;
    m.add_function(wrap_pyfunction!(ring_all_reduce_py, m)?)?;
    m.add_function(wrap_pyfunction!(all_reduce_model_gradients, m)?)?;
    m.add_function(wrap_pyfunction!(sync_model_parameters, m)?)?;

    // Quantization classes and functions
    m.add_class::<PyQuantizationParams>()?;
    m.add_function(wrap_pyfunction!(quantize_tensor, m)?)?;
    m.add_function(wrap_pyfunction!(dequantize_tensor, m)?)?;
    m.add_function(wrap_pyfunction!(dynamic_quantize_tensor, m)?)?;
    m.add_function(wrap_pyfunction!(fake_quantize_tensor, m)?)?;
    m.add_function(wrap_pyfunction!(per_channel_quantize_tensor, m)?)?;
    m.add_function(wrap_pyfunction!(quantize_model, m)?)?;
    m.add_function(wrap_pyfunction!(enable_qat, m)?)?;
    m.add_function(wrap_pyfunction!(calibrate_quantization, m)?)?;
    m.add_function(wrap_pyfunction!(qat_training_step, m)?)?;
    m.add_function(wrap_pyfunction!(optimize_quantized_inference, m)?)?;

    // Transform classes and functions
    m.add_class::<PyTransform>()?;
    m.add_class::<PyCompose>()?;
    m.add_class::<PyNormalize>()?;
    m.add_class::<PyStandardize>()?;
    m.add_class::<PyToTensor>()?;
    m.add_class::<PyRandomCrop>()?;
    m.add_class::<PyCenterCrop>()?;

    // Text Transform classes
    m.add_class::<PyTokenReplacement>()?;
    m.add_class::<PyWordDropout>()?;
    m.add_class::<PyTokenShuffle>()?;
    m.add_class::<PyBackTranslation>()?;
    m.add_class::<PyLambdaTransform>()?;

    // Additional Image Transform classes
    m.add_class::<PyRandomHorizontalFlip>()?;
    m.add_class::<PyRandomVerticalFlip>()?;
    m.add_class::<PyRandomRotation>()?;

    // Transform helper functions
    m.add_function(wrap_pyfunction!(compose, m)?)?;
    m.add_function(wrap_pyfunction!(normalize, m)?)?;
    m.add_function(wrap_pyfunction!(standardize, m)?)?;
    m.add_function(wrap_pyfunction!(to_tensor, m)?)?;
    m.add_function(wrap_pyfunction!(random_crop, m)?)?;
    m.add_function(wrap_pyfunction!(center_crop, m)?)?;

    // Text Transform helper functions
    m.add_function(wrap_pyfunction!(token_replacement, m)?)?;
    m.add_function(wrap_pyfunction!(word_dropout, m)?)?;
    m.add_function(wrap_pyfunction!(token_shuffle, m)?)?;
    m.add_function(wrap_pyfunction!(back_translation, m)?)?;
    m.add_function(wrap_pyfunction!(lambda_transform, m)?)?;

    // Additional Image Transform helper functions
    m.add_function(wrap_pyfunction!(random_horizontal_flip, m)?)?;
    m.add_function(wrap_pyfunction!(random_vertical_flip, m)?)?;
    m.add_function(wrap_pyfunction!(random_rotation, m)?)?;

    // Debugging tools classes and functions
    m.add_class::<PyPrintOptions>()?;
    m.add_class::<PyTensorSummary>()?;
    m.add_class::<PyHistogram>()?;

    // Debugging functions
    m.add_function(wrap_pyfunction!(tensor_summary, m)?)?;
    m.add_function(wrap_pyfunction!(check_tensor_health, m)?)?;
    m.add_function(wrap_pyfunction!(tensor_histogram, m)?)?;
    m.add_function(wrap_pyfunction!(print_tensor, m)?)?;
    m.add_function(wrap_pyfunction!(find_nan_indices, m)?)?;
    m.add_function(wrap_pyfunction!(find_inf_indices, m)?)?;
    m.add_function(wrap_pyfunction!(tensor_percentiles, m)?)?;

    // Additional debugging functions
    m.add_function(wrap_pyfunction!(tensors_allclose, m)?)?;
    m.add_function(wrap_pyfunction!(tensor_memory_info, m)?)?;
    m.add_function(wrap_pyfunction!(validate_tensor, m)?)?;
    m.add_function(wrap_pyfunction!(tensor_where_condition, m)?)?;

    // Benchmark module registration
    benchmarks::register_benchmark_functions(py, m)?;

    // Memory optimization module registration
    // memory_optimizer::register_memory_functions(py, m)?; // Temporarily disabled

    // Visualization module registration
    visualization::register_visualization_functions(py, m)?;

    // Large model support module registration
    large_model_support::register_large_model_functions(py, m)?;

    // Eager execution optimization module registration
    eager_execution_optimizer::register_eager_execution_functions(py, m)?;

    // Dtype promotion module registration
    dtype_promotion::register_dtype_promotion_functions(py, m)?;

    // Bottleneck detection module registration
    bottleneck_detection::register_bottleneck_detection_functions(py, m)?;

    Ok(())
}

// ===== C API Implementation =====

/// C-compatible status codes for error handling
#[repr(C)]
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TensorStatus {
    Success = 0,
    InvalidArgument = 1,
    OutOfMemory = 2,
    DeviceError = 3,
    ShapeMismatch = 4,
    DtypeMismatch = 5,
    Unknown = 999,
}

/// C-compatible tensor handle
#[repr(C)]
pub struct CTensor {
    inner: *mut Tensor<f32>,
    shape: *mut usize,
    ndim: usize,
    device: Device,
}

/// C-compatible device enum
#[repr(C)]
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum CDevice {
    Cpu = 0,
    Gpu = 1,
}

impl From<Device> for CDevice {
    fn from(device: Device) -> Self {
        match device {
            Device::Cpu => CDevice::Cpu,
            #[cfg(feature = "gpu")]
            Device::Gpu(_) => CDevice::Gpu,
        }
    }
}

impl From<CDevice> for Device {
    fn from(device: CDevice) -> Self {
        match device {
            CDevice::Cpu => Device::Cpu,
            #[cfg(feature = "gpu")]
            CDevice::Gpu => Device::Gpu(0),
            #[cfg(not(feature = "gpu"))]
            CDevice::Gpu => Device::Cpu,
        }
    }
}

/// Thread-local error message storage
use std::cell::RefCell;
thread_local! {
    static LAST_ERROR: RefCell<Option<String>> = RefCell::new(None);
}

/// Set the last error message
fn set_last_error(error: String) {
    LAST_ERROR.with(|e| {
        *e.borrow_mut() = Some(error);
    });
}

/// Get the last error message
fn get_last_error() -> Option<String> {
    LAST_ERROR.with(|e| e.borrow().clone())
}

// ===== Core C API Functions =====

/// Create a new tensor with zeros
#[no_mangle]
pub extern "C" fn tensor_zeros(shape: *const usize, ndim: usize, device: CDevice) -> *mut CTensor {
    if shape.is_null() || ndim == 0 {
        set_last_error("Invalid shape or ndim".to_string());
        return std::ptr::null_mut();
    }

    let shape_slice = unsafe { std::slice::from_raw_parts(shape, ndim) };
    let tensor = match Tensor::zeros(shape_slice).to_device(device.into()) {
        Ok(t) => t,
        Err(e) => {
            set_last_error(format!("Failed to create tensor: {}", e));
            return std::ptr::null_mut();
        }
    };

    let tensor_ptr = Box::into_raw(Box::new(tensor));
    let shape_copy = Box::into_raw(shape_slice.to_vec().into_boxed_slice()) as *mut usize;

    Box::into_raw(Box::new(CTensor {
        inner: tensor_ptr,
        shape: shape_copy,
        ndim,
        device: device.into(),
    }))
}

/// Create a new tensor with ones
#[no_mangle]
pub extern "C" fn tensor_ones(shape: *const usize, ndim: usize, device: CDevice) -> *mut CTensor {
    if shape.is_null() || ndim == 0 {
        set_last_error("Invalid shape or ndim".to_string());
        return std::ptr::null_mut();
    }

    let shape_slice = unsafe { std::slice::from_raw_parts(shape, ndim) };
    let tensor = match Tensor::ones(shape_slice).to_device(device.into()) {
        Ok(t) => t,
        Err(e) => {
            set_last_error(format!("Failed to create tensor: {}", e));
            return std::ptr::null_mut();
        }
    };

    let tensor_ptr = Box::into_raw(Box::new(tensor));
    let shape_copy = Box::into_raw(shape_slice.to_vec().into_boxed_slice()) as *mut usize;

    Box::into_raw(Box::new(CTensor {
        inner: tensor_ptr,
        shape: shape_copy,
        ndim,
        device: device.into(),
    }))
}

/// Create a new tensor from raw data
#[no_mangle]
pub extern "C" fn tensor_from_data(
    data: *const f32,
    shape: *const usize,
    ndim: usize,
    device: CDevice,
) -> *mut CTensor {
    if data.is_null() || shape.is_null() || ndim == 0 {
        set_last_error("Invalid data, shape, or ndim".to_string());
        return std::ptr::null_mut();
    }

    let shape_slice = unsafe { std::slice::from_raw_parts(shape, ndim) };
    let size = shape_slice.iter().product::<usize>();
    let data_slice = unsafe { std::slice::from_raw_parts(data, size) };

    let tensor = match Tensor::from_vec(data_slice.to_vec(), shape_slice)
        .and_then(|t| t.to_device(device.into()))
    {
        Ok(t) => t,
        Err(e) => {
            set_last_error(format!("Failed to create tensor: {}", e));
            return std::ptr::null_mut();
        }
    };

    let tensor_ptr = Box::into_raw(Box::new(tensor));
    let shape_copy = Box::into_raw(shape_slice.to_vec().into_boxed_slice()) as *mut usize;

    Box::into_raw(Box::new(CTensor {
        inner: tensor_ptr,
        shape: shape_copy,
        ndim,
        device: device.into(),
    }))
}

/// Destroy a tensor and free memory
#[no_mangle]
pub extern "C" fn tensor_destroy(tensor: *mut CTensor) -> TensorStatus {
    if tensor.is_null() {
        return TensorStatus::InvalidArgument;
    }

    unsafe {
        let ctensor = Box::from_raw(tensor);
        let _ = Box::from_raw(ctensor.inner);
        let _ = Box::from_raw(ctensor.shape);
    }

    TensorStatus::Success
}

/// Get tensor shape
#[no_mangle]
pub extern "C" fn tensor_shape(
    tensor: *const CTensor,
    shape_out: *mut usize,
    ndim_out: *mut usize,
) -> TensorStatus {
    if tensor.is_null() || shape_out.is_null() || ndim_out.is_null() {
        return TensorStatus::InvalidArgument;
    }

    let ctensor = unsafe { &*tensor };
    let shape_slice = unsafe { std::slice::from_raw_parts(ctensor.shape, ctensor.ndim) };

    unsafe {
        *ndim_out = ctensor.ndim;
        std::ptr::copy_nonoverlapping(shape_slice.as_ptr(), shape_out, ctensor.ndim);
    }

    TensorStatus::Success
}

/// Get tensor data pointer (read-only)
#[no_mangle]
pub extern "C" fn tensor_data(tensor: *const CTensor) -> *const f32 {
    if tensor.is_null() {
        return std::ptr::null();
    }

    let ctensor = unsafe { &*tensor };
    let inner = unsafe { &*ctensor.inner };

    match inner.as_slice() {
        Some(slice) => slice.as_ptr(),
        None => {
            set_last_error("Tensor data not available on CPU".to_string());
            std::ptr::null()
        }
    }
}

/// Get mutable tensor data pointer
#[no_mangle]
pub extern "C" fn tensor_data_mut(tensor: *mut CTensor) -> *mut f32 {
    if tensor.is_null() {
        return std::ptr::null_mut();
    }

    let ctensor = unsafe { &mut *tensor };
    let inner = unsafe { &mut *ctensor.inner };

    match inner.as_slice() {
        Some(slice) => slice.as_ptr() as *mut f32,
        None => {
            set_last_error("Tensor data not available on CPU".to_string());
            std::ptr::null_mut()
        }
    }
}

/// Get tensor size (total number of elements)
#[no_mangle]
pub extern "C" fn tensor_size(tensor: *const CTensor) -> usize {
    if tensor.is_null() {
        return 0;
    }

    let ctensor = unsafe { &*tensor };
    let inner = unsafe { &*ctensor.inner };
    inner.size()
}

/// Get tensor device
#[no_mangle]
pub extern "C" fn tensor_device(tensor: *const CTensor) -> CDevice {
    if tensor.is_null() {
        return CDevice::Cpu;
    }

    let ctensor = unsafe { &*tensor };
    ctensor.device.into()
}

/// Move tensor to device
#[no_mangle]
pub extern "C" fn tensor_to_device(tensor: *mut CTensor, device: CDevice) -> TensorStatus {
    if tensor.is_null() {
        return TensorStatus::InvalidArgument;
    }

    let ctensor = unsafe { &mut *tensor };
    let inner = unsafe { &mut *ctensor.inner };

    match inner.to_device(device.into()) {
        Ok(new_tensor) => {
            let _ = unsafe { Box::from_raw(ctensor.inner) };
            ctensor.inner = Box::into_raw(Box::new(new_tensor));
            ctensor.device = device.into();
            TensorStatus::Success
        }
        Err(e) => {
            set_last_error(format!("Failed to move tensor to device: {}", e));
            TensorStatus::DeviceError
        }
    }
}

// ===== Tensor Operations =====

/// Add two tensors
#[no_mangle]
pub extern "C" fn tensor_add(
    a: *const CTensor,
    b: *const CTensor,
    out: *mut CTensor,
) -> TensorStatus {
    if a.is_null() || b.is_null() || out.is_null() {
        return TensorStatus::InvalidArgument;
    }

    let a_inner = unsafe { &*(*a).inner };
    let b_inner = unsafe { &*(*b).inner };
    let out_inner = unsafe { &mut *(*out).inner };

    match a_inner.add(b_inner) {
        Ok(result) => {
            *out_inner = result;
            TensorStatus::Success
        }
        Err(e) => {
            set_last_error(format!("Failed to add tensors: {}", e));
            TensorStatus::Unknown
        }
    }
}

/// Subtract two tensors
#[no_mangle]
pub extern "C" fn tensor_sub(
    a: *const CTensor,
    b: *const CTensor,
    out: *mut CTensor,
) -> TensorStatus {
    if a.is_null() || b.is_null() || out.is_null() {
        return TensorStatus::InvalidArgument;
    }

    let a_inner = unsafe { &*(*a).inner };
    let b_inner = unsafe { &*(*b).inner };
    let out_inner = unsafe { &mut *(*out).inner };

    match a_inner.sub(b_inner) {
        Ok(result) => {
            *out_inner = result;
            TensorStatus::Success
        }
        Err(e) => {
            set_last_error(format!("Failed to subtract tensors: {}", e));
            TensorStatus::Unknown
        }
    }
}

/// Multiply two tensors
#[no_mangle]
pub extern "C" fn tensor_mul(
    a: *const CTensor,
    b: *const CTensor,
    out: *mut CTensor,
) -> TensorStatus {
    if a.is_null() || b.is_null() || out.is_null() {
        return TensorStatus::InvalidArgument;
    }

    let a_inner = unsafe { &*(*a).inner };
    let b_inner = unsafe { &*(*b).inner };
    let out_inner = unsafe { &mut *(*out).inner };

    match a_inner.mul(b_inner) {
        Ok(result) => {
            *out_inner = result;
            TensorStatus::Success
        }
        Err(e) => {
            set_last_error(format!("Failed to multiply tensors: {}", e));
            TensorStatus::Unknown
        }
    }
}

/// Matrix multiplication
#[no_mangle]
pub extern "C" fn tensor_matmul(
    a: *const CTensor,
    b: *const CTensor,
    out: *mut CTensor,
) -> TensorStatus {
    if a.is_null() || b.is_null() || out.is_null() {
        return TensorStatus::InvalidArgument;
    }

    let a_inner = unsafe { &*(*a).inner };
    let b_inner = unsafe { &*(*b).inner };
    let out_inner = unsafe { &mut *(*out).inner };

    match a_inner.matmul(b_inner) {
        Ok(result) => {
            *out_inner = result;
            TensorStatus::Success
        }
        Err(e) => {
            set_last_error(format!("Failed to multiply matrices: {}", e));
            TensorStatus::Unknown
        }
    }
}

/// Tensor sum reduction
#[no_mangle]
pub extern "C" fn tensor_sum(
    tensor: *const CTensor,
    axis: *const i32,
    axis_len: usize,
    keepdims: bool,
    out: *mut CTensor,
) -> TensorStatus {
    if tensor.is_null() || out.is_null() {
        return TensorStatus::InvalidArgument;
    }

    let inner = unsafe { &*(*tensor).inner };
    let out_inner = unsafe { &mut *(*out).inner };

    let result = if axis.is_null() {
        // Sum over all axes
        inner.sum(None, keepdims)
    } else {
        // Sum over specified axes
        let axis_slice = unsafe { std::slice::from_raw_parts(axis, axis_len) };
        inner.sum(Some(axis_slice), keepdims)
    };

    match result {
        Ok(result) => {
            *out_inner = result;
            TensorStatus::Success
        }
        Err(e) => {
            set_last_error(format!("Failed to sum tensor: {}", e));
            TensorStatus::Unknown
        }
    }
}

/// Tensor mean reduction
#[no_mangle]
pub extern "C" fn tensor_mean(
    tensor: *const CTensor,
    axis: *const i32,
    axis_len: usize,
    keepdims: bool,
    out: *mut CTensor,
) -> TensorStatus {
    if tensor.is_null() || out.is_null() {
        return TensorStatus::InvalidArgument;
    }

    let inner = unsafe { &*(*tensor).inner };
    let out_inner = unsafe { &mut *(*out).inner };

    let result = if axis.is_null() {
        // Mean over all axes
        inner.mean(None, keepdims)
    } else {
        // Mean over specified axes
        let axis_slice = unsafe { std::slice::from_raw_parts(axis, axis_len) };
        inner.mean(Some(axis_slice), keepdims)
    };

    match result {
        Ok(result) => {
            *out_inner = result;
            TensorStatus::Success
        }
        Err(e) => {
            set_last_error(format!("Failed to calculate mean: {}", e));
            TensorStatus::Unknown
        }
    }
}

/// Reshape tensor
#[no_mangle]
pub extern "C" fn tensor_reshape(
    tensor: *const CTensor,
    new_shape: *const usize,
    new_ndim: usize,
    out: *mut CTensor,
) -> TensorStatus {
    if tensor.is_null() || new_shape.is_null() || out.is_null() {
        return TensorStatus::InvalidArgument;
    }

    let inner = unsafe { &*(*tensor).inner };
    let out_inner = unsafe { &mut *(*out).inner };
    let shape_slice = unsafe { std::slice::from_raw_parts(new_shape, new_ndim) };

    match inner.reshape(shape_slice) {
        Ok(result) => {
            *out_inner = result;
            TensorStatus::Success
        }
        Err(e) => {
            set_last_error(format!("Failed to reshape tensor: {}", e));
            TensorStatus::ShapeMismatch
        }
    }
}

/// Transpose tensor
#[no_mangle]
pub extern "C" fn tensor_transpose(
    tensor: *const CTensor,
    axes: *const usize,
    axes_len: usize,
    out: *mut CTensor,
) -> TensorStatus {
    if tensor.is_null() || out.is_null() {
        return TensorStatus::InvalidArgument;
    }

    let inner = unsafe { &*(*tensor).inner };
    let out_inner = unsafe { &mut *(*out).inner };

    let result = if axes.is_null() {
        // Default transpose (reverse all axes)
        inner.transpose()
    } else {
        // Axis-specific transpose
        let axes_slice = unsafe { std::slice::from_raw_parts(axes, axes_len) };
        transpose_axes(inner, Some(axes_slice))
    };

    match result {
        Ok(result) => {
            *out_inner = result;
            TensorStatus::Success
        }
        Err(e) => {
            set_last_error(format!("Failed to transpose tensor: {}", e));
            TensorStatus::Unknown
        }
    }
}

// ===== Error Handling =====

/// Get the last error message
#[no_mangle]
pub extern "C" fn tensor_last_error() -> *const std::os::raw::c_char {
    match get_last_error() {
        Some(error) => {
            let c_string = std::ffi::CString::new(error).unwrap_or_else(|_| {
                std::ffi::CString::new("Invalid UTF-8 in error message").unwrap()
            });
            c_string.into_raw()
        }
        None => std::ptr::null(),
    }
}

/// Free error message string
#[no_mangle]
pub extern "C" fn tensor_free_error(error: *mut std::os::raw::c_char) {
    if !error.is_null() {
        unsafe {
            let _ = std::ffi::CString::from_raw(error);
        }
    }
}

// ===== Utility Functions =====

/// Check if GPU is available
#[no_mangle]
pub extern "C" fn tensor_is_gpu_available() -> bool {
    #[cfg(feature = "gpu")]
    {
        tenflowers_core::gpu::is_gpu_available()
    }
    #[cfg(not(feature = "gpu"))]
    {
        false
    }
}

/// Get device count
#[no_mangle]
pub extern "C" fn tensor_get_device_count() -> usize {
    #[cfg(feature = "gpu")]
    {
        tenflowers_core::gpu::get_device_count()
    }
    #[cfg(not(feature = "gpu"))]
    {
        1 // Only CPU available
    }
}

/// Initialize the library
#[no_mangle]
pub extern "C" fn tensor_init() -> TensorStatus {
    // Initialize any global state if needed
    TensorStatus::Success
}

/// Cleanup the library
#[no_mangle]
pub extern "C" fn tensor_cleanup() -> TensorStatus {
    // Cleanup any global state if needed
    TensorStatus::Success
}

// ===== Version Information =====

/// Get library version
#[no_mangle]
pub extern "C" fn tensor_version() -> *const std::os::raw::c_char {
    let version = env!("CARGO_PKG_VERSION");
    let c_string = std::ffi::CString::new(version).unwrap();
    c_string.into_raw()
}

/// Free version string
#[no_mangle]
pub extern "C" fn tensor_free_version(version: *mut std::os::raw::c_char) {
    if !version.is_null() {
        unsafe {
            let _ = std::ffi::CString::from_raw(version);
        }
    }
}

// ===== Tests =====

